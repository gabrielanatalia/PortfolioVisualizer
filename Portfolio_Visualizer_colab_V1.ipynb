{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielanatalia/PortfolioVisualizer/blob/main/Portfolio_Visualizer_colab_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d215e46-b6fa-4abf-b6b4-2653cfaa0aac",
      "metadata": {
        "id": "6d215e46-b6fa-4abf-b6b4-2653cfaa0aac"
      },
      "source": [
        "# **Portfolio Visualizer**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5f9942a9-bdca-4745-a748-8d9d4300533d",
      "metadata": {
        "id": "5f9942a9-bdca-4745-a748-8d9d4300533d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567a8baf-b116-4c06-ee0f-6fa376a38186",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: reportlab in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from reportlab) (11.1.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from reportlab) (5.2.0)\n",
            "Requirement already satisfied: kaleido in /usr/local/lib/python3.11/dist-packages (0.2.1)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Cloning into 'Projects'...\n",
            "remote: Enumerating objects: 558, done.\u001b[K\n",
            "remote: Counting objects: 100% (97/97), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 558 (delta 68), reused 42 (delta 42), pack-reused 461 (from 1)\u001b[K\n",
            "Receiving objects: 100% (558/558), 40.31 MiB | 15.56 MiB/s, done.\n",
            "Resolving deltas: 100% (328/328), done.\n",
            "/content/Projects\n"
          ]
        }
      ],
      "source": [
        "# @title 1. Load libraries and functions\n",
        "!pip install reportlab\n",
        "!pip install kaleido\n",
        "!pip install PyPDF2\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math, os, io, time, pytz, re, copy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import date, timedelta\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import norm\n",
        "from scipy.optimize import minimize, fsolve\n",
        "import itertools\n",
        "import plotly.graph_objects as go\n",
        "import yfinance as yf\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import matplotlib.cm as cm\n",
        "from matplotlib.colors import ListedColormap\n",
        "from matplotlib import colors\n",
        "import statsmodels.formula.api as smf\n",
        "from dateutil.parser import parse\n",
        "from datetime import datetime, timedelta\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML, Javascript\n",
        "from ipywidgets import VBox, HBox, Label, HTML\n",
        "from google.colab import widgets as gc_widgets\n",
        "from contextlib import redirect_stdout\n",
        "from google.colab import files\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.units import inch\n",
        "from IPython.display import FileLink\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import PyPDF2\n",
        "from PyPDF2 import PdfMerger, PdfReader, PdfWriter\n",
        "\n",
        "\n",
        "!git clone https://github.com/gabrielanatalia/Projects/\n",
        "%cd /content/Projects\n",
        "import sys\n",
        "sys.path.append('/content/Projects')\n",
        "import port_cons as pc\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def convert_to_datetime(input_str, parserinfo=None):\n",
        "    return parse(input_str, parserinfo=parserinfo)\n",
        "\n",
        "TOLERANCE = 1e-10\n",
        "\n",
        "def _allocation_risk(weights, covariances):\n",
        "\n",
        "    portfolio_risk = np.sqrt((weights * covariances * weights.T))[0, 0]\n",
        "\n",
        "    return portfolio_risk\n",
        "\n",
        "def _assets_risk_contribution_to_allocation_risk(weights, covariances):\n",
        "\n",
        "    portfolio_risk = _allocation_risk(weights, covariances)\n",
        "\n",
        "    assets_risk_contribution = np.multiply(weights.T, covariances * weights.T) \\\n",
        "        / portfolio_risk\n",
        "\n",
        "    return assets_risk_contribution\n",
        "\n",
        "def _risk_budget_objective_error(weights, args):\n",
        "    covariances = args[0]\n",
        "    assets_risk_budget = args[1]\n",
        "    weights = np.matrix(weights)\n",
        "\n",
        "    portfolio_risk = _allocation_risk(weights, covariances)\n",
        "\n",
        "    assets_risk_contribution = \\\n",
        "        _assets_risk_contribution_to_allocation_risk(weights, covariances)\n",
        "\n",
        "    assets_risk_target = \\\n",
        "        np.asmatrix(np.multiply(portfolio_risk, assets_risk_budget))\n",
        "\n",
        "    error = sum(np.absolute(assets_risk_contribution - assets_risk_target.T))[0, 0]\n",
        "    return error\n",
        "\n",
        "def _get_risk_parity_weights(covariances, assets_risk_budget, initial_weights):\n",
        "\n",
        "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1.0},{'type': 'ineq', 'fun': lambda x: x})\n",
        "\n",
        "    optimize_result = minimize(fun=_risk_budget_objective_error,\n",
        "                               x0=initial_weights,\n",
        "                               args=[covariances, assets_risk_budget],\n",
        "                               method='SLSQP',\n",
        "                               constraints=constraints,\n",
        "                               tol=TOLERANCE,\n",
        "                               options={'disp': False})\n",
        "\n",
        "    weights = optimize_result.x\n",
        "    print(optimize_result.message)\n",
        "    return weights\n",
        "\n",
        "def rebal_wgt_riskparity(returns_data, start_date, end_date, rebal_months=[4,10], halflife=3.5, annualized=252, shrink_covar=False):\n",
        "    num_of_assets = len(returns_data.columns)\n",
        "\n",
        "    ret_data_filtered = returns_data.loc[start_date:end_date]\n",
        "    first_date = returns_data.index[0]\n",
        "    tickers = list(returns_data.columns)\n",
        "\n",
        "    weights = pd.DataFrame(0, index=ret_data_filtered.index, columns=ret_data_filtered.columns)\n",
        "    weights.index = pd.to_datetime(weights.index, format='%Y-%m-%d')\n",
        "    reb_flag = pd.DataFrame(0, index=weights.index, columns=['reb_flag'])\n",
        "\n",
        "    alpha = 1 - math.exp(math.log(0.5) / (halflife * annualized))\n",
        "    span = (2 / alpha) - 1\n",
        "\n",
        "    for i in range(len(ret_data_filtered)):\n",
        "        curr_date = ret_data_filtered.index[i]\n",
        "        curr_date_format = curr_date.strftime('%Y-%m-%d')\n",
        "\n",
        "        if (weights.index[i].month in rebal_months and weights.index[i-1].month != weights.index[i].month) or i==0:\n",
        "\n",
        "            if shrink_covar:\n",
        "                shrink_covar_matrix_model = LedoitWolf().fit(returns_data.loc[first_date:curr_date])\n",
        "                covar_ann = pd.DataFrame(shrink_covar_matrix_model.covariance_ * annualized, index=tickers, columns=tickers)\n",
        "                covar_ann.columns = tickers\n",
        "                covar_ann.index = tickers\n",
        "            else:\n",
        "                exp_cov_matrix = returns_data.loc[first_date:curr_date].ewm(span=span).cov(pairwise=True).iloc[-num_of_assets:]\n",
        "                covar_ann = exp_cov_matrix * annualized\n",
        "                covar_ann.columns = tickers\n",
        "                covar_ann.index = tickers\n",
        "\n",
        "            valid_covar_ann = covar_ann.dropna(how='all')\n",
        "            valid_covar_ann = valid_covar_ann.dropna(axis=1, how='all')\n",
        "            valid_num_assets = len(valid_covar_ann)\n",
        "            valid_tickers = valid_covar_ann.columns\n",
        "\n",
        "            assets_risk_budget = np.ones([valid_num_assets]) / valid_num_assets\n",
        "            initial_weights = np.ones([valid_num_assets]) / valid_num_assets\n",
        "\n",
        "            # print(valid_covar_ann)\n",
        "            new_wgt = _get_risk_parity_weights(valid_covar_ann.values, assets_risk_budget, initial_weights)\n",
        "            new_wgt = pd.DataFrame(new_wgt).T\n",
        "            new_wgt.columns = valid_tickers\n",
        "\n",
        "            for ticker in valid_tickers:\n",
        "                weights.at[curr_date_format, ticker] = new_wgt[ticker].values\n",
        "\n",
        "            reb_flag.loc[curr_date_format] = True\n",
        "\n",
        "        else:\n",
        "            weights.iloc[i] = weights.iloc[i-1] * (1+ ret_data_filtered.iloc[i].fillna(0))\n",
        "            weights_sum = weights.iloc[i].sum()\n",
        "            weights.iloc[i] /= weights_sum\n",
        "            reb_flag.iloc[i] = False\n",
        "\n",
        "    weights = weights.rename(columns={c: c + '_wgt' for c in weights.columns})\n",
        "    weights = pd.concat([reb_flag, weights], axis=1)\n",
        "\n",
        "    return weights\n",
        "\n",
        "def combine_backtest_data(portfolio_names):\n",
        "    # combined portfolio returns\n",
        "    all_port_ret = {}\n",
        "\n",
        "    for portfolio in portfolio_names:\n",
        "        perf_df = globals()[f\"{portfolio}_perf\"]\n",
        "        ret_col = [col for col in perf_df.columns if col.endswith('_port_ret')]\n",
        "        all_port_ret[portfolio] = perf_df[ret_col]\n",
        "\n",
        "    df_all_port_ret = pd.concat(all_port_ret.values(), keys=all_port_ret.keys(), axis=1)\n",
        "    df_all_port_ret.columns = [col[0] for col in df_all_port_ret.columns]\n",
        "\n",
        "    # combined portfolio weights\n",
        "    all_port_weights = {}\n",
        "\n",
        "    for portfolio in portfolio_names:\n",
        "        wgt_df = globals()[f\"{portfolio}_wgt\"]\n",
        "        # wgt_col = [col for col in wgt_df.columns if col.endswith('_wgt')]\n",
        "        # all_port_weights[portfolio] = wgt_df[wgt_col]\n",
        "        all_port_weights[portfolio] = wgt_df\n",
        "\n",
        "    df_all_port_weights = pd.concat(all_port_weights.values(), keys=all_port_weights.keys(), axis=1)\n",
        "\n",
        "    # combined portfolio backtest daata\n",
        "    all_port_bt = {}\n",
        "\n",
        "    for portfolio in portfolio_names:\n",
        "        bt_df = globals()[f\"{portfolio}_perf\"]\n",
        "        all_port_bt[portfolio] = bt_df\n",
        "\n",
        "    df_all_port_bt = pd.concat(all_port_bt.values(), keys=all_port_bt.keys(), axis=1)\n",
        "    return df_all_port_ret, df_all_port_weights, df_all_port_bt\n",
        "\n",
        "\n",
        "def print_arial(text):\n",
        "    display(HTML(f\"<div style='font-family: Arial, sans-serif'>{text}</div>\"))\n",
        "\n",
        "def print_arial_bold(text):\n",
        "    display(HTML(f\"<div style='font-family: Arial, sans-serif; font-weight: bold;'>{text}</div>\"))\n",
        "\n",
        "def merge_pdfs(existing_pdf, merged_pdf, output_pdf):\n",
        "    # Open the existing PDFs\n",
        "    with open(existing_pdf, \"rb\") as pdf1, open(merged_pdf, \"rb\") as pdf2:\n",
        "        reader1 = PyPDF2.PdfReader(pdf1)\n",
        "        reader2 = PyPDF2.PdfReader(pdf2)\n",
        "        writer = PyPDF2.PdfWriter()\n",
        "\n",
        "        # Add all pages from the first PDF\n",
        "        for page in reader1.pages:\n",
        "            writer.add_page(page)\n",
        "\n",
        "        # Add all pages from the second PDF\n",
        "        for page in reader2.pages:\n",
        "            writer.add_page(page)\n",
        "\n",
        "        # Save the merged PDF\n",
        "        with open(output_pdf, \"wb\") as output:\n",
        "            writer.write(output)\n",
        "\n",
        "def plot_pie_chart_topX(series, title, topX=10, width=1000, height=600, colors=None):\n",
        "    # Filter for values greater than 0\n",
        "    series = series[series > 0]\n",
        "\n",
        "    # Proceed only if there are values to plot\n",
        "    if not series.empty:\n",
        "        top_x = series.sort_values(ascending=False).head(topX)\n",
        "        other_sum = series.sum() - top_x.sum()\n",
        "\n",
        "        # Filter labels and values based on positive values\n",
        "        labels = list(top_x.index)\n",
        "        values = list(top_x)\n",
        "\n",
        "        # Add 'Others' only if other_sum is greater than 0\n",
        "        if other_sum > 0.01:\n",
        "            labels.append('Others')\n",
        "            values.append(other_sum)\n",
        "\n",
        "        # Create the Pie trace data\n",
        "        pie_data = {\n",
        "            'labels': labels,\n",
        "            'values': values,\n",
        "            'textinfo': 'label+percent',\n",
        "            'hole': 0.3,\n",
        "            'textposition': 'outside',\n",
        "        }\n",
        "\n",
        "        # Add marker with custom colors if provided\n",
        "        if colors:\n",
        "            pie_data['marker'] = dict(colors=colors)\n",
        "\n",
        "        fig = go.Figure(data=[go.Pie(**pie_data)])  # Unpack pie_data into go.Pie\n",
        "        fig.update_layout(title={'text': f'<b>{title}</b>','font': dict(size=75)}, width=width, height=height, showlegend=False, font=dict(family=\"Arial\", size=75, color='black'))\n",
        "        return fig\n",
        "    else:\n",
        "        print(\"No values greater than 0 to plot.\")\n",
        "        return None\n",
        "\n",
        "def plot_bar_chart_topX(series, title, topX=10, width=1000, height=600, colors=None):\n",
        "\n",
        "\n",
        "    # Filter for values greater than 0\n",
        "    series = series[series > 0]\n",
        "\n",
        "    # Proceed only if there are values to plot\n",
        "    if not series.empty:\n",
        "        top_x = series.sort_values(ascending=False).head(topX)\n",
        "        other_sum = series.sum() - top_x.sum()\n",
        "\n",
        "        # Filter labels and values based on positive values\n",
        "        labels = list(top_x.index)\n",
        "        values = list(top_x)\n",
        "\n",
        "        # Add 'Others' only if other_sum is greater than 0\n",
        "        if other_sum > 0:\n",
        "            labels.append('Others')\n",
        "            values.append(other_sum)\n",
        "\n",
        "        # Calculate percentages and format labels\n",
        "        total_sum = sum(values)\n",
        "        text_labels = [f'{round(value / total_sum * 100, 2)}%' for value in values]  # Only percentage\n",
        "\n",
        "        # Create the Bar trace data\n",
        "        bar_data = {\n",
        "            'x': labels,\n",
        "            'y': values,\n",
        "            'text': text_labels,\n",
        "            'textposition': 'auto',\n",
        "            'textangle': 0\n",
        "        }\n",
        "\n",
        "        # Add marker with the first custom color if provided\n",
        "        if colors:\n",
        "            bar_data['marker'] = dict(color=colors[0])  # Use the first color from the list\n",
        "\n",
        "        fig = go.Figure(data=[go.Bar(**bar_data)])  # Unpack bar_data into go.Bar\n",
        "        fig.update_layout(title={'text': f'<b>{title}</b>','font': dict(size=75)}, width=width, height=height, showlegend=False, yaxis_tickformat=\".0%\", font=dict(family=\"Arial\", size=75, color='black'))\n",
        "        return fig\n",
        "    else:\n",
        "        print(\"No values greater than 0 to plot.\")\n",
        "        return None\n",
        "\n",
        "def calc_custom_weighted_risk_rating(custom_usd_rows, df_sec_list):\n",
        "    # Calculates the weighted risk rating of custom USD portfolios\n",
        "\n",
        "    # Merge risk ratings from security list\n",
        "    custom_usd_risk_rating = custom_usd_rows.copy()\n",
        "    custom_usd_risk_rating = custom_usd_risk_rating.merge(\n",
        "        df_sec_list[['Ticker', 'Risk rating']], how='left', left_on='type', right_on='Ticker'\n",
        "    )\n",
        "\n",
        "    # Calculate weighted risk rating and NAV in SGD\n",
        "    custom_usd_risk_rating_weighted_avg = custom_usd_risk_rating.groupby('portfolio_id').apply(\n",
        "        lambda x: pd.Series({\n",
        "            'Risk rating': np.average(x['Risk rating'], weights=x['nav_in_sgd']),\n",
        "        })\n",
        "    ).reset_index()\n",
        "\n",
        "    return custom_usd_risk_rating_weighted_avg\n",
        "\n",
        "########################################################################################################################\n",
        "\n",
        "# read asseet class, sector, country data from csv\n",
        "data_path = '/content/Projects/Data/'\n",
        "df_sec_list = pd.read_csv(data_path + 'PV_sec_list.csv')\n",
        "df_sec_list['Remarks'] = df_sec_list['Remarks'].fillna('N/A')\n",
        "df_asset_class = pd.read_csv(data_path + 'PV_asset_class.csv', index_col=0)\n",
        "df_sector = pd.read_csv(data_path + 'PV_sector.csv', index_col=0)\n",
        "df_country = pd.read_csv(data_path + 'PV_country.csv', index_col=0)\n",
        "df_fi_metrics = pd.read_csv(data_path + 'PV_FI_metrics.csv', index_col=0)\n",
        "df_fx = pd.read_csv(data_path + 'PV_daily_ret.csv',header=0, index_col='Date', parse_dates=['Date'],dayfirst=True)[['USDSGD', 'USDHKD']]/100\n",
        "\n",
        "\n",
        "syfe_colors = ['#263159', '#2f51c9', '#879be3', '#bcbed7', '#dedfee','#fff2cc', '#ffe599', '#e3bf61', '#666666', '#7d839b', '#414e7d']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title PDF Funcs\n",
        "from reportlab.lib.styles import ParagraphStyle\n",
        "from reportlab.lib.pagesizes import landscape, A4\n",
        "from reportlab.lib import colors\n",
        "from reportlab.lib.units import inch\n",
        "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Spacer, Image, Paragraph\n",
        "import os\n",
        "\n",
        "\n",
        "def create_table(df, title):\n",
        "\n",
        "    elements = []\n",
        "    if df.empty:\n",
        "        return elements\n",
        "    else:\n",
        "        table_data = [df.columns.tolist()]  # Add header row\n",
        "        for _, row in df.iterrows():\n",
        "            table_data.append(list(row))\n",
        "\n",
        "        table = Table(table_data)\n",
        "        table_style = TableStyle(\n",
        "            [\n",
        "                (\"BACKGROUND\", (0, 0), (-1, 0), colors.HexColor(\"#263159\")),\n",
        "                (\"TEXTCOLOR\", (0, 0), (-1, 0), colors.whitesmoke),\n",
        "                (\"ALIGN\", (0, 0), (-1, -1), \"CENTER\"),\n",
        "                (\"FONTNAME\", (0, 0), (-1, 0), \"Helvetica-Bold\"),\n",
        "                (\"FONTSIZE\", (0, 0), (-1, 0), 9),\n",
        "                (\"BOTTOMPADDING\", (0, 0), (-1, 0), 3),\n",
        "                (\"TOPPADDING\", (0, 0), (-1, 0), 3),\n",
        "                (\"BOTTOMPADDING\", (0, 1), (-1, -1), 1),\n",
        "                (\"TOPPADDING\", (0, 1), (-1, -1), 1),\n",
        "                (\"BACKGROUND\", (0, 1), (-1, -1), colors.whitesmoke),\n",
        "                (\"TEXTCOLOR\", (0, 1), (-1, -1), colors.black),\n",
        "                (\"FONTNAME\", (0, 1), (-1, -1), \"Helvetica\"),\n",
        "                (\"FONTSIZE\", (0, 1), (-1, -1), 8),\n",
        "                (\"VALIGN\", (0, 0), (-1, -1), \"TOP\"),\n",
        "                (\"ROWBACKGROUNDS\", (0, 1), (-1, -1), [colors.whitesmoke, colors.lightgrey]),\n",
        "                (\"FONTNAME\", (0, -1), (-1, -1), \"Helvetica-Bold\"),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        for i in range(len(df)):  # Iterate using numerical index\n",
        "              if df.iloc[i]['Portfolio ID'] in ['Growth Portfolios', 'Income & Preservation Portfolios', \"Core\", \"Specialised\", \"Income+\", \"REITs\", \"Alternatives\",\"Cash / MMF\"]:\n",
        "                  table_style.add(\"BACKGROUND\", (0, i + 1), (-1, i + 1), colors.HexColor(\"#879be4\"))\n",
        "\n",
        "        table.setStyle(table_style)\n",
        "\n",
        "        custom_title_style = ParagraphStyle(\n",
        "            name=\"CustomTitle\",\n",
        "            fontName=\"Helvetica-Bold\",\n",
        "            fontSize=12,\n",
        "            leading=12,  # Line height\n",
        "            alignment=0,  # Left align\n",
        "        )\n",
        "\n",
        "        # Update the title line in your function\n",
        "        elements.append(Spacer(1, 0.5 * inch))\n",
        "        elements.append(Paragraph(f\"{title}\", custom_title_style))\n",
        "        elements.append(Spacer(1, 0.2 * inch))  # Reduced space after the title\n",
        "        elements.append(table)\n",
        "\n",
        "    return elements\n",
        "\n",
        "def add_page_numbers_header(input_pdf, output_pdf, client_name, page_size=landscape(A4)):\n",
        "    page_width, page_height = page_size\n",
        "\n",
        "    reader = PdfReader(input_pdf)\n",
        "    writer = PdfWriter()\n",
        "    total_pages = len(reader.pages)\n",
        "\n",
        "    for page_num, page in enumerate(reader.pages, start=1):\n",
        "        packet = io.BytesIO()\n",
        "        can = canvas.Canvas(packet, pagesize=page_size)\n",
        "        can.setFont(\"Helvetica\", 8)\n",
        "\n",
        "        # Add page number to bottom-right corner\n",
        "        page_number_text = f\"Page {page_num} of {total_pages}\"\n",
        "        text_width = can.stringWidth(page_number_text, \"Helvetica\", 8)\n",
        "        x_position = page_width - 20 - text_width\n",
        "        y_position = 10\n",
        "        can.drawString(x_position, y_position, page_number_text)\n",
        "\n",
        "        # Add header to upper right-hand corner (same as before)\n",
        "        header_x = page_width - 20  # Start from the right edge\n",
        "\n",
        "        # Client Name\n",
        "        client_name_text = f\"Client Name: {client_name}\"\n",
        "        client_name_width = can.stringWidth(client_name_text, \"Helvetica\", 8)\n",
        "        can.drawString(header_x - client_name_width, page_height - 20, client_name_text)  # Calculate x for right alignment\n",
        "\n",
        "        # Date\n",
        "        date_text = f\"Date: {datetime.now().strftime('%B %d, %Y')}\"\n",
        "        date_width = can.stringWidth(date_text, \"Helvetica\", 8)\n",
        "        can.drawString(header_x - date_width, page_height - 30, date_text)  # Calculate x for right alignment\n",
        "\n",
        "        can.save()\n",
        "\n",
        "        packet.seek(0)\n",
        "        page_overlay = PdfReader(packet)\n",
        "        page.merge_page(page_overlay.pages[0])\n",
        "        writer.add_page(page)\n",
        "\n",
        "    with open(output_pdf, \"wb\") as f:\n",
        "        writer.write(f)\n",
        "\n",
        "def merge_with_template(template_pdf_path, overlay_pdf_path, output_pdf_path):\n",
        "    \"\"\"Merges multiple overlay pages onto a single-page template, repeating the template as needed.\"\"\"\n",
        "\n",
        "    template_pdf = PdfReader(template_pdf_path)\n",
        "    overlay_pdf = PdfReader(overlay_pdf_path)\n",
        "    output_pdf = PdfWriter()\n",
        "\n",
        "    template_page = template_pdf.pages[0]  # Since the template has only 1 page\n",
        "\n",
        "    for page_num in range(len(overlay_pdf.pages)):\n",
        "        overlay_page = overlay_pdf.pages[page_num]\n",
        "\n",
        "        # Copy the template so it doesn't get modified\n",
        "        template_copy = template_page.create_blank_page(\n",
        "            width=template_page.mediabox[2], height=template_page.mediabox[3]\n",
        "        )\n",
        "        template_copy.merge_page(template_page)  # Copy original template\n",
        "        template_copy.merge_page(overlay_page)  # Overlay the new content\n",
        "\n",
        "        output_pdf.add_page(template_copy)\n",
        "\n",
        "    # Write final merged PDF\n",
        "    with open(output_pdf_path, \"wb\") as final_pdf:\n",
        "        output_pdf.write(final_pdf)\n",
        "\n",
        "def create_pdf_with_table_and_charts(output_file, table_df, table_title, charts, col_width_manual=None):\n",
        "    elements = []\n",
        "    temp_images = []  # Track temporary image files for cleanup\n",
        "\n",
        "    # Create PDF document\n",
        "    doc = SimpleDocTemplate(\n",
        "        output_file,\n",
        "        pagesize=landscape(A4),\n",
        "        leftMargin=0.4 * inch,  # Adjust left margin\n",
        "        rightMargin=0.3 * inch,  # Adjust right margin\n",
        "        topMargin=0.6 * inch,  # Adjust top margin\n",
        "        bottomMargin=0.2 * inch  # Adjust bottom margin\n",
        "    )\n",
        "\n",
        "    # Calculate available width for table\n",
        "    page_width = landscape(A4)[0]\n",
        "    available_width = page_width - (doc.leftMargin + doc.rightMargin)\n",
        "\n",
        "    # Create table elements\n",
        "    table_elements = create_table(table_df, table_title)\n",
        "\n",
        "    if table_elements:\n",
        "        table = table_elements[-1]  # Last element is the table\n",
        "\n",
        "        if isinstance(table, Table):\n",
        "            # Calculate column widths dynamically based on text length\n",
        "            text_lengths = table_df.applymap(lambda x: len(str(x))).sum(axis=0)\n",
        "            total_text_length = sum(text_lengths)\n",
        "\n",
        "            # Normalize column widths based on relative text length\n",
        "            if col_width_manual is None:\n",
        "                col_widths = [(available_width * (col_size / total_text_length)) for col_size in text_lengths]\n",
        "                table._argW = col_widths  # Manually set column widths\n",
        "            else:\n",
        "                table._argW = col_width_manual\n",
        "        # print(table._argW)\n",
        "        elements.extend(table_elements)  # Add table elements\n",
        "\n",
        "        # Add explanatory text if the table is for \"Income & Preservation Portfolios\"\n",
        "        if table_title == \"Income & Preservation Portfolios\":\n",
        "            explanation_text = (\n",
        "                \"<i>*Est. Yield (%): References Yield to Maturity (YTM) for Income+ portfolios, estimated dividend yield for REIT+ portfolios, projected returns for Cash+ Flexi portfolios, and guaranteed rates for Cash+ Guaranteed portfolios.</i><br/>\"\n",
        "                \"<i>**Proj. Dividend: Estimated dividend yield multiplied by current portfolio value.</i>\"\n",
        "            )\n",
        "            text_style = ParagraphStyle(\n",
        "                name=\"ExplanationStyle\",\n",
        "                fontName=\"Helvetica-Oblique\",  # Italic font\n",
        "                fontSize=6,\n",
        "                leading=8,  # Line spacing\n",
        "                alignment=0,  # Left-aligned\n",
        "            )\n",
        "            elements.append(Spacer(1, 0.1 * inch))  # Space before text\n",
        "            elements.append(Paragraph(explanation_text, text_style))\n",
        "\n",
        "        elements.append(Spacer(1, 0.2 * inch))  # Space before charts\n",
        "\n",
        "    # Chart settings\n",
        "    num_charts = len(charts)\n",
        "    cols_per_row = 2 if num_charts % 2 == 0 else 3  # Adjust layout\n",
        "\n",
        "    chart_width = 3.5 * inch\n",
        "    chart_height = 2.6 * inch\n",
        "\n",
        "    chart_grid = []\n",
        "    row = []\n",
        "\n",
        "    for idx, chart in enumerate(charts):\n",
        "        # Save chart to temporary image\n",
        "        image_file = f\"temp_chart_{idx}.png\"\n",
        "        chart.write_image(image_file, format=\"png\", width=4000, height=3000)\n",
        "        temp_images.append(image_file)\n",
        "\n",
        "        # Add chart image to row\n",
        "        img = Image(image_file, width=chart_width, height=chart_height)\n",
        "        row.append(img)\n",
        "\n",
        "        # Add row when cols_per_row charts are added or if it's the last chart\n",
        "        if len(row) == cols_per_row or idx == len(charts) - 1:\n",
        "            chart_grid.append(row)\n",
        "            row = []\n",
        "\n",
        "    # Create a table for charts with borders and adjusted colWidths\n",
        "    for chart_row in chart_grid:\n",
        "        col_widths = [available_width / len(chart_row)] * len(chart_row)  # Auto-fit chart columns\n",
        "        chart_table = Table([chart_row], colWidths=col_widths)\n",
        "\n",
        "        # Add border to chart table\n",
        "        chart_table.setStyle(TableStyle([\n",
        "            ('BOX', (0, 0), (-1, -1), 0.1, colors.white),\n",
        "        ]))\n",
        "        elements.append(chart_table)\n",
        "        elements.append(Spacer(1, 0.1 * inch))\n",
        "\n",
        "    doc.build(elements)\n",
        "\n",
        "    # Clean up temporary image files\n",
        "    for image_file in temp_images:\n",
        "        if os.path.exists(image_file):\n",
        "            os.remove(image_file)\n",
        "\n",
        "def calculate_subtotal_income_preservation(df, classification):\n",
        "    # Filter data for the given classification\n",
        "    subset = df[df['L2_classification'] == classification]\n",
        "\n",
        "    # Sum relevant numeric columns\n",
        "    subtotal = subset[['Value (SGD)', 'Value (USD)', 'Proj. Dividend (SGD)', 'Allocation']].sum()\n",
        "\n",
        "    # Assign Portfolio ID\n",
        "    subtotal['Portfolio ID'] = classification\n",
        "\n",
        "    # Calculate weighted average for Est. Yield (%)\n",
        "    allocation_sum = subset['Allocation'].sum()\n",
        "\n",
        "    if allocation_sum != 0:\n",
        "        weighted_yield = (subset['Est. Yield (%)'] * subset['Allocation']).sum() / allocation_sum\n",
        "    else:\n",
        "        weighted_yield = 0  # Avoid division by zero\n",
        "\n",
        "    # Add weighted Est. Yield (%) to the subtotal\n",
        "    subtotal['Est. Yield (%)'] = weighted_yield\n",
        "\n",
        "    return subtotal\n",
        "\n",
        "def dividend_option_adj(row):\n",
        "    if row['Dividend Option'] == 'REINVEST':\n",
        "        return 'Accumulating'\n",
        "    elif row['internal_port_name'] in income_plus_groups:\n",
        "        return 'Payout (monthly)'\n",
        "    elif row['internal_port_name'] in reit_groups:\n",
        "        return 'Payout (quarterly)'\n",
        "    else:\n",
        "        return '-'\n",
        "\n",
        "def format_maturity_period(value):\n",
        "    if isinstance(value, str):  # Check if value is a string\n",
        "        if value == '\"ONE_MONTH\"':\n",
        "            return \"1 month\"\n",
        "        if value == '\"THREE_MONTHS\"':\n",
        "            return \"3 months\"\n",
        "        if value == '\"SIX_MONTHS\"':\n",
        "            return \"6 months\"\n",
        "        if value == '\"TWELVE_MONTHS\"':\n",
        "            return \"12 months\"\n",
        "        else:\n",
        "            return \"-\"\n",
        "    return value  # Return original value if not a string or no match\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vYECEhoWIFEs"
      },
      "id": "vYECEhoWIFEs",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "\n",
        "syfe_port_mapping = pd.DataFrame({\n",
        "'MB_port_name': ['CASH_PLUS', 'CASH_PLUS_USD', 'CHINA_GROWTH', 'CORE_BALANCED', 'CORE_DEFENSIVE', 'CORE_GROWTH', 'DISRUPTIVE_TECHNOLOGY', 'ESG_AND_CLEAN_ENERGY',\n",
        "                  'GLOBAL_EQUITY_100', 'HEALTHCARE_INNOVATION', 'INCOME_ENHANCE', 'INCOME_PRESERVE', 'REIT', 'REIT_RISK_MANAGED',\n",
        "                  'SRS_CASH_PLUS', 'SRS_GLOBAL_EQUITY_100', 'SRS_INCOME_ENHANCED', 'SRS_INCOME_PRESERVE', 'DOWNSIDE_PROTECTED', 'CASH_PLUS_GUARANTEED_SGD',\n",
        "                 'CUSTOM_USD', 'SIFN27D'],\n",
        "\n",
        "'internal_port_name': ['Cash SGD flexi', 'Cash USD flexi', 'China Growth', 'Core Balanced', 'Core Defensive', 'Core Growth', 'Disruptive Technology',\n",
        "                        'ESG & Clean Energy', 'Core Equity100', 'Healthcare Innovation', 'Income Enhance', 'Income Preserve', 'REIT 100', 'REIT Risk Managed',\n",
        "                        'SRS Cash SGD flexi', 'SRS Equity100', 'SRS Income Enhance', 'SRS Income Preserve', 'Downside protected', 'Cash SGD guaranteed',\n",
        "                       'Custom USD', 'Silverdale Fund (Nov 2027)']\n",
        "})\n",
        "\n",
        "core_groups = ['Core Equity100', 'Core Growth', 'Core Balanced', 'Core Defensive', 'SRS Equity100']\n",
        "specialised_groups = ['China Growth', 'Disruptive Technology', 'ESG & Clean Energy', 'Healthcare Innovation', 'Downside protected', 'Custom USD']\n",
        "reit_groups = ['REIT 100', 'REIT Risk Managed']\n",
        "income_plus_groups = ['Income Enhance', 'Income Preserve', 'SRS Income Enhance', 'SRS Income Preserve']\n",
        "alt_groups = ['Silverdale Fund (Nov 2027)']\n",
        "custom_groups = ['Custom USD']\n",
        "cm_groups = ['Cash SGD flexi', 'SRS Cash SGD flexi', 'Cash USD flexi', 'Cash SGD guaranteed']\n",
        "\n",
        "growth_groups = core_groups + specialised_groups\n",
        "income_preservation_groups = income_plus_groups + reit_groups + alt_groups + cm_groups\n",
        "all_syfe__portfolios = growth_groups + income_preservation_groups\n",
        "\n",
        "syfe_port_mapping['L1_classification'] = np.where(syfe_port_mapping['internal_port_name'].isin(growth_groups), 'Growth', 'Income & Preservation')\n",
        "\n",
        "L2_conditions = [\n",
        "    syfe_port_mapping['internal_port_name'].isin(core_groups),\n",
        "    syfe_port_mapping['internal_port_name'].isin(specialised_groups),\n",
        "    syfe_port_mapping['internal_port_name'].isin(reit_groups),\n",
        "    syfe_port_mapping['internal_port_name'].isin(income_plus_groups),\n",
        "    syfe_port_mapping['internal_port_name'].isin(alt_groups),\n",
        "    syfe_port_mapping['internal_port_name'].isin(cm_groups),\n",
        "]\n",
        "\n",
        "labels = ['Core', 'Specialised', 'REITs', 'Income+', 'Alternatives','Cash / MMF']\n",
        "\n",
        "# Assign L2 classification\n",
        "syfe_port_mapping['L2_classification'] = np.select(L2_conditions, labels, default='Other')\n",
        "\n",
        "syfe_port_mapping = syfe_port_mapping.merge(df_sec_list[['Ticker', 'Risk rating']], how='left', left_on='internal_port_name', right_on='Ticker')\n",
        "syfe_port_mapping.drop(columns=['Ticker'], inplace=True)\n",
        "\n",
        "\n",
        "################################################################################################################################\n",
        "mb_port_names_core = syfe_port_mapping[syfe_port_mapping['internal_port_name'].isin(core_groups)]['MB_port_name'].tolist()\n",
        "mb_port_names_specialised = syfe_port_mapping[syfe_port_mapping['internal_port_name'].isin(specialised_groups)]['MB_port_name'].tolist()\n",
        "mb_port_names_cm = syfe_port_mapping[syfe_port_mapping['internal_port_name'].isin(cm_groups)]['MB_port_name'].tolist()\n",
        "mb_port_names_growth = syfe_port_mapping[syfe_port_mapping['internal_port_name'].isin(growth_groups)]['MB_port_name'].tolist()\n",
        "mb_port_names_income_preservation = syfe_port_mapping[syfe_port_mapping['internal_port_name'].isin(income_preservation_groups)]['MB_port_name'].tolist()\n",
        "mb_port_names_income_plus = ['INCOME_ENHANCE', 'INCOME_PRESERVE', 'SRS_INCOME_ENHANCE', 'SRS_INCOME_PRESERVE']\n",
        "mb_port_names_reits = ['REIT', 'REIT_RISK_MANAGED']\n",
        "mb_port_names_alt = ['SIFN27D']\n",
        "\n",
        "order_of_ports = ['GLOBAL_EQUITY_100', 'CORE_GROWTH', 'CORE_BALANCED', 'CORE_DEFENSIVE', 'SRS_GLOBAL_EQUITY_100',\n",
        "                  'DISRUPTIVE_TECHNOLOGY', 'ESG_AND_CLEAN_ENERGY', 'HEALTHCARE_INNOVATION', 'CHINA_GROWTH', 'DOWNSIDE_PROTECTED', 'CUSTOM_USD',\n",
        "                  'INCOME_PRESERVE', 'INCOME_ENHANCE', 'SRS_INCOME_PRESERVE', 'SRS_INCOME_ENHANCED', 'REIT' ,'REIT_RISK_MANAGED', 'SIFN27D',\n",
        "                  'CASH_PLUS', 'CASH_PLUS_USD', 'CASH_PLUS_GUARANTEED_SGD', 'SRS_CASH_PLUS']\n",
        "\n",
        "# all_asset_mapping = df_sec_list.merge(syfe_port_mapping, how='left', left_on='Ticker', right_on='internal_port_name')\n",
        "# all_asset_mapping.loc[all_asset_mapping['MB_port_name'].isnull(), ['MB_port_name', 'internal_port_name']] = all_asset_mapping['Ticker']"
      ],
      "metadata": {
        "id": "5KKVzOkl3cge"
      },
      "id": "5KKVzOkl3cge",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Upload MB report\n",
        "\n",
        "#####################################################################################################################\n",
        "\n",
        "bbg_last_update_date = pd.read_csv(data_path + 'PV_daily_ret.csv', index_col=0, usecols=[0], parse_dates=['Date'],dayfirst=True).index[-1]\n",
        "bbg_last_update_date = bbg_last_update_date.strftime('%Y-%m-%d')\n",
        "\n",
        "#####################################################################################################################\n",
        "print('\\n')\n",
        "print_arial_bold('Upload client holdings from <a href=\"https://metabase.internal.syfe.com/question/1470-find-clients-portfolios-by-email?email=&portfolio_id=&client_id=&phone=&source_of_funds=\" target=\"_blank\">Metabase</a>')\n",
        "\n",
        "uploader = widgets.FileUpload(\n",
        "    accept='*',  # Accepts all file types\n",
        "    multiple=False  # Only allows one file to be uploaded at a time\n",
        ")\n",
        "\n",
        "# function to upload file\n",
        "def handle_upload(change, syfe_port_mapping=syfe_port_mapping):\n",
        "    global df_client_portfolios, aggregated_holdings, custom_usd_rows, aggregated_holdings_all_clients, custom_usd_all_clients\n",
        "\n",
        "    syfe_port_mapping = pd.DataFrame({\n",
        "    'MB_port_name': ['CASH_PLUS', 'CASH_PLUS_USD', 'CHINA_GROWTH', 'CORE_BALANCED', 'CORE_DEFENSIVE', 'CORE_GROWTH', 'DISRUPTIVE_TECHNOLOGY', 'ESG_AND_CLEAN_ENERGY',\n",
        "                      'GLOBAL_EQUITY_100', 'HEALTHCARE_INNOVATION', 'INCOME_ENHANCE', 'INCOME_PRESERVE', 'REIT', 'REIT_RISK_MANAGED',\n",
        "                      'SRS_CASH_PLUS', 'SRS_GLOBAL_EQUITY_100', 'SRS_INCOME_ENHANCED', 'SRS_INCOME_PRESERVE', 'DOWNSIDE_PROTECTED', 'CASH_PLUS_GUARANTEED_SGD',\n",
        "                    'CUSTOM_USD', 'SIFN27D'],\n",
        "\n",
        "    'internal_port_name': ['Cash SGD flexi', 'Cash USD flexi', 'China Growth', 'Core Balanced', 'Core Defensive', 'Core Growth', 'Disruptive Technology',\n",
        "                            'ESG & Clean Energy', 'Core Equity100', 'Healthcare Innovation', 'Income Enhance', 'Income Preserve', 'REIT 100', 'REIT Risk Managed',\n",
        "                            'SRS Cash SGD flexi', 'SRS Equity100', 'SRS Income Enhance', 'SRS Income Preserve', 'Downside protected', 'Cash SGD guaranteed',\n",
        "                          'Custom USD', 'Silverdale Fund (Nov 2027)']\n",
        "    })\n",
        "\n",
        "    uploaded_filename = next(iter(uploader.value))\n",
        "    content = uploader.value[uploaded_filename]['content']\n",
        "    with open(uploaded_filename, 'wb') as f:\n",
        "        f.write(content)\n",
        "    print(f'Uploaded `{uploaded_filename}` successfully!')\n",
        "\n",
        "    # Read the CSV file into a pandas DataFrame\n",
        "    try:\n",
        "        df_client_portfolios = pd.read_csv(io.BytesIO(content))\n",
        "        client_id_list = list((df_client_portfolios['client_id']).unique())\n",
        "        aggregated_holdings_all_clients = pd.DataFrame()\n",
        "        custom_usd_all_clients = pd.DataFrame()\n",
        "\n",
        "        for client_id in client_id_list:\n",
        "          df_client_portfolios_active = df_client_portfolios[df_client_portfolios['client_id']==client_id]\n",
        "          df_client_portfolios_active = df_client_portfolios_active[df_client_portfolios_active['status']=='ACTIVE'] # filter for active portfolios only\n",
        "          if df_client_portfolios_active['actual_holding_weightage'].astype(str).str.startswith('SIFN27D', na=False).any():\n",
        "              df_client_portfolios_active = process_silverdale_port(df_client_portfolios_active)\n",
        "          df_client_portfolios_active = process_custom_usd(df_client_portfolios_active) # explode custom usd underlying into individual rows\n",
        "          # display(df_client_portfolios_active)\n",
        "          df_client_portfolios_active = df_client_portfolios_active.merge(syfe_port_mapping, how='left', left_on='type', right_on='MB_port_name')\n",
        "\n",
        "          # Handle custom usd mapping: filter for rows with NaN MB_port_name and update MB_port_name with 'type'\n",
        "          nan_mb_port_name_rows = df_client_portfolios_active['MB_port_name'].isna()\n",
        "          df_client_portfolios_active.loc[nan_mb_port_name_rows, 'MB_port_name'] = df_client_portfolios_active.loc[nan_mb_port_name_rows, 'type']\n",
        "          df_client_portfolios_active.loc[nan_mb_port_name_rows, 'internal_port_name'] = df_client_portfolios_active.loc[nan_mb_port_name_rows, 'type']\n",
        "          custom_usd_rows = df_client_portfolios_active[nan_mb_port_name_rows].copy()\n",
        "          custom_usd_rows = custom_usd_rows.merge(df_sec_list[['Ticker']], how='left', left_on='MB_port_name', right_on='Ticker')\n",
        "\n",
        "          non_custom_usd_rows = df_client_portfolios_active[~nan_mb_port_name_rows]  # Rows that were not originally NaN\n",
        "          df_client_portfolios_active = pd.concat([non_custom_usd_rows, custom_usd_rows], ignore_index=True)\n",
        "          # display(df_client_portfolios_active)\n",
        "\n",
        "          aggregated_holdings = aggregate_client_holdings(df_client_portfolios_active)\n",
        "          aggregated_holdings['client_id'] = client_id\n",
        "\n",
        "          aggregated_holdings_all_clients = pd.concat([aggregated_holdings_all_clients, aggregated_holdings],axis=0)\n",
        "          custom_usd_all_clients = pd.concat([custom_usd_all_clients, custom_usd_rows],axis=0)\n",
        "\n",
        "        return aggregated_holdings_all_clients\n",
        "\n",
        "    except pd.errors.ParserError:\n",
        "        print(\"Error: Could not parse the file as a CSV. Please ensure it's a valid CSV file.\")\n",
        "\n",
        "uploader.observe(handle_upload, names='value') # Observe the uploader for changes\n",
        "display(uploader) # Display the uploader\n",
        "\n",
        "def aggregate_client_holdings(df_client_portfolios):\n",
        "    # Aggregate holdings based on 'internal_port_name'\n",
        "    aggregated_holdings = df_client_portfolios.groupby('internal_port_name').agg({\n",
        "        'internal_port_name': lambda x: ', '.join(x.astype(str)),  # Join tickers with commas\n",
        "        'nav_in_sgd': 'sum'  # Sum market values\n",
        "    })\n",
        "    # aggregated_holdings[['nav_in_sgd']] = aggregated_holdings[['nav_in_sgd']].apply(pd.to_numeric)\n",
        "    # Calculate allocations\n",
        "    total_market_value = aggregated_holdings['nav_in_sgd'].sum()\n",
        "    aggregated_holdings['Allocation'] = aggregated_holdings['nav_in_sgd'] / total_market_value\n",
        "    aggregated_holdings['Allocation'] = round(aggregated_holdings['Allocation'], 8)\n",
        "    return aggregated_holdings\n",
        "\n",
        "def process_custom_usd(df):\n",
        "    df[\"nav_in_sgd\"] = df[\"nav_in_sgd\"].replace(\",\", \"\", regex=True)\n",
        "    df[\"nav_in_sgd\"] = pd.to_numeric(df[\"nav_in_sgd\"], errors=\"coerce\")\n",
        "    df[\"nav_in_usd\"] = df[\"nav_in_usd\"].replace(\",\", \"\", regex=True)\n",
        "    df[\"nav_in_usd\"] = pd.to_numeric(df[\"nav_in_usd\"], errors=\"coerce\")\n",
        "\n",
        "    # Separate CUSTOM_USD portfolios\n",
        "    custom_usd_df = df[df[\"type\"] == \"CUSTOM_USD\"].copy()\n",
        "    other_portfolios_df = df[df[\"type\"] != \"CUSTOM_USD\"]\n",
        "\n",
        "    split_custom_usd_df = []\n",
        "\n",
        "    for _, row in custom_usd_df.iterrows():\n",
        "        holdings_str = row[\"actual_holding_weightage\"]\n",
        "\n",
        "        if isinstance(holdings_str, str):  # Ensure it's a string\n",
        "            try:\n",
        "                # Split by comma and then by spaces\n",
        "                holdings = [\n",
        "                    h.strip().rsplit(\" \", 1)  # Split ticker and weight\n",
        "                    for h in holdings_str.split(\",\")\n",
        "                    if h.strip()]\n",
        "                # print(row)\n",
        "                for ticker, weight_str in holdings:\n",
        "                    try:\n",
        "                        weight = float(weight_str.strip(\"%\")) / 100\n",
        "                        new_row = row.copy()\n",
        "                        new_row[\"type\"] = ticker\n",
        "                        nav_in_sgd = row[\"nav_in_sgd\"]\n",
        "                        if isinstance(nav_in_sgd, str):\n",
        "                          nav_in_sgd = float(nav_in_sgd.replace(\",\", \"\"))\n",
        "                        new_row[\"nav_in_sgd\"] = nav_in_sgd * weight if nav_in_sgd else None\n",
        "                        nav_in_usd = row[\"nav_in_usd\"]\n",
        "                        if isinstance(nav_in_usd, str):\n",
        "                            nav_in_usd = float(nav_in_usd.replace(\",\", \"\"))\n",
        "                        new_row[\"nav_in_usd\"] = nav_in_usd * weight if nav_in_usd else None\n",
        "\n",
        "                        split_custom_usd_df.append(new_row)\n",
        "                    except ValueError:\n",
        "                        print(f\"Warning: Invalid weight format for ticker {ticker}: {weight_str}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing holdings string '{holdings_str}': {e}\")\n",
        "        else:\n",
        "            print(f\"Warning: actual_holding_weightage is not a string: {holdings_str}\")\n",
        "\n",
        "    # Concatenate the split CUSTOM_USD rows with the non-CUSTOM_USD rows\n",
        "    processed_df = pd.concat([other_portfolios_df, pd.DataFrame(split_custom_usd_df)],ignore_index=True,)\n",
        "    processed_df[['nav_in_sgd']] = processed_df[['nav_in_sgd']].apply(pd.to_numeric)\n",
        "    processed_df[['nav_in_usd']] = processed_df[['nav_in_usd']].apply(pd.to_numeric)\n",
        "\n",
        "\n",
        "    return processed_df\n",
        "\n",
        "\n",
        "#####################################################################################################################\n",
        "# @title Confirm portfolio parameters\n",
        "\n",
        "def get_unique_tickers():\n",
        "        all_tickers_set = set(bm_tickers)  # Start with benchmark tickers\n",
        "        for portfolio_widgets_dict in portfolio_widgets.values():\n",
        "            portfolio_tickers = re.split(r'\\s*,\\s*', portfolio_widgets_dict['tickers'].value)\n",
        "            all_tickers_set.update(portfolio_tickers)  # Add portfolio tickers\n",
        "        return list(all_tickers_set)"
      ],
      "metadata": {
        "id": "zpcwvrMlT9UV",
        "outputId": "fade8372-2cbb-41b7-ba80-5e77495a60bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133,
          "referenced_widgets": [
            "537e41ac51d548aaa7aba726d0c9119d",
            "a1edc1e9ccbc4662bdc33261fb184d9d",
            "72e8749f4b494301a99eb6bc3b4244b4",
            "a981b0a660de4726925e8fc39286d72a",
            "89243d96db9541f8a079f56b62e6d27f",
            "60c326786da54d61befd08cdc05d6108"
          ]
        },
        "cellView": "form"
      },
      "id": "zpcwvrMlT9UV",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<div style=\\'font-family: Arial, sans-serif; font-weight: bold;\\'>Upload client holdings from <a h…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "537e41ac51d548aaa7aba726d0c9119d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileUpload(value={}, accept='*', description='Upload')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a981b0a660de4726925e8fc39286d72a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded `Client_2_PV.csv` successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Calc & Generate PDF\n",
        "\n",
        "client_id_list = list((df_client_portfolios['client_id']).unique())\n",
        "\n",
        "for client_id in client_id_list:\n",
        "  print('Generating report for ', client_id)\n",
        "\n",
        "  # GENERATE KEY HOLDINGS & ALLOCATIONS\n",
        "\n",
        "  ###################################################################################################################################################################################################\n",
        "  # client_latest_alloc = df_client_portfolios[df_client_portfolios['status']=='ACTIVE'][['type', 'nav_in_sgd']]\n",
        "  client_latest_alloc = aggregated_holdings_all_clients[aggregated_holdings_all_clients['client_id']==client_id]\n",
        "  client_latest_alloc['nav_in_sgd'] = client_latest_alloc['nav_in_sgd'].astype(str).str.replace(',', '').astype(float)\n",
        "  # client_latest_alloc = pd.DataFrame(client_latest_alloc.groupby('type')['nav_in_sgd'].sum())\n",
        "  client_latest_alloc['Client Portfolio'] = client_latest_alloc['nav_in_sgd'] / client_latest_alloc['nav_in_sgd'].sum()\n",
        "  client_latest_alloc = client_latest_alloc[['Client Portfolio']]\n",
        "  client_latest_alloc = client_latest_alloc.rename(index=syfe_port_mapping.set_index('MB_port_name')['internal_port_name'])\n",
        "\n",
        "  client_latest_alloc_adj = client_latest_alloc.T\n",
        "  client_latest_alloc_adj['reb_flag'] = True\n",
        "\n",
        "  # split into growth and income portfolios\n",
        "  all_port_wgt_income_preservation = client_latest_alloc_adj.loc[client_latest_alloc_adj[('reb_flag')] == True].head().iloc[-1:]\n",
        "  cols_to_keep_income_pres = ['reb_flag'] + [col for col in income_preservation_groups if col in all_port_wgt_income_preservation.columns]\n",
        "  all_port_wgt_income_preservation = all_port_wgt_income_preservation[cols_to_keep_income_pres]\n",
        "\n",
        "  all_port_wgt_growth = client_latest_alloc_adj.loc[client_latest_alloc_adj[('reb_flag')] == True].head().iloc[-1:]\n",
        "  cols_to_keep_growth = ['reb_flag'] + [col for col in all_port_wgt_growth.columns if col != 'reb_flag' and col not in income_preservation_groups]\n",
        "  # cols_to_keep_growth = ['reb_flag'] + [col for col in growth_groups if col in all_port_wgt_growth.columns]\n",
        "  all_port_wgt_growth = all_port_wgt_growth[cols_to_keep_growth]\n",
        "  ###################################################################################################################################################################################################\n",
        "\n",
        "  assetclass_breakdown_all = pc.exposure_analysis(client_latest_alloc_adj, df_asset_class, latest_data=True)\n",
        "  assetclass_breakdown_all = (assetclass_breakdown_all.loc[(assetclass_breakdown_all != 0).any(axis=1)].sort_values(by=assetclass_breakdown_all.columns[0], ascending=False))\n",
        "\n",
        "  country_breakdown_all = pc.exposure_analysis(client_latest_alloc_adj, df_country, latest_data=True)\n",
        "  country_breakdown_all = (country_breakdown_all.loc[(country_breakdown_all != 0).any(axis=1)].sort_values(by=country_breakdown_all.columns[0], ascending=False))\n",
        "  country_breakdown_all.pipe(pc.apply_style_heatmap).pipe(pc.apply_2dp_percentage)\n",
        "\n",
        "  # growth exposure\n",
        "  if all_port_wgt_growth.empty == False:\n",
        "    assetclass_breakdown_growth = pc.exposure_analysis(all_port_wgt_growth, df_asset_class, latest_data=True)\n",
        "    assetclass_breakdown_growth = (assetclass_breakdown_growth.loc[(assetclass_breakdown_growth != 0).any(axis=1)].sort_values(by=assetclass_breakdown_growth.columns[0], ascending=False))\n",
        "    assetclass_breakdown_growth = assetclass_breakdown_growth / assetclass_breakdown_growth.sum()\n",
        "\n",
        "    country_breakdown_growth = pc.exposure_analysis(all_port_wgt_growth, df_country, latest_data=True)\n",
        "    country_breakdown_growth = (country_breakdown_growth.loc[(country_breakdown_growth != 0).any(axis=1)].sort_values(by=country_breakdown_growth.columns[0], ascending=False))\n",
        "    country_breakdown_growth.pipe(pc.apply_style_heatmap).pipe(pc.apply_2dp_percentage)\n",
        "    country_breakdown_growth = country_breakdown_growth / country_breakdown_growth.sum()\n",
        "\n",
        "    sector_breakdown_growth = pc.exposure_analysis(all_port_wgt_growth, df_sector, latest_data=True)\n",
        "    sector_breakdown_growth = (sector_breakdown_growth.loc[(sector_breakdown_growth != 0).any(axis=1)].sort_values(by=sector_breakdown_growth.columns[0], ascending=False))\n",
        "    sector_breakdown_growth.pipe(pc.apply_style_heatmap).pipe(pc.apply_2dp_percentage)\n",
        "    sector_breakdown_growth = sector_breakdown_growth / sector_breakdown_growth.sum()\n",
        "\n",
        "  # income & preservation exposure\n",
        "  if all_port_wgt_income_preservation.empty == False:\n",
        "    assetclass_breakdown_income_preservation = pc.exposure_analysis(all_port_wgt_income_preservation, df_asset_class, latest_data=True)\n",
        "    assetclass_breakdown_income_preservation = (assetclass_breakdown_income_preservation.loc[(assetclass_breakdown_income_preservation != 0).any(axis=1)].sort_values(by=assetclass_breakdown_income_preservation.columns[0], ascending=False))\n",
        "    assetclass_breakdown_income_preservation = assetclass_breakdown_income_preservation / assetclass_breakdown_income_preservation.sum()\n",
        "\n",
        "    country_breakdown_income_preservation = pc.exposure_analysis(all_port_wgt_income_preservation, df_country, latest_data=True)\n",
        "    country_breakdown_income_preservation = (country_breakdown_income_preservation.loc[(country_breakdown_income_preservation != 0).any(axis=1)].sort_values(by=country_breakdown_income_preservation.columns[0], ascending=False))\n",
        "    country_breakdown_income_preservation.pipe(pc.apply_style_heatmap).pipe(pc.apply_2dp_percentage)\n",
        "    country_breakdown_income_preservation = country_breakdown_income_preservation / country_breakdown_income_preservation.sum()\n",
        "\n",
        "    sector_breakdown_income_preservation = pc.exposure_analysis(all_port_wgt_income_preservation, df_sector, latest_data=True)\n",
        "    sector_breakdown_income_preservation = (sector_breakdown_income_preservation.loc[(sector_breakdown_income_preservation != 0).any(axis=1)].sort_values(by=sector_breakdown_income_preservation.columns[0], ascending=False))\n",
        "    sector_breakdown_income_preservation.pipe(pc.apply_style_heatmap).pipe(pc.apply_2dp_percentage)\n",
        "    sector_breakdown_income_preservation = sector_breakdown_income_preservation / sector_breakdown_income_preservation.sum()\n",
        "\n",
        "  ###################################################################################################################################################################################################\n",
        "\n",
        "  # PORTFOLIO SUMMARY TABLE\n",
        "  for col in ['nav_in_sgd', 'nav_in_usd', 'pnl_inception', 'invested_amount', 'dividend_balance']:\n",
        "      df_client_portfolios[col] = pd.to_numeric(df_client_portfolios[col].astype(str).str.replace(',', '', regex=True), errors='coerce')\n",
        "\n",
        "  # df_client_portfolios = df_client_portfolios.sort_values(by='nav_in_sgd', ascending=False)\n",
        "  df_client_portfolios_to_show = df_client_portfolios[df_client_portfolios['client_id']==client_id]\n",
        "  df_client_portfolios_to_show = df_client_portfolios_to_show[df_client_portfolios_to_show['status'] == 'ACTIVE']\n",
        "  if df_client_portfolios_to_show['actual_holding_weightage'].astype(str).str.startswith('SIFN27D', na=False).any():\n",
        "      df_client_portfolios_to_show = process_silverdale_port(df_client_portfolios_to_show)\n",
        "  # Select and format columns\n",
        "  cols_to_show_all = ['portfolio_id', 'type', 'activated_date_sgt', 'nav_in_sgd', 'nav_in_usd', 'dividend_balance', 'dividend_option', 'maturity_period', 'fd_created_at_rate']\n",
        "  client_port_rename_cols_all = ['Portfolio ID', 'Portfolio Type', 'Activated date', 'Value (SGD)', 'Value (USD)', 'Dividend (SGD)', 'Dividend Option','Maturity period', 'Guaranteed rate']\n",
        "  df_client_portfolios_to_show_all = df_client_portfolios_to_show[cols_to_show_all]\n",
        "  df_client_portfolios_to_show_all.columns = client_port_rename_cols_all\n",
        "  df_client_portfolios_to_show_all = df_client_portfolios_to_show_all.merge(syfe_port_mapping, left_on='Portfolio Type', right_on='MB_port_name', how='left')\n",
        "\n",
        "  # Check if 'CUSTOM_USD' exists in 'Portfolio Type'\n",
        "  if 'CUSTOM_USD' in df_client_portfolios_to_show_all['Portfolio Type'].values:\n",
        "      custom_usd_risk_rating = calc_custom_weighted_risk_rating(custom_usd_all_clients[custom_usd_all_clients['client_id']==client_id], df_sec_list)\n",
        "\n",
        "      # Iterate through rows with 'CUSTOM_USD'\n",
        "      for index, row in df_client_portfolios_to_show_all[df_client_portfolios_to_show_all['Portfolio Type'] == 'CUSTOM_USD'].iterrows():\n",
        "          # Get the Portfolio ID\n",
        "          portfolio_id = row['Portfolio ID']\n",
        "\n",
        "          # Find the corresponding Risk rating in custom_usd_risk_rating\n",
        "          try:\n",
        "              risk_rating = custom_usd_risk_rating[custom_usd_risk_rating['portfolio_id'] == portfolio_id]['Risk rating'].values[0]\n",
        "              # Update the Risk rating in df_client_portfolios_to_show_all\n",
        "              df_client_portfolios_to_show_all.loc[index, 'Risk rating'] = risk_rating\n",
        "          except IndexError:\n",
        "              # Handle cases where portfolio_id is not found in custom_usd_risk_rating\n",
        "              print(f\"Warning: Risk rating not found for Portfolio ID: {portfolio_id}\")\n",
        "\n",
        "  ###################################################################################################################################################################################################\n",
        "\n",
        "  # PORTFOLIO SUMMARY TABLE\n",
        "  all_portfolios_summary = df_client_portfolios_to_show_all.copy()\n",
        "\n",
        "  all_portfolios_summary['Allocation'] = all_portfolios_summary['Value (SGD)'] / all_portfolios_summary['Value (SGD)'].sum()\n",
        "\n",
        "  total_row_all = pd.DataFrame(columns=all_portfolios_summary.columns)\n",
        "\n",
        "  for col in all_portfolios_summary.columns:\n",
        "      if col in ['Value (SGD)', 'Value (USD)', 'Allocation']:\n",
        "          total_row_all.at['Total', col] = all_portfolios_summary[col].sum()\n",
        "      elif col == 'Risk rating':\n",
        "          total_row_all.at['Total', col] = np.dot(\n",
        "              all_portfolios_summary[col].astype(float), all_portfolios_summary['Allocation']\n",
        "          ) / all_portfolios_summary['Allocation'].sum()\n",
        "      else:\n",
        "          total_row_all.at['Total', col] = ''\n",
        "\n",
        "  total_row_all.iloc[0, 0] = 'Total'\n",
        "\n",
        "  all_portfolios_summary[['Value (SGD)', 'Value (USD)']] = round(all_portfolios_summary[['Value (SGD)', 'Value (USD)']], 2)\n",
        "  growth_rows = all_portfolios_summary[all_portfolios_summary['Portfolio Type'].isin(mb_port_names_growth)]\n",
        "  income_pres_rows = all_portfolios_summary[all_portfolios_summary['Portfolio Type'].isin(mb_port_names_income_preservation)]\n",
        "\n",
        "  if not growth_rows.empty:\n",
        "    growth_subtotal = growth_rows.agg({\n",
        "        'Value (SGD)': 'sum',\n",
        "        'Value (USD)': 'sum',\n",
        "        'Allocation': 'sum',\n",
        "        'Risk rating': lambda x: np.average(x.astype(float), weights=growth_rows.loc[x.index, 'Allocation'])\n",
        "    })\n",
        "    growth_subtotal['Portfolio ID'] = 'Growth Portfolios'\n",
        "  else:\n",
        "      # Create an empty Series with 0 values for all columns\n",
        "      growth_subtotal = pd.Series({\n",
        "          'Value (SGD)': 0,\n",
        "          'Value (USD)': 0,\n",
        "          'Allocation': 0,\n",
        "          'Risk rating': 0\n",
        "      }, dtype=object)  # Using object dtype to handle mixed types\n",
        "      growth_subtotal['Portfolio ID'] = 'Growth Portfolios'\n",
        "      growth_subtotal = growth_subtotal.to_frame().T  # Convert to DataFrame\n",
        "\n",
        "  # Calculate subtotals for income_preservation_groups\n",
        "  if not income_pres_rows.empty:  # Only calculate if there are relevant rows\n",
        "      income_pres_subtotal = income_pres_rows.agg({\n",
        "          'Value (SGD)': 'sum',\n",
        "          'Value (USD)': 'sum',\n",
        "          'Allocation': 'sum',\n",
        "          'Risk rating': lambda x: np.average(\n",
        "              x.astype(float),\n",
        "              weights=income_pres_rows.loc[x.index, 'Allocation']\n",
        "          ) if not x.empty else np.nan  # Handle empty cases safely\n",
        "      })\n",
        "\n",
        "      income_pres_subtotal['Portfolio ID'] = 'Income & Preservation Portfolios'\n",
        "  else:\n",
        "    # Create an empty Series with 0 values for all columns\n",
        "    income_pres_subtotal = pd.Series({\n",
        "        'Value (SGD)': 0,\n",
        "        'Value (USD)': 0,\n",
        "        'Allocation': 0,\n",
        "        'Risk rating': 0\n",
        "    }, dtype=object)  # Using object dtype to handle mixed types\n",
        "    income_pres_subtotal['Portfolio ID'] = 'Income & Preservation Portfolios'\n",
        "    income_pres_subtotal = income_pres_subtotal.to_frame().T  # Convert to DataFrame\n",
        "\n",
        "  # Concatenate subtotals and original DataFrame\n",
        "  if total_row_all['Value (SGD)'].values[0] > 0:  # Check if NAV (SGD) is greater than 0\n",
        "      all_portfolios_summary_final = pd.concat([all_portfolios_summary, total_row_all])\n",
        "\n",
        "  all_portfolios_summary_final['Portfolio Type'] = pd.Categorical(\n",
        "      all_portfolios_summary_final['Portfolio Type'],\n",
        "      categories=order_of_ports,\n",
        "      ordered=True\n",
        "  )\n",
        "\n",
        "  # Sort the DataFrame\n",
        "  all_portfolios_summary_final = all_portfolios_summary_final.sort_values(by='Portfolio Type').reset_index(drop=True)\n",
        "\n",
        "  other_rows = all_portfolios_summary_final[~all_portfolios_summary_final['L1_classification'].isin(['Growth', 'Income & Preservation'])]\n",
        "\n",
        "  concat_list = [growth_rows]\n",
        "\n",
        "  if not growth_rows.empty:\n",
        "      concat_list.append(growth_subtotal.to_frame().T)\n",
        "\n",
        "  concat_list.append(income_pres_rows)\n",
        "\n",
        "  if not income_pres_rows.empty:  # Check if subtotal exists\n",
        "      concat_list.append(income_pres_subtotal.to_frame().T)\n",
        "\n",
        "  concat_list.append(other_rows)\n",
        "\n",
        "  all_portfolios_summary_final = pd.concat(concat_list, ignore_index=True)\n",
        "\n",
        "  all_portfolios_summary_final[['Value (SGD)', 'Value (USD)']] = all_portfolios_summary_final[['Value (SGD)', 'Value (USD)']].applymap(lambda x: \"{:,.2f}\".format(x) if isinstance(x, (int, float)) else x)\n",
        "  all_portfolios_summary_final[['Risk rating']] = all_portfolios_summary_final[['Risk rating']].applymap(lambda x: \"{:,.1f}\".format(x) if isinstance(x, (int, float)) else x)\n",
        "  all_portfolios_summary_final['Allocation'] = (all_portfolios_summary_final['Allocation'] * 100).map('{:.2f}%'.format)\n",
        "\n",
        "  for col in all_portfolios_summary_final.columns:\n",
        "      if pd.api.types.is_categorical_dtype(all_portfolios_summary_final[col]):\n",
        "          # Add an empty string to the categories\n",
        "          all_portfolios_summary_final[col] = all_portfolios_summary_final[col].cat.add_categories([''])\n",
        "          # Fill NaN with the empty string\n",
        "          all_portfolios_summary_final[col] = all_portfolios_summary_final[col].fillna('')\n",
        "\n",
        "      elif all_portfolios_summary_final[col].dtype == 'object':  # For string columns\n",
        "          all_portfolios_summary_final[col] = all_portfolios_summary_final[col].fillna('')\n",
        "\n",
        "      else:  # For numeric columns\n",
        "          all_portfolios_summary_final[col] = all_portfolios_summary_final[col].fillna(0)\n",
        "\n",
        "\n",
        "  all_portfolios_summary_final = all_portfolios_summary_final[['Portfolio ID', 'internal_port_name', 'L2_classification', 'Risk rating', 'Activated date', 'Value (SGD)', 'Value (USD)', 'Allocation']]\n",
        "  all_portfolios_summary_final.rename(columns={'internal_port_name': 'Portfolio Type', 'L2_classification':'Classification', 'Risk rating':'Risk rating (Max:5)'}, inplace=True)\n",
        "\n",
        "  ###################################################################################################################################################################################################\n",
        "  # GROWTH PORTFOLIO TABLE\n",
        "\n",
        "  # Separate the dataframe based on the 'type' column\n",
        "  growth_portfolios = all_portfolios_summary[all_portfolios_summary['L1_classification']=='Growth']\n",
        "  growth_portfolios['Allocation'] = growth_portfolios['Value (SGD)'] / growth_portfolios['Value (SGD)'].sum()\n",
        "\n",
        "  core_subtotal = growth_portfolios[growth_portfolios['L2_classification']=='Core'].sum(numeric_only=True)\n",
        "  core_subtotal['Portfolio ID'] = 'Core'\n",
        "  specialised_subtotal = growth_portfolios[growth_portfolios['L2_classification']=='Specialised'].sum(numeric_only=True)\n",
        "  specialised_subtotal['Portfolio ID'] = 'Specialised'\n",
        "\n",
        "  total_row_growth = pd.DataFrame({col: [growth_portfolios[col].sum() if col in ['Value (SGD)', 'Value (USD)', 'Invested Amount', 'P&L since inception', 'Dividend (SGD)', 'Allocation'] else '']\n",
        "                            for col in growth_portfolios.columns}, index=['Total'])\n",
        "\n",
        "  total_row_growth.iloc[0, 0] = 'Total'\n",
        "\n",
        "  if total_row_growth['Value (SGD)'].values[0] > 0:  # Check if NAV (SGD) is greater than 0\n",
        "      growth_portfolios = pd.concat([growth_portfolios, total_row_growth])\n",
        "\n",
        "  growth_portfolios['Portfolio Type'] = pd.Categorical(\n",
        "      growth_portfolios['Portfolio Type'],\n",
        "      categories=order_of_ports,\n",
        "      ordered=True\n",
        "  )\n",
        "\n",
        "  # Sort the DataFrame\n",
        "  growth_portfolios = growth_portfolios.sort_values(by='Portfolio Type').reset_index(drop=True)\n",
        "  core_rows = growth_portfolios[growth_portfolios['L2_classification'] == 'Core']\n",
        "  specialised_rows = growth_portfolios[growth_portfolios['L2_classification'] == 'Specialised']\n",
        "  other_rows = growth_portfolios[~growth_portfolios['L2_classification'].isin(['Core', 'Specialised'])]\n",
        "\n",
        "  # growth_portfolios = pd.concat([core_rows, core_subtotal.to_frame().T, specialised_rows, specialised_subtotal.to_frame().T, other_rows])\n",
        "\n",
        "  growth_portfolios_list = []  # Start with an empty list\n",
        "  growth_portfolios_list.append(core_rows)\n",
        "\n",
        "  if core_rows['Value (SGD)'].sum() != 0:\n",
        "      growth_portfolios_list.append(core_subtotal.to_frame().T)\n",
        "\n",
        "  growth_portfolios_list.append(specialised_rows)\n",
        "\n",
        "  if specialised_rows['Value (SGD)'].sum() != 0:\n",
        "      growth_portfolios_list.append(specialised_subtotal.to_frame().T)\n",
        "\n",
        "  growth_portfolios_list.append(other_rows)\n",
        "\n",
        "  # Concatenate the list of DataFrames\n",
        "  growth_portfolios = pd.concat(growth_portfolios_list)\n",
        "\n",
        "  growth_portfolios[['Value (SGD)', 'Value (USD)']] = growth_portfolios[['Value (SGD)', 'Value (USD)']].applymap(lambda x: \"{:,.2f}\".format(x) if isinstance(x, (int, float)) else x)\n",
        "  growth_portfolios['Allocation'] = (growth_portfolios['Allocation'] * 100).map('{:.2f}%'.format)\n",
        "\n",
        "  for col in growth_portfolios.columns:\n",
        "      if pd.api.types.is_categorical_dtype(growth_portfolios[col]):\n",
        "          # Add an empty string to the categories\n",
        "          growth_portfolios[col] = growth_portfolios[col].cat.add_categories([''])\n",
        "          # Fill NaN with the empty string\n",
        "          growth_portfolios[col] = growth_portfolios[col].fillna('')\n",
        "\n",
        "      elif growth_portfolios[col].dtype == 'object':  # For string columns\n",
        "          growth_portfolios[col] = growth_portfolios[col].fillna('')\n",
        "\n",
        "      else:  # For numeric columns\n",
        "          growth_portfolios[col] = growth_portfolios[col].fillna(0)\n",
        "\n",
        "  growth_portfolios = growth_portfolios[['Portfolio ID', 'internal_port_name', 'Value (SGD)', 'Value (USD)',  'Allocation']]\n",
        "  growth_portfolios.rename(columns={'internal_port_name': 'Portfolio Type'}, inplace=True)\n",
        "\n",
        "  ###################################################################################################################################################################################################\n",
        "  # INCOME & PRESERVATION PORTFOLIOS TABLE\n",
        "\n",
        "  income_preservation_fi_metrics = df_fi_metrics[[ticker for ticker in df_fi_metrics.columns if ticker in income_preservation_groups]]\n",
        "  # Create a dictionary for ticker to MB_port_name mapping\n",
        "  ticker_to_mb_mapping = dict(zip(syfe_port_mapping['internal_port_name'], syfe_port_mapping['MB_port_name']))\n",
        "  income_preservation_fi_metrics = income_preservation_fi_metrics.rename(columns=ticker_to_mb_mapping)\n",
        "  income_preservation_fi_metrics.T[['YTM / est. yield']]\n",
        "\n",
        "  income_pres_portfolios = all_portfolios_summary[all_portfolios_summary['L1_classification']=='Income & Preservation']\n",
        "  income_pres_portfolios = pd.merge(income_pres_portfolios, income_preservation_fi_metrics.T[['YTM / est. yield']], left_on='Portfolio Type', right_index=True, how='left')\n",
        "  income_pres_portfolios['Est. Yield (%)'] = income_pres_portfolios.apply(lambda row: row['YTM / est. yield'] if row['Portfolio Type'] != 'CASH_PLUS_GUARANTEED_SGD' else row['Guaranteed rate'], axis=1)\n",
        "  income_pres_portfolios = income_pres_portfolios.drop(columns=['YTM / est. yield', 'Guaranteed rate'])\n",
        "\n",
        "  # Ensure correct data types\n",
        "  income_pres_portfolios['Allocation'] = pd.to_numeric(income_pres_portfolios['Value (SGD)'], errors='coerce') / income_pres_portfolios['Value (SGD)'].sum()\n",
        "  income_pres_portfolios['Est. Yield (%)'] = pd.to_numeric(income_pres_portfolios['Est. Yield (%)'], errors='coerce')\n",
        "  income_pres_portfolios['Allocation'] = pd.to_numeric(income_pres_portfolios['Allocation'], errors='coerce')\n",
        "  income_pres_portfolios['Proj. Dividend (SGD)'] = income_pres_portfolios['Est. Yield (%)'] / 100 * income_pres_portfolios['Value (SGD)']\n",
        "\n",
        "  # Calculate subtotals\n",
        "  income_plus_subtotal = calculate_subtotal_income_preservation(income_pres_portfolios, 'Income+')\n",
        "  reits_subtotal = calculate_subtotal_income_preservation(income_pres_portfolios, 'REITs')\n",
        "  alt_subtotal = calculate_subtotal_income_preservation(income_pres_portfolios, 'Alternatives')\n",
        "  cash_mmf_subtotal = calculate_subtotal_income_preservation(income_pres_portfolios, 'Cash / MMF')\n",
        "\n",
        "  income_pres_portfolios['Est. Yield (%)'] = pd.to_numeric(income_pres_portfolios['Est. Yield (%)'], errors='coerce')\n",
        "  income_pres_portfolios['Proj. Dividend (SGD)'] = pd.to_numeric(income_pres_portfolios['Proj. Dividend (SGD)'], errors='coerce')\n",
        "\n",
        "  total_row_income_pres = pd.DataFrame({\n",
        "      col: [\n",
        "          # Sum numeric columns\n",
        "          income_pres_portfolios[col].sum() if col in ['Value (SGD)', 'Value (USD)', 'Invested Amount', 'P&L since inception', 'Dividend (SGD)', 'Allocation', 'Proj. Dividend (SGD)'] else\n",
        "          # Calculate weighted average for Yield (%) column safely\n",
        "          ((income_pres_portfolios[col] * income_pres_portfolios['Allocation']).sum() / income_pres_portfolios['Allocation'].sum())\n",
        "          if col == 'Est. Yield (%)' and income_pres_portfolios['Allocation'].sum() != 0 else\n",
        "          ''  # Keep other columns empty\n",
        "      ] for col in income_pres_portfolios.columns\n",
        "  }, index=['Total'])\n",
        "\n",
        "  total_row_income_pres.iloc[0, 0] = 'Total'\n",
        "\n",
        "  if total_row_income_pres['Value (SGD)'].values[0] > 0:  # Check if NAV (SGD) is greater than 0\n",
        "      income_pres_portfolios = pd.concat([income_pres_portfolios, total_row_income_pres])\n",
        "\n",
        "  income_pres_portfolios['Portfolio Type'] = pd.Categorical(\n",
        "      income_pres_portfolios['Portfolio Type'],\n",
        "      categories=order_of_ports,\n",
        "      ordered=True\n",
        "  )\n",
        "\n",
        "  # Sort the DataFrame\n",
        "  income_pres_portfolios = income_pres_portfolios.sort_values(by='Portfolio Type').reset_index(drop=True)\n",
        "  income_plus_rows = income_pres_portfolios[income_pres_portfolios['L2_classification'] == 'Income+']\n",
        "  reits_rows = income_pres_portfolios[income_pres_portfolios['L2_classification'] == 'REITs']\n",
        "  alt_rows = income_pres_portfolios[income_pres_portfolios['L2_classification'] == 'Alternatives']\n",
        "  cm_rows = income_pres_portfolios[income_pres_portfolios['L2_classification'] == 'Cash / MMF']\n",
        "  others_rows = income_pres_portfolios[~income_pres_portfolios['L2_classification'].isin(['Income+', 'REITs', 'Alternatives', 'Cash / MMF'])]\n",
        "\n",
        "\n",
        "  # income_pres_portfolios = pd.concat([income_plus_rows, income_plus_subtotal.to_frame().T, reits_rows, reits_subtotal.to_frame().T, cm_rows, cash_mmf_subtotal.to_frame().T, total_row_income_pres])\n",
        "\n",
        "  income_pres_portfolios_list = []  # Start with an empty list\n",
        "  income_pres_portfolios_list.append(income_plus_rows)\n",
        "\n",
        "  if income_plus_rows['Value (SGD)'].sum() != 0:\n",
        "      income_pres_portfolios_list.append(income_plus_subtotal.to_frame().T)\n",
        "\n",
        "  income_pres_portfolios_list.append(reits_rows)\n",
        "\n",
        "  if reits_rows['Value (SGD)'].sum() != 0:\n",
        "      income_pres_portfolios_list.append(reits_subtotal.to_frame().T)\n",
        "\n",
        "  income_pres_portfolios_list.append(alt_rows)\n",
        "\n",
        "  if alt_rows['Value (SGD)'].sum() != 0:\n",
        "      income_pres_portfolios_list.append(alt_subtotal.to_frame().T)\n",
        "\n",
        "  income_pres_portfolios_list.append(cm_rows)\n",
        "\n",
        "  if cm_rows['Value (SGD)'].sum() != 0:\n",
        "      income_pres_portfolios_list.append(cash_mmf_subtotal.to_frame().T)\n",
        "\n",
        "  income_pres_portfolios_list.append(total_row_income_pres)\n",
        "\n",
        "  # Concatenate the list of DataFrames\n",
        "  income_pres_portfolios = pd.concat(income_pres_portfolios_list)\n",
        "\n",
        "  income_pres_portfolios[['Value (SGD)', 'Value (USD)', 'Est. Yield (%)', 'Dividend (SGD)', 'Proj. Dividend (SGD)']] = income_pres_portfolios[['Value (SGD)', 'Value (USD)', 'Est. Yield (%)', 'Dividend (SGD)', 'Proj. Dividend (SGD)']].applymap(lambda x: \"{:,.2f}\".format(x) if isinstance(x, (int, float)) else x)\n",
        "  income_pres_portfolios['Allocation'] = (income_pres_portfolios['Allocation'] * 100).map('{:.2f}%'.format)\n",
        "\n",
        "  for col in income_pres_portfolios.columns:\n",
        "      if pd.api.types.is_categorical_dtype(income_pres_portfolios[col]):\n",
        "          # Add an empty string to the categories\n",
        "          income_pres_portfolios[col] = income_pres_portfolios[col].cat.add_categories([''])\n",
        "          # Fill NaN with the empty string\n",
        "          income_pres_portfolios[col] = income_pres_portfolios[col].fillna('')\n",
        "\n",
        "      elif income_pres_portfolios[col].dtype == 'object':  # For string columns\n",
        "          income_pres_portfolios[col] = income_pres_portfolios[col].fillna('')\n",
        "\n",
        "      else:  # For numeric columns\n",
        "          income_pres_portfolios[col] = income_pres_portfolios[col].fillna(0)\n",
        "\n",
        "  income_pres_portfolios['Dividend Option adj'] = income_pres_portfolios.apply(dividend_option_adj, axis=1)\n",
        "  income_pres_portfolios.drop(columns=['Dividend Option'], inplace=True)\n",
        "\n",
        "  # Apply the function to the 'Maturity Period' column\n",
        "  income_pres_portfolios['Maturity period'] = income_pres_portfolios['Maturity period'].apply(format_maturity_period)\n",
        "\n",
        "  income_pres_portfolios = income_pres_portfolios[['Portfolio ID', 'internal_port_name', 'Value (SGD)', 'Value (USD)', 'Est. Yield (%)', 'Proj. Dividend (SGD)', 'Dividend Option adj','Maturity period', 'Allocation']]\n",
        "  income_pres_portfolios.rename(columns={'internal_port_name': 'Portfolio Type', 'Est. Yield (%)':'Est. Yield (%)*', 'Proj. Dividend (SGD)':'Proj. Dividend (SGD)**', 'Dividend Option adj':'Dividend Option'}, inplace=True)\n",
        "\n",
        "  ###################################################################################################################################################################################################\n",
        "\n",
        "  # GENERATE PDF\n",
        "\n",
        "  client_name = 'CLIENT NAME'\n",
        "  template_pdf = PyPDF2.PdfReader(data_path + 'Portfolio_Visualiser_Template_Landscape.pdf')\n",
        "\n",
        "  # if client_latest_alloc[i][client_latest_alloc[i].index.isin(growth_groups)].empty == False:\n",
        "  #   growth_breakdown_chart = plot_sunburst_chart_growth(client_latest_alloc[i][client_latest_alloc[i].index.isin(growth_groups)], title='Growth Allocation')\n",
        "\n",
        "  # if client_latest_alloc[i][client_latest_alloc[i].index.isin(income_preservation_groups)].empty == False:\n",
        "  #   income_pres_breakdown_chart = plot_sunburst_chart_income_preservation(client_latest_alloc[i][client_latest_alloc[i].index.isin(income_preservation_groups)],\n",
        "  #                                                               title='Income & Preservation Allocation')\n",
        "  # if client_latest_alloc[i][client_latest_alloc[i].index.isin(income_preservation_groups)].empty == False and client_latest_alloc[i][client_latest_alloc[i].index.isin(growth_groups)].empty == False:\n",
        "  #   growth_income_breakdown_chart = plot_sunburst_chart_growth_income(client_latest_alloc[i], title='Growth & Income Allocation')\n",
        "\n",
        "  top_asset_class_chart_all = plot_pie_chart_topX(assetclass_breakdown_all.iloc[:, 0], title='Asset Class Exposure', colors=syfe_colors)\n",
        "  top_asset_class_chart_growth = plot_pie_chart_topX(assetclass_breakdown_growth.iloc[:, 0], title='Asset Class Exposure', colors=syfe_colors)\n",
        "  top_asset_class_chart_income_preservation = plot_pie_chart_topX(assetclass_breakdown_income_preservation.iloc[:, 0], title='Asset Class Exposure', colors=syfe_colors)\n",
        "\n",
        "  top_country_chart_all = plot_bar_chart_topX(country_breakdown_all.iloc[:, 0], title=\"Country Exposure\",  colors=syfe_colors)\n",
        "  top_country_chart_growth = plot_bar_chart_topX(country_breakdown_growth.iloc[:, 0], title=\"Country Exposure\",  colors=syfe_colors)\n",
        "  top_country_chart_income_preservation = plot_bar_chart_topX(country_breakdown_income_preservation.iloc[:, 0], title=\"Country Exposure\",  colors=syfe_colors)\n",
        "\n",
        "  top_sector_chart_growth = plot_bar_chart_topX(sector_breakdown_growth.iloc[:, 0], title=\"Sector Exposure\",  colors=syfe_colors)\n",
        "  top_sector_chart_income_preservation = plot_bar_chart_topX(sector_breakdown_income_preservation.iloc[:, 0], title=\"Sector Exposure\", colors=syfe_colors)\n",
        "\n",
        "  # CREATE INDIVIDUAL PDF & MERGE PDFS\n",
        "  # Assuming you have your table DataFrame, title, and chart variables\n",
        "  create_pdf_with_table_and_charts(\"portfolio_summary.pdf\", all_portfolios_summary_final, \"Portfolio Summary\",[top_asset_class_chart_all, top_country_chart_all],\n",
        "                                  col_width_manual=[145, 125, 70, 110, 90, 90, 90, 69.7])\n",
        "\n",
        "  if not growth_portfolios.empty:\n",
        "      create_pdf_with_table_and_charts(\"growth_portfolios.pdf\", growth_portfolios, \"Growth Portfolios\", [top_asset_class_chart_growth, top_country_chart_growth, top_sector_chart_growth])\n",
        "\n",
        "  if not income_pres_portfolios.empty:\n",
        "      create_pdf_with_table_and_charts(\"income_preservation_portfolios.pdf\", income_pres_portfolios, \"Income & Preservation Portfolios\",\n",
        "                                      [top_asset_class_chart_income_preservation , top_country_chart_income_preservation, top_sector_chart_income_preservation],\n",
        "                                      col_width_manual=[93, 120, 80, 80, 80, 100, 90, 100, 50])\n",
        "\n",
        "  # Merge PDFs\n",
        "  appendix_pdf = PyPDF2.PdfReader(data_path + 'Portfolio_Visualiser_Appendix.pdf')\n",
        "\n",
        "  merger = PdfMerger()\n",
        "  merger.append(\"portfolio_summary.pdf\")\n",
        "  if not growth_portfolios.empty:\n",
        "      merger.append(\"growth_portfolios.pdf\")\n",
        "  if not income_pres_portfolios.empty:\n",
        "      merger.append(\"income_preservation_portfolios.pdf\")\n",
        "  merger.write(str(client_id) + \"_report_merged.pdf\")\n",
        "\n",
        "  # Paths\n",
        "  template_pdf_path = os.path.join(data_path, \"Portfolio_Visualiser_Template_Landscape.pdf\")\n",
        "  cover_pdf_path = os.path.join(data_path, \"Portfolio_Visualiser_Cover.pdf\")\n",
        "  overlay_pdf_path = os.path.join('/content/Projects/' + str(client_id) + '_report_merged.pdf')\n",
        "  output_pdf_path = os.path.join('/content/Projects/' + str(client_id) + '_report_final.pdf')\n",
        "\n",
        "  # Merge overlay onto the template PDF\n",
        "  merge_with_template(template_pdf_path, overlay_pdf_path, output_pdf_path)\n",
        "\n",
        "  merger = PdfMerger()\n",
        "  merger.append(output_pdf_path)\n",
        "  # merger.append(appendix_pdf)\n",
        "  merger.write(output_pdf_path)\n",
        "\n",
        "  add_page_numbers_header(output_pdf_path, output_pdf_path, client_name=client_name)\n",
        "  merger = PdfMerger()\n",
        "  merger.append(cover_pdf_path)\n",
        "  merger.append(output_pdf_path)\n",
        "  merger.write(output_pdf_path)\n",
        "\n",
        "  files.download(output_pdf_path)\n",
        "\n",
        "  print(f\"Final report generated: {output_pdf_path}\")\n"
      ],
      "metadata": {
        "id": "zLO0ezPQDgZV",
        "outputId": "0388e425-027d-405d-dece-cb9ca493cb61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "id": "zLO0ezPQDgZV",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating report for  2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cfed1892-eb00-4cd1-9322-626f270026ea\", \"2_report_final.pdf\", 2677500)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final report generated: /content/Projects/2_report_final.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum([93, 120, 80, 80, 80, 100, 90, 100, 55])"
      ],
      "metadata": {
        "id": "ckRQv4kODSYd",
        "outputId": "e3ebbfb3-bed2-41ce-eb58-72345cee47d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ckRQv4kODSYd",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "798"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Archive\n",
        "\n",
        "# Func sunburst charts\n",
        "# Function to save charts to a single PDF\n",
        "\n",
        "from reportlab.lib.units import inch\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.units import inch\n",
        "from reportlab.lib.pagesizes import letter, A4, landscape\n",
        "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, BaseDocTemplate, Frame, PageTemplate, PageBreak\n",
        "from reportlab.lib import colors\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "from reportlab.lib.units import cm  # Import cm for specifying width in centimeters\n",
        "\n",
        "\n",
        "########################################################################################################################\n",
        "\n",
        "syfe_colors = ['#263159', '#2f51c9', '#879be3', '#bcbed7', '#dedfee','#fff2cc', '#ffe599', '#e3bf61', '#666666', '#7d839b', '#414e7d']\n",
        "\n",
        "def convert_maturity_period(value):\n",
        "    \"\"\"Converts maturity period values to the desired format, handling non-string values.\"\"\"\n",
        "    if isinstance(value, str):  # Check if value is a string\n",
        "        match = re.search(r'(\\w+)_MONTHS', value)\n",
        "        if match:\n",
        "            period_num = {\n",
        "                'THREE': '3',\n",
        "                'SIX': '6',\n",
        "                'TWELVE': '12'  # Add more mappings as needed\n",
        "            }.get(match.group(1))\n",
        "            if period_num:\n",
        "                return f\"{period_num} months\"\n",
        "    return value  # Return original value if not a string or no match\n",
        "\n",
        "def plot_sunburst_chart_MP(df_allocation, title=None, width=1000, height=600):\n",
        "    # Define groups\n",
        "    core_groups = ['Core E100', 'Core Growth', 'Core Balanced', 'Core Defensive', 'SRS E100']\n",
        "    specialised_groups = ['China Growth', 'Disruptive Tech', 'ESG & Clean Energy', 'Healthcare Innovation', 'Downside protected']\n",
        "    passive_income_groups = ['Income Enhance', 'Income Preserve', 'REIT 100', 'REIT RM', 'SRS Income Enhance', 'SRS Income Preserve']\n",
        "    custom_groups = ['CUSTOM_USD']\n",
        "\n",
        "    # Filter out rows with allocation <= 0.0001 or NaN\n",
        "    df_allocation = df_allocation[df_allocation != 0].dropna()\n",
        "\n",
        "    # Categorize portfolios\n",
        "    categories = []\n",
        "    for portfolio in df_allocation.index:\n",
        "        if portfolio in core_groups:\n",
        "            categories.append('Core')\n",
        "        elif portfolio in specialised_groups:\n",
        "            categories.append('Specialised')\n",
        "        elif portfolio in passive_income_groups:\n",
        "            categories.append('Passive Income')\n",
        "        elif portfolio in custom_groups:\n",
        "            categories.append('Custom')\n",
        "        else:\n",
        "            categories.append('Other')\n",
        "\n",
        "    # Dynamically create the list of unique categories based on the data\n",
        "    unique_categories = sorted(set(categories))  # Only include categories present in the data\n",
        "    labels = ['Portfolio Allocation'] + unique_categories + list(df_allocation.index)\n",
        "    parents = [''] + ['Portfolio Allocation'] * len(unique_categories) + categories\n",
        "\n",
        "    # Calculate values dynamically for existing categories\n",
        "    category_sums = []\n",
        "    for unique_cat in unique_categories:\n",
        "        category_sum = df_allocation.loc[\n",
        "            [portfolio for portfolio in df_allocation.index if\n",
        "             (portfolio in core_groups and unique_cat == 'Core') or\n",
        "             (portfolio in specialised_groups and unique_cat == 'Specialised') or\n",
        "             (portfolio in custom_groups and unique_cat == 'Custom') or\n",
        "             (portfolio in passive_income_groups and unique_cat == 'Passive Income')]\n",
        "        ].sum()\n",
        "        category_sums.append(category_sum)\n",
        "\n",
        "    values = [df_allocation.sum()] + category_sums + list(df_allocation.values)\n",
        "\n",
        "    # Filter out nodes where values <= 0\n",
        "    filtered_data = [\n",
        "        (label, parent, value) for label, parent, value in zip(labels, parents, values) if value > 0\n",
        "    ]\n",
        "    filtered_labels = [x[0] for x in filtered_data]\n",
        "    filtered_parents = [x[1] for x in filtered_data]\n",
        "    filtered_values = [x[2] for x in filtered_data]\n",
        "\n",
        "    # Create the sunburst chart\n",
        "    fig = go.Figure(go.Sunburst(\n",
        "        labels=filtered_labels,\n",
        "        parents=filtered_parents,\n",
        "        values=filtered_values,\n",
        "        branchvalues=\"total\",\n",
        "        textinfo=\"label+percent parent\",  # Include labels and percent for all nodes\n",
        "        insidetextorientation=\"horizontal\",\n",
        "    ))\n",
        "\n",
        "    # Customize traces\n",
        "    fig.update_traces(\n",
        "        texttemplate=[\n",
        "            \"%{label}<br>%{percentRoot:.2%}\" if parent != \"\" else \"\"\n",
        "            for parent in filtered_parents\n",
        "        ],\n",
        "        outsidetextfont={\"size\": 12, \"family\": \"Arial\"},\n",
        "        marker=dict(line=dict(width=0.5, color=\"white\"))\n",
        "    )\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        title_text=title,\n",
        "        margin=dict(t=50, l=0, r=0, b=0),\n",
        "        width=width,\n",
        "        height=height,\n",
        "        uniformtext=dict(minsize=10, mode='show')  # Uniform text size setting\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "\n",
        "def plot_sunburst_chart_MP_and_CM(df_allocation, title=None, width=1000, height=600):\n",
        "    # Define groups\n",
        "    core_groups = ['Core E100', 'Core Growth', 'Core Balanced', 'Core Defensive', 'SRS E100']\n",
        "    specialised_groups = ['China Growth', 'Disruptive Tech', 'ESG & Clean Energy', 'Healthcare Innovation', 'Downside protected']\n",
        "    passive_income_groups = ['Income Enhance', 'Income Preserve', 'REIT 100', 'REIT RM', 'SRS Income Enhance', 'SRS Income Preserve']\n",
        "    custom_groups = ['CUSTOM_USD']\n",
        "\n",
        "    mp_groups = core_groups + specialised_groups + passive_income_groups + custom_groups\n",
        "    cm_groups = ['Cash SGD flexi', 'Cash USD flexi', 'Cash SGD guaranteed']\n",
        "\n",
        "    # Filter out rows with allocation of 0 or NaN\n",
        "    df_allocation = df_allocation[df_allocation != 0].dropna()\n",
        "\n",
        "    # Categorize portfolios\n",
        "    categories = []\n",
        "    for portfolio in df_allocation.index:\n",
        "        if portfolio in mp_groups:\n",
        "            categories.append('Managed Portfolios')\n",
        "        elif portfolio in cm_groups:\n",
        "            categories.append('Cash Management')\n",
        "        else:\n",
        "            categories.append('Other')\n",
        "\n",
        "    # Create labels, parents, and values\n",
        "    unique_categories = ['Managed Portfolios', 'Cash Management']\n",
        "    labels = ['Portfolio Allocation'] + unique_categories + list(df_allocation.index)\n",
        "    parents = [''] + ['Portfolio Allocation'] * len(unique_categories) + categories\n",
        "\n",
        "    # Corrected calculation of values\n",
        "    category_sums = []\n",
        "    for unique_cat in unique_categories:\n",
        "        category_sum = df_allocation.loc[[portfolio for portfolio in df_allocation.index if portfolio in mp_groups and unique_cat == 'Managed Portfolios' or \\\n",
        "                                          portfolio in cm_groups and unique_cat == 'Cash Management']].sum()\n",
        "        category_sums.append(category_sum)\n",
        "\n",
        "    values = [df_allocation.sum()] + category_sums + list(df_allocation.values)\n",
        "\n",
        "    # Create the sunburst chart\n",
        "    fig = go.Figure(go.Sunburst(\n",
        "    labels=labels,\n",
        "    parents=parents,\n",
        "    values=values,\n",
        "    branchvalues=\"total\",\n",
        "    textinfo=\"label+percent parent\",  # Include labels and percent for all nodes\n",
        "    insidetextorientation=\"horizontal\",))\n",
        "\n",
        "    # Customize traces to hide the root node label\n",
        "    fig.update_traces(\n",
        "    texttemplate=[\n",
        "        \"%{label}<br>%{percentRoot:.2%}\" if parent != \"\" else \"\"\n",
        "        for parent in parents\n",
        "    ],\n",
        "    outsidetextfont={\"size\": 12},\n",
        "    marker=dict(line=dict(width=0.5, color=\"white\"))\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        title_text=title,\n",
        "        margin=dict(t=50, l=0, r=0, b=0),\n",
        "        width=width,\n",
        "        height=height,\n",
        "        uniformtext=dict(minsize=10, mode='show')  # Uniform text size setting\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "def plot_sunburst_chart_growth(df_allocation, title=None, width=1000, height=600):\n",
        "    # Define groups\n",
        "    core_groups = ['Core E100', 'Core Growth', 'Core Balanced', 'Core Defensive', 'SRS E100']\n",
        "    specialised_groups = ['China Growth', 'Disruptive Tech', 'ESG & Clean Energy', 'Healthcare Innovation', 'Downside protected', 'Custom USD']\n",
        "\n",
        "    # Filter out rows with allocation of 0 or NaN\n",
        "    df_allocation = df_allocation[df_allocation != 0].dropna()\n",
        "\n",
        "    # Categorize portfolios\n",
        "    categories = []\n",
        "    for portfolio in df_allocation.index:\n",
        "        if portfolio in core_groups:\n",
        "            categories.append('Core')\n",
        "        elif portfolio in specialised_groups:\n",
        "            categories.append('Specialised')\n",
        "        else:\n",
        "            categories.append('Other')\n",
        "\n",
        "    # Create labels, parents, and values\n",
        "    unique_categories = ['Core', 'Specialised']\n",
        "    labels = ['Portfolio Allocation'] + unique_categories + list(df_allocation.index)\n",
        "    parents = [''] + ['Portfolio Allocation'] * len(unique_categories) + categories\n",
        "\n",
        "    # Calculate category sums\n",
        "    category_sums = []\n",
        "    for unique_cat in unique_categories:\n",
        "        category_sum = df_allocation.loc[[portfolio for portfolio in df_allocation.index if portfolio in core_groups and unique_cat == 'Core' or \\\n",
        "                                          portfolio in specialised_groups and unique_cat == 'Specialised']].sum()\n",
        "        category_sums.append(category_sum)\n",
        "\n",
        "    values = [df_allocation.sum()] + category_sums + list(df_allocation.values)\n",
        "\n",
        "    # Filter nodes with values > 0\n",
        "    filtered_data = [\n",
        "        (label, parent, value) for label, parent, value in zip(labels, parents, values) if value > 0\n",
        "    ]\n",
        "    filtered_labels = [x[0] for x in filtered_data]\n",
        "    filtered_parents = [x[1] for x in filtered_data]\n",
        "    filtered_values = [x[2] for x in filtered_data]\n",
        "\n",
        "    # Create the sunburst chart\n",
        "    fig = go.Figure(go.Sunburst(\n",
        "        labels=filtered_labels,\n",
        "        parents=filtered_parents,\n",
        "        values=filtered_values,\n",
        "        branchvalues=\"total\",\n",
        "        textinfo=\"label+percent parent\",  # Include labels and percent for all nodes\n",
        "        insidetextorientation=\"horizontal\",\n",
        "    ))\n",
        "\n",
        "    # Customize traces to hide the root node label\n",
        "    fig.update_traces(\n",
        "        texttemplate=[\n",
        "            \"%{label}<br>%{percentRoot:.2%}\" if parent != \"\" else \"\"\n",
        "            for parent in filtered_parents\n",
        "        ],\n",
        "        outsidetextfont={\"size\": 12},\n",
        "        marker=dict(line=dict(width=0.5, color=\"white\"))\n",
        "    )\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        title_text=title,\n",
        "        margin=dict(t=50, l=0, r=0, b=0),\n",
        "        width=width,\n",
        "        height=height,\n",
        "        uniformtext=dict(minsize=10, mode='show')  # Uniform text size setting\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "def plot_sunburst_chart_income_preservation(df_allocation, title=None, width=1000, height=600):\n",
        "    # Define groups\n",
        "    income_groups = ['Income Enhance', 'Income Preserve', 'SRS Income Enhance', 'SRS Income Preserve']\n",
        "    reits_groups = ['REIT 100', 'REIT RM']\n",
        "    cm_groups = ['Cash SGD flexi', 'Cash USD flexi', 'Cash SGD guaranteed']\n",
        "\n",
        "    # Filter out rows with allocation of 0 or NaN\n",
        "    df_allocation = df_allocation[df_allocation != 0].dropna()\n",
        "\n",
        "    # Categorize portfolios\n",
        "    categories = []\n",
        "    for portfolio in df_allocation.index:\n",
        "        if portfolio in income_groups:\n",
        "            categories.append('Bonds')\n",
        "        elif portfolio in reits_groups:\n",
        "            categories.append('REITs')\n",
        "        elif portfolio in cm_groups:\n",
        "            categories.append('Cash / MMF')\n",
        "        else:\n",
        "            categories.append('Other')\n",
        "\n",
        "    # Create labels, parents, and values\n",
        "    unique_categories = ['Bonds', 'REITs', 'Cash / MMF']\n",
        "    labels = ['Portfolio Allocation'] + unique_categories + list(df_allocation.index)\n",
        "    parents = [''] + ['Portfolio Allocation'] * len(unique_categories) + categories\n",
        "\n",
        "    # Corrected calculation of values\n",
        "    category_sums = []\n",
        "    for unique_cat in unique_categories:\n",
        "        category_sum = df_allocation.loc[[portfolio for portfolio in df_allocation.index if portfolio in income_groups and unique_cat == 'Bonds' or\n",
        "                                          portfolio in reits_groups and unique_cat == 'REITs' or\n",
        "                                          portfolio in cm_groups and unique_cat == 'Cash / MMF']].sum()\n",
        "        category_sums.append(category_sum)\n",
        "\n",
        "    values = [df_allocation.sum()] + category_sums + list(df_allocation.values)\n",
        "\n",
        "    # Create the sunburst chart\n",
        "    fig = go.Figure(go.Sunburst(\n",
        "    labels=labels,\n",
        "    parents=parents,\n",
        "    values=values,\n",
        "    branchvalues=\"total\",\n",
        "    textinfo=\"label+percent parent\",  # Include labels and percent for all nodes\n",
        "    insidetextorientation=\"horizontal\",))\n",
        "\n",
        "    # Customize traces to hide the root node label\n",
        "    fig.update_traces(\n",
        "    texttemplate=[\n",
        "        \"%{label}<br>%{percentRoot:.2%}\" if parent != \"\" else \"\"\n",
        "        for parent in parents\n",
        "    ],\n",
        "    outsidetextfont={\"size\": 12},\n",
        "    marker=dict(line=dict(width=0.5, color=\"white\"))\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        title_text=title,\n",
        "        margin=dict(t=50, l=0, r=0, b=0),\n",
        "        width=width,\n",
        "        height=height,\n",
        "        uniformtext=dict(minsize=10, mode='show')  # Uniform text size setting\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "def plot_sunburst_chart_growth_income(df_allocation, title=None, width=1000, height=600):\n",
        "    # Define groups\n",
        "    growth_groups = ['Core E100', 'Core Growth', 'Core Balanced', 'Core Defensive','SRS E100', 'China Growth','Disruptive Tech', 'ESG & Clean Energy', 'Healthcare Innovation', 'Downside protected', 'Custom USD']\n",
        "    income_preservation_groups = ['Income Enhance', 'Income Preserve','REIT 100', 'REIT RM', 'SRS Income Enhance','SRS Income Preserve', 'Cash SGD flexi', 'Cash USD flexi', 'Cash SGD guaranteed']\n",
        "\n",
        "    # Filter out rows with allocation of 0 or NaN\n",
        "    df_allocation = df_allocation[df_allocation != 0].dropna()\n",
        "\n",
        "    # Categorize portfolios\n",
        "    categories = []\n",
        "    for portfolio in df_allocation.index:\n",
        "        if portfolio in growth_groups:\n",
        "            categories.append('Growth')\n",
        "        elif portfolio in income_preservation_groups:\n",
        "            categories.append('Income & Preservation')\n",
        "        else:\n",
        "            categories.append('Other')\n",
        "\n",
        "    # Create labels, parents, and values\n",
        "    unique_categories = ['Growth', 'Income & Preservation']\n",
        "    labels = ['Portfolio Allocation'] + unique_categories + list(df_allocation.index)\n",
        "    parents = [''] + ['Portfolio Allocation'] * len(unique_categories) + categories\n",
        "\n",
        "    # Corrected calculation of values\n",
        "    category_sums = []\n",
        "    for unique_cat in unique_categories:\n",
        "        category_sum = df_allocation.loc[[portfolio for portfolio in df_allocation.index if portfolio in growth_groups and unique_cat == 'Growth' or\n",
        "                                          portfolio in income_preservation_groups and unique_cat == 'Income & Preservation']].sum()\n",
        "        category_sums.append(category_sum)\n",
        "\n",
        "    values = [df_allocation.sum()] + category_sums + list(df_allocation.values)\n",
        "\n",
        "    # Create the sunburst chart\n",
        "    fig = go.Figure(go.Sunburst(\n",
        "    labels=labels,\n",
        "    parents=parents,\n",
        "    values=values,\n",
        "    branchvalues=\"total\",\n",
        "    textinfo=\"label+percent parent\",  # Include labels and percent for all nodes\n",
        "    insidetextorientation=\"horizontal\",))\n",
        "\n",
        "    # Customize traces to hide the root node label\n",
        "    fig.update_traces(\n",
        "    texttemplate=[\n",
        "        \"%{label}<br>%{percentRoot:.2%}\" if parent != \"\" else \"\"\n",
        "        for parent in parents\n",
        "    ],\n",
        "    outsidetextfont={\"size\": 12},\n",
        "    marker=dict(line=dict(width=0.5, color=\"white\"))\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        title_text=title,\n",
        "        margin=dict(t=50, l=0, r=0, b=0),\n",
        "        width=width,\n",
        "        height=height,\n",
        "        uniformtext=dict(minsize=10, mode='show')  # Uniform text size setting\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "\n",
        "# Fixed income metrics - duration, YTM, dividend yield, credit quality\n",
        "\n",
        "# # calc dividend of all constituents\n",
        "# dvd_breakdown_all = pc.exposure_analysis(client_latest_alloc_adj, df_fi_metrics.loc[['T12M dividend yield']].astype(float), latest_data=True)\n",
        "# dvd_breakdown_all = round(dvd_breakdown_all, 2)\n",
        "\n",
        "\n",
        "# # Duration, YTM and credit quality of FI components only\n",
        "# fixed_income_list = df_fi_metrics.columns[df_fi_metrics.iloc[df_fi_metrics.index.get_loc('YTM / est. yield')] != 0].tolist()\n",
        "# port_fi_metrics = pd.DataFrame()\n",
        "\n",
        "# ytm_duration_df = pc.exposure_analysis_mixed(client_latest_alloc_adj, df_fi_metrics.loc[['Duration', 'YTM / est. yield']].astype(float), fixed_income_list, latest_data=True)\n",
        "# port_fi_metrics = pd.concat([port_fi_metrics, ytm_duration_df], axis=1)\n",
        "# port_fi_metrics.loc['Credit rating'] = pc.calc_avg_credit_rating(client_latest_alloc_adj, df_fi_metrics.loc[['Credit rating']], latest_data=True)\n",
        "\n",
        "# # port_fi_metrics = pd.concat([port_fi_metrics, df_fi_metrics.loc[['Duration', 'YTM / est. yield', 'Credit rating']][bm_tickers]], axis=1)\n",
        "# port_fi_metrics = pd.concat([port_fi_metrics, dvd_breakdown_all], axis=0)\n",
        "# port_fi_metrics"
      ],
      "metadata": {
        "cellView": "form",
        "id": "E6zglWkVSj3o"
      },
      "id": "E6zglWkVSj3o",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "537e41ac51d548aaa7aba726d0c9119d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1edc1e9ccbc4662bdc33261fb184d9d",
            "placeholder": "​",
            "style": "IPY_MODEL_72e8749f4b494301a99eb6bc3b4244b4",
            "value": "<div style='font-family: Arial, sans-serif; font-weight: bold;'>Upload client holdings from <a href=\"https://metabase.internal.syfe.com/question/1470-find-clients-portfolios-by-email?email=&portfolio_id=&client_id=&phone=&source_of_funds=\" target=\"_blank\">Metabase</a></div>"
          }
        },
        "a1edc1e9ccbc4662bdc33261fb184d9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72e8749f4b494301a99eb6bc3b4244b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a981b0a660de4726925e8fc39286d72a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 1,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": "*",
            "button_style": "",
            "data": [
              null
            ],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_89243d96db9541f8a079f56b62e6d27f",
            "metadata": [
              {
                "name": "Client_2_PV.csv",
                "type": "text/csv",
                "size": 4765,
                "lastModified": 1739159706878
              }
            ],
            "multiple": false,
            "style": "IPY_MODEL_60c326786da54d61befd08cdc05d6108"
          }
        },
        "89243d96db9541f8a079f56b62e6d27f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c326786da54d61befd08cdc05d6108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}