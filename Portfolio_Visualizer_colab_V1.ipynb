{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielanatalia/PortfolioVisualizer/blob/main/Portfolio_Visualizer_colab_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d215e46-b6fa-4abf-b6b4-2653cfaa0aac",
      "metadata": {
        "id": "6d215e46-b6fa-4abf-b6b4-2653cfaa0aac"
      },
      "source": [
        "# **Portfolio Visualizer**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5f9942a9-bdca-4745-a748-8d9d4300533d",
      "metadata": {
        "id": "5f9942a9-bdca-4745-a748-8d9d4300533d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd0f7f1-cbd4-432e-e357-b28f4367597d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting reportlab\n",
            "  Downloading reportlab-4.3.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from reportlab) (11.1.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from reportlab) (5.2.0)\n",
            "Downloading reportlab-4.3.1-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: reportlab\n",
            "Successfully installed reportlab-4.3.1\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\n",
            "Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kaleido\n",
            "Successfully installed kaleido-0.2.1\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Cloning into 'Projects'...\n",
            "remote: Enumerating objects: 618, done.\u001b[K\n",
            "remote: Counting objects: 100% (157/157), done.\u001b[K\n",
            "remote: Compressing objects: 100% (115/115), done.\u001b[K\n",
            "remote: Total 618 (delta 106), reused 42 (delta 42), pack-reused 461 (from 1)\u001b[K\n",
            "Receiving objects: 100% (618/618), 40.60 MiB | 20.97 MiB/s, done.\n",
            "Resolving deltas: 100% (366/366), done.\n",
            "/content/Projects\n"
          ]
        }
      ],
      "source": [
        "# @title 1. Load libraries and functions\n",
        "!pip install reportlab\n",
        "!pip install kaleido\n",
        "!pip install PyPDF2\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math, os, io, time, pytz, re, copy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import date, timedelta\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import norm\n",
        "from scipy.optimize import minimize, fsolve\n",
        "import itertools\n",
        "import plotly.graph_objects as go\n",
        "import yfinance as yf\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import matplotlib.cm as cm\n",
        "from matplotlib.colors import ListedColormap\n",
        "from matplotlib import colors\n",
        "import statsmodels.formula.api as smf\n",
        "from dateutil.parser import parse\n",
        "from datetime import datetime, timedelta\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML, Javascript\n",
        "from ipywidgets import VBox, HBox, Label, HTML\n",
        "from google.colab import widgets as gc_widgets\n",
        "from contextlib import redirect_stdout\n",
        "from google.colab import files\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.units import inch\n",
        "from IPython.display import FileLink\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import PyPDF2\n",
        "from PyPDF2 import PdfMerger, PdfReader, PdfWriter\n",
        "from reportlab.pdfbase.ttfonts import TTFont\n",
        "from reportlab.pdfbase import pdfmetrics\n",
        "\n",
        "!git clone https://github.com/gabrielanatalia/Projects/\n",
        "%cd /content/Projects\n",
        "import sys\n",
        "sys.path.append('/content/Projects')\n",
        "import port_cons as pc\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def convert_to_datetime(input_str, parserinfo=None):\n",
        "    return parse(input_str, parserinfo=parserinfo)\n",
        "\n",
        "TOLERANCE = 1e-10\n",
        "\n",
        "def _allocation_risk(weights, covariances):\n",
        "\n",
        "    portfolio_risk = np.sqrt((weights * covariances * weights.T))[0, 0]\n",
        "\n",
        "    return portfolio_risk\n",
        "\n",
        "def _assets_risk_contribution_to_allocation_risk(weights, covariances):\n",
        "\n",
        "    portfolio_risk = _allocation_risk(weights, covariances)\n",
        "\n",
        "    assets_risk_contribution = np.multiply(weights.T, covariances * weights.T) \\\n",
        "        / portfolio_risk\n",
        "\n",
        "    return assets_risk_contribution\n",
        "\n",
        "def _risk_budget_objective_error(weights, args):\n",
        "    covariances = args[0]\n",
        "    assets_risk_budget = args[1]\n",
        "    weights = np.matrix(weights)\n",
        "\n",
        "    portfolio_risk = _allocation_risk(weights, covariances)\n",
        "\n",
        "    assets_risk_contribution = \\\n",
        "        _assets_risk_contribution_to_allocation_risk(weights, covariances)\n",
        "\n",
        "    assets_risk_target = \\\n",
        "        np.asmatrix(np.multiply(portfolio_risk, assets_risk_budget))\n",
        "\n",
        "    error = sum(np.absolute(assets_risk_contribution - assets_risk_target.T))[0, 0]\n",
        "    return error\n",
        "\n",
        "def _get_risk_parity_weights(covariances, assets_risk_budget, initial_weights):\n",
        "\n",
        "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1.0},{'type': 'ineq', 'fun': lambda x: x})\n",
        "\n",
        "    optimize_result = minimize(fun=_risk_budget_objective_error,\n",
        "                               x0=initial_weights,\n",
        "                               args=[covariances, assets_risk_budget],\n",
        "                               method='SLSQP',\n",
        "                               constraints=constraints,\n",
        "                               tol=TOLERANCE,\n",
        "                               options={'disp': False})\n",
        "\n",
        "    weights = optimize_result.x\n",
        "    print(optimize_result.message)\n",
        "    return weights\n",
        "\n",
        "def rebal_wgt_riskparity(returns_data, start_date, end_date, rebal_months=[4,10], halflife=3.5, annualized=252, shrink_covar=False):\n",
        "    num_of_assets = len(returns_data.columns)\n",
        "\n",
        "    ret_data_filtered = returns_data.loc[start_date:end_date]\n",
        "    first_date = returns_data.index[0]\n",
        "    tickers = list(returns_data.columns)\n",
        "\n",
        "    weights = pd.DataFrame(0, index=ret_data_filtered.index, columns=ret_data_filtered.columns)\n",
        "    weights.index = pd.to_datetime(weights.index, format='%Y-%m-%d')\n",
        "    reb_flag = pd.DataFrame(0, index=weights.index, columns=['reb_flag'])\n",
        "\n",
        "    alpha = 1 - math.exp(math.log(0.5) / (halflife * annualized))\n",
        "    span = (2 / alpha) - 1\n",
        "\n",
        "    for i in range(len(ret_data_filtered)):\n",
        "        curr_date = ret_data_filtered.index[i]\n",
        "        curr_date_format = curr_date.strftime('%Y-%m-%d')\n",
        "\n",
        "        if (weights.index[i].month in rebal_months and weights.index[i-1].month != weights.index[i].month) or i==0:\n",
        "\n",
        "            if shrink_covar:\n",
        "                shrink_covar_matrix_model = LedoitWolf().fit(returns_data.loc[first_date:curr_date])\n",
        "                covar_ann = pd.DataFrame(shrink_covar_matrix_model.covariance_ * annualized, index=tickers, columns=tickers)\n",
        "                covar_ann.columns = tickers\n",
        "                covar_ann.index = tickers\n",
        "            else:\n",
        "                exp_cov_matrix = returns_data.loc[first_date:curr_date].ewm(span=span).cov(pairwise=True).iloc[-num_of_assets:]\n",
        "                covar_ann = exp_cov_matrix * annualized\n",
        "                covar_ann.columns = tickers\n",
        "                covar_ann.index = tickers\n",
        "\n",
        "            valid_covar_ann = covar_ann.dropna(how='all')\n",
        "            valid_covar_ann = valid_covar_ann.dropna(axis=1, how='all')\n",
        "            valid_num_assets = len(valid_covar_ann)\n",
        "            valid_tickers = valid_covar_ann.columns\n",
        "\n",
        "            assets_risk_budget = np.ones([valid_num_assets]) / valid_num_assets\n",
        "            initial_weights = np.ones([valid_num_assets]) / valid_num_assets\n",
        "\n",
        "            # print(valid_covar_ann)\n",
        "            new_wgt = _get_risk_parity_weights(valid_covar_ann.values, assets_risk_budget, initial_weights)\n",
        "            new_wgt = pd.DataFrame(new_wgt).T\n",
        "            new_wgt.columns = valid_tickers\n",
        "\n",
        "            for ticker in valid_tickers:\n",
        "                weights.at[curr_date_format, ticker] = new_wgt[ticker].values\n",
        "\n",
        "            reb_flag.loc[curr_date_format] = True\n",
        "\n",
        "        else:\n",
        "            weights.iloc[i] = weights.iloc[i-1] * (1+ ret_data_filtered.iloc[i].fillna(0))\n",
        "            weights_sum = weights.iloc[i].sum()\n",
        "            weights.iloc[i] /= weights_sum\n",
        "            reb_flag.iloc[i] = False\n",
        "\n",
        "    weights = weights.rename(columns={c: c + '_wgt' for c in weights.columns})\n",
        "    weights = pd.concat([reb_flag, weights], axis=1)\n",
        "\n",
        "    return weights\n",
        "\n",
        "def combine_backtest_data(portfolio_names):\n",
        "    # combined portfolio returns\n",
        "    all_port_ret = {}\n",
        "\n",
        "    for portfolio in portfolio_names:\n",
        "        perf_df = globals()[f\"{portfolio}_perf\"]\n",
        "        ret_col = [col for col in perf_df.columns if col.endswith('_port_ret')]\n",
        "        all_port_ret[portfolio] = perf_df[ret_col]\n",
        "\n",
        "    df_all_port_ret = pd.concat(all_port_ret.values(), keys=all_port_ret.keys(), axis=1)\n",
        "    df_all_port_ret.columns = [col[0] for col in df_all_port_ret.columns]\n",
        "\n",
        "    # combined portfolio weights\n",
        "    all_port_weights = {}\n",
        "\n",
        "    for portfolio in portfolio_names:\n",
        "        wgt_df = globals()[f\"{portfolio}_wgt\"]\n",
        "        # wgt_col = [col for col in wgt_df.columns if col.endswith('_wgt')]\n",
        "        # all_port_weights[portfolio] = wgt_df[wgt_col]\n",
        "        all_port_weights[portfolio] = wgt_df\n",
        "\n",
        "    df_all_port_weights = pd.concat(all_port_weights.values(), keys=all_port_weights.keys(), axis=1)\n",
        "\n",
        "    # combined portfolio backtest daata\n",
        "    all_port_bt = {}\n",
        "\n",
        "    for portfolio in portfolio_names:\n",
        "        bt_df = globals()[f\"{portfolio}_perf\"]\n",
        "        all_port_bt[portfolio] = bt_df\n",
        "\n",
        "    df_all_port_bt = pd.concat(all_port_bt.values(), keys=all_port_bt.keys(), axis=1)\n",
        "    return df_all_port_ret, df_all_port_weights, df_all_port_bt\n",
        "\n",
        "\n",
        "def print_arial(text):\n",
        "    display(HTML(f\"<div style='font-family: Arial, sans-serif'>{text}</div>\"))\n",
        "\n",
        "def print_arial_bold(text):\n",
        "    display(HTML(f\"<div style='font-family: Arial, sans-serif; font-weight: bold;'>{text}</div>\"))\n",
        "\n",
        "def merge_pdfs(existing_pdf, merged_pdf, output_pdf):\n",
        "    # Open the existing PDFs\n",
        "    with open(existing_pdf, \"rb\") as pdf1, open(merged_pdf, \"rb\") as pdf2:\n",
        "        reader1 = PyPDF2.PdfReader(pdf1)\n",
        "        reader2 = PyPDF2.PdfReader(pdf2)\n",
        "        writer = PyPDF2.PdfWriter()\n",
        "\n",
        "        # Add all pages from the first PDF\n",
        "        for page in reader1.pages:\n",
        "            writer.add_page(page)\n",
        "\n",
        "        # Add all pages from the second PDF\n",
        "        for page in reader2.pages:\n",
        "            writer.add_page(page)\n",
        "\n",
        "        # Save the merged PDF\n",
        "        with open(output_pdf, \"wb\") as output:\n",
        "            writer.write(output)\n",
        "\n",
        "def plot_pie_chart_topX(series, title, topX=10, width=1000, height=600, colors=None):\n",
        "    # Filter for values greater than 0\n",
        "    series = series[series > 0]\n",
        "\n",
        "    # Proceed only if there are values to plot\n",
        "    if not series.empty:\n",
        "        top_x = series.sort_values(ascending=False).head(topX)\n",
        "        other_sum = series.sum() - top_x.sum()\n",
        "\n",
        "        # Filter labels and values based on positive values\n",
        "        labels = list(top_x.index)\n",
        "        values = list(top_x)\n",
        "\n",
        "        # Add 'Others' only if other_sum is greater than 0\n",
        "        if other_sum > 0.01:\n",
        "            labels.append('Others')\n",
        "            values.append(other_sum)\n",
        "\n",
        "        # Create the Pie trace data\n",
        "        pie_data = {\n",
        "            'labels': labels,\n",
        "            'values': values,\n",
        "            'textinfo': 'label+percent',\n",
        "            'hole': 0.3,\n",
        "            'textposition': 'outside',\n",
        "        }\n",
        "\n",
        "        # Add marker with custom colors if provided\n",
        "        if colors:\n",
        "            pie_data['marker'] = dict(colors=colors)\n",
        "\n",
        "        fig = go.Figure(data=[go.Pie(**pie_data)])  # Unpack pie_data into go.Pie\n",
        "        fig.update_layout(title={'text': f'<b>{title}</b>','font': dict(size=75)}, width=width, height=height, showlegend=False, font=dict(family=\"Arial\", size=75, color='black'))\n",
        "        return fig\n",
        "    else:\n",
        "        print(\"No values greater than 0 to plot.\")\n",
        "        return None\n",
        "\n",
        "def plot_bar_chart_topX(series_list, title, topX=10, width=1000, height=600, colors=None, legend_names=[\"Client Portfolio\", \"Benchmark\"]):\n",
        "\n",
        "    fig = go.Figure()\n",
        "    legend_names = legend_names\n",
        "\n",
        "    for i, series in enumerate(series_list):\n",
        "        # Filter for values greater than 0\n",
        "        series = series[series > 0]\n",
        "\n",
        "        # Proceed only if there are values to plot\n",
        "        if not series.empty:\n",
        "            top_x = series.sort_values(ascending=False).head(topX)\n",
        "            other_sum = series.sum() - top_x.sum()\n",
        "\n",
        "            # Filter labels and values based on positive values\n",
        "            labels = list(top_x.index)\n",
        "            values = list(top_x)\n",
        "\n",
        "            # Add 'Others' only if other_sum is greater than 0\n",
        "            if other_sum > 0:\n",
        "                labels.append('Others')\n",
        "                values.append(other_sum)\n",
        "\n",
        "            # Calculate percentages and format labels\n",
        "            total_sum = sum(values)\n",
        "            text_labels = [f'{round(value / total_sum * 100, 2)}%' for value in values]  # Only percentage\n",
        "\n",
        "            # Create the Bar trace data\n",
        "            bar_data = go.Bar(\n",
        "                x=labels,\n",
        "                y=values,\n",
        "                text=text_labels,\n",
        "                textposition='auto',\n",
        "                textangle=0,\n",
        "                name=legend_names[i],  # Use legend names from the list\n",
        "                marker=dict(color=colors[i] if colors else None)  # Use custom color if provided\n",
        "            )\n",
        "\n",
        "            fig.add_trace(bar_data)  # Add the trace to the figure\n",
        "\n",
        "    fig.update_layout(\n",
        "        title={'text': f'<b>{title}</b>', 'font': dict(size=75)},\n",
        "        width=width,\n",
        "        height=height,\n",
        "        showlegend=True,  # Show legend for multiple series\n",
        "        yaxis_tickformat=\".0%\",\n",
        "        font=dict(family=\"Arial\", size=75, color='black'), legend=dict(x=0.95, y=0.95, xanchor='right', yanchor='top', bgcolor='rgba(0,0,0,0)')\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def calc_custom_weighted_risk_rating(custom_usd_rows, df_sec_list):\n",
        "    # Calculates the weighted risk rating of custom USD portfolios\n",
        "\n",
        "    # Merge risk ratings from security list\n",
        "    custom_usd_risk_rating = custom_usd_rows.copy()\n",
        "    custom_usd_risk_rating = custom_usd_risk_rating.merge(\n",
        "        df_sec_list[['Ticker', 'Risk rating']], how='left', left_on='type', right_on='Ticker'\n",
        "    )\n",
        "\n",
        "    # Calculate weighted risk rating and NAV in SGD\n",
        "    custom_usd_risk_rating_weighted_avg = custom_usd_risk_rating.groupby('portfolio_id').apply(\n",
        "        lambda x: pd.Series({\n",
        "            'Risk rating': np.average(x['Risk rating'], weights=x['nav_in_sgd']),\n",
        "        })\n",
        "    ).reset_index()\n",
        "\n",
        "    return custom_usd_risk_rating_weighted_avg\n",
        "\n",
        "########################################################################################################################\n",
        "\n",
        "# read asseet class, sector, country data from csv\n",
        "data_path = '/content/Projects/Data/'\n",
        "df_sec_list = pd.read_csv(data_path + 'PV_sec_list.csv')\n",
        "df_sec_list['Remarks'] = df_sec_list['Remarks'].fillna('N/A')\n",
        "df_asset_class = pd.read_csv(data_path + 'PV_asset_class.csv', index_col=0)\n",
        "df_sector = pd.read_csv(data_path + 'PV_sector.csv', index_col=0)\n",
        "df_country = pd.read_csv(data_path + 'PV_country.csv', index_col=0)\n",
        "df_fi_metrics = pd.read_csv(data_path + 'PV_FI_metrics.csv', index_col=0)\n",
        "df_fx = pd.read_csv(data_path + 'PV_daily_ret.csv',header=0, index_col='Date', parse_dates=['Date'],dayfirst=True)[['USDSGD', 'USDHKD']]/100\n",
        "\n",
        "pdfmetrics.registerFont(TTFont('ProximaNovaBold', \"/content/Projects/Data/ProximaNova-Bold.ttf\"))\n",
        "pdfmetrics.registerFont(TTFont('ProximaNovaRegular', \"/content/Projects/Data/ProximaNova-Regular.ttf\"))\n",
        "\n",
        "syfe_colors = ['#263159', '#2f51c9', '#879be3', '#bcbed7', '#dedfee','#fff2cc', '#ffe599', '#e3bf61', '#666666', '#7d839b', '#414e7d']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title PDF Funcs\n",
        "from reportlab.lib.styles import ParagraphStyle\n",
        "from reportlab.lib.pagesizes import landscape, A4\n",
        "from reportlab.lib import colors\n",
        "from reportlab.lib.units import inch\n",
        "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Spacer, Image, Paragraph\n",
        "import os\n",
        "\n",
        "\n",
        "def create_table(df, title):\n",
        "    header_style = ParagraphStyle(\n",
        "        name=\"TableHeader\",\n",
        "        fontName=\"ProximaNovaBold\",\n",
        "        fontSize=8,\n",
        "        leading=9,  # Adjust line spacing\n",
        "        alignment=1,  # Center align\n",
        "    )\n",
        "\n",
        "    elements = []\n",
        "\n",
        "    if df.empty:\n",
        "        return elements\n",
        "    else:\n",
        "\n",
        "        # Wrap \"Ann. Proj. Dividend (SGD)\" header text\n",
        "        column_headers = [\n",
        "            Paragraph(col.replace(\"Ann. Proj. Dividend (SGD)**\", \"Ann. Proj.<br/>Dividend (SGD)**\"), header_style)\n",
        "            for col in df.columns\n",
        "        ]\n",
        "\n",
        "        table_data = [df.columns.tolist()]  # Add header row\n",
        "        for _, row in df.iterrows():\n",
        "            table_data.append(list(row))\n",
        "\n",
        "        table = Table(table_data)\n",
        "        table_style = TableStyle(\n",
        "            [\n",
        "                (\"BACKGROUND\", (0, 0), (-1, 0), colors.HexColor(\"#263159\")),\n",
        "                (\"TEXTCOLOR\", (0, 0), (-1, 0), colors.whitesmoke),\n",
        "                (\"ALIGN\", (0, 0), (-1, -1), \"CENTER\"),\n",
        "                (\"FONTNAME\", (0, 0), (-1, 0), \"ProximaNovaBold\"),\n",
        "                (\"FONTSIZE\", (0, 0), (-1, 0), 8),\n",
        "                (\"BOTTOMPADDING\", (0, 0), (-1, 0), 2),\n",
        "                (\"TOPPADDING\", (0, 0), (-1, 0), 2),\n",
        "                (\"BOTTOMPADDING\", (0, 1), (-1, -1), 1),\n",
        "                (\"TOPPADDING\", (0, 1), (-1, -1), 1),\n",
        "                (\"BACKGROUND\", (0, 1), (-1, -1), colors.whitesmoke),\n",
        "                (\"TEXTCOLOR\", (0, 1), (-1, -1), colors.black),\n",
        "                (\"FONTNAME\", (0, 1), (-1, -1), \"ProximaNovaRegular\"),\n",
        "                (\"FONTSIZE\", (0, 1), (-1, -1), 8),\n",
        "                (\"VALIGN\", (0, 0), (-1, -1), \"TOP\"),\n",
        "                (\"ROWBACKGROUNDS\", (0, 1), (-1, -1), [colors.whitesmoke, colors.lightgrey]),\n",
        "                (\"FONTNAME\", (0, -1), (-1, -1), \"ProximaNovaBold\"),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        for col_index, col_name in enumerate(df.columns):\n",
        "            if col_name in [\"Value (SGD)\", \"Ann. Proj. Dividend (SGD)**\"]:\n",
        "                table_style.add(\"ALIGN\", (col_index, 0), (col_index, -1), \"RIGHT\")\n",
        "\n",
        "        for i in range(len(df)):  # Iterate using numerical index\n",
        "              if df.iloc[i]['Portfolio ID'] in ['Growth Portfolios', 'Income & Preservation Portfolios', \"Core\", \"Specialised\", \"Income+\", \"REITs\", \"Alternatives\",\"Cash / MMF\"]:\n",
        "                  table_style.add(\"BACKGROUND\", (0, i + 1), (-1, i + 1), colors.HexColor(\"#879be4\"))\n",
        "\n",
        "        table.setStyle(table_style)\n",
        "\n",
        "        custom_title_style = ParagraphStyle(\n",
        "            name=\"CustomTitle\",\n",
        "            fontName=\"ProximaNovaBold\",\n",
        "            fontSize=12,\n",
        "            leading=12,  # Line height\n",
        "            alignment=0,  # Left align\n",
        "        )\n",
        "\n",
        "        # Update the title line in your function\n",
        "        elements.append(Spacer(1, 0.3 * inch))\n",
        "        elements.append(Paragraph(f\"{title}\", custom_title_style))\n",
        "        elements.append(Spacer(1, 0.2 * inch))  # Reduced space after the title\n",
        "        elements.append(table)\n",
        "\n",
        "    return elements\n",
        "\n",
        "def add_page_numbers_header(input_pdf, output_pdf, client_name, client_id, page_size=landscape(A4)):\n",
        "    page_width, page_height = page_size\n",
        "\n",
        "    reader = PdfReader(input_pdf)\n",
        "    writer = PdfWriter()\n",
        "    total_pages = len(reader.pages)\n",
        "\n",
        "    for page_num, page in enumerate(reader.pages, start=1):\n",
        "        packet = io.BytesIO()\n",
        "        can = canvas.Canvas(packet, pagesize=page_size)\n",
        "        can.setFont(\"ProximaNovaRegular\", 8)\n",
        "\n",
        "        # Add page number to bottom-right corner\n",
        "        page_number_text = f\"Page {page_num} of {total_pages}\"\n",
        "        text_width = can.stringWidth(page_number_text, \"ProximaNovaRegular\", 8)\n",
        "        x_position = page_width - 20 - text_width\n",
        "        y_position = 10\n",
        "        can.drawString(x_position, y_position, page_number_text)\n",
        "\n",
        "        # FOR INTERNAL PURPOSES ONLY V1 (in red, bottom left corner)\n",
        "        internal_text = \"[FOR INTERNAL PURPOSES ONLY - V1]\"\n",
        "        can.setFont(\"ProximaNovaRegular\", 8)  # Set font to ProximaNovaRegular, size 8\n",
        "        can.drawString(20, 10, internal_text)  # 20 units from left, 10 units from bottom\n",
        "\n",
        "        # Add header to upper right-hand corner (same as before)\n",
        "        header_x = page_width - 20  # Start from the right edge\n",
        "\n",
        "        # Client Name\n",
        "        client_name_text = f\"Client Name: {client_name}\"\n",
        "        client_name_width = can.stringWidth(client_name_text, \"ProximaNovaRegular\", 8)\n",
        "        can.drawString(header_x - client_name_width, page_height - 20, client_name_text)  # Calculate x for right alignment\n",
        "\n",
        "        # Client ID\n",
        "        client_id_text = f\"Client ID: {client_id}\"\n",
        "        client_name_width = can.stringWidth(client_name_text, \"ProximaNovaRegular\", 8)\n",
        "        can.drawString(header_x - client_name_width, page_height - 20, client_name_text)  # Calculate x for right alignment\n",
        "\n",
        "        # Date\n",
        "        date_text = f\"Date: {datetime.now().strftime('%B %d, %Y')}\"\n",
        "        date_width = can.stringWidth(date_text, \"ProximaNovaRegular\", 8)\n",
        "        can.drawString(header_x - date_width, page_height - 30, date_text)  # Calculate x for right alignment\n",
        "\n",
        "        can.save()\n",
        "\n",
        "        packet.seek(0)\n",
        "        page_overlay = PdfReader(packet)\n",
        "        page.merge_page(page_overlay.pages[0])\n",
        "        writer.add_page(page)\n",
        "\n",
        "    with open(output_pdf, \"wb\") as f:\n",
        "        writer.write(f)\n",
        "\n",
        "def merge_with_template(template_pdf_path, overlay_pdf_path, output_pdf_path):\n",
        "    \"\"\"Merges multiple overlay pages onto a single-page template, repeating the template as needed.\"\"\"\n",
        "\n",
        "    template_pdf = PdfReader(template_pdf_path)\n",
        "    overlay_pdf = PdfReader(overlay_pdf_path)\n",
        "    output_pdf = PdfWriter()\n",
        "\n",
        "    template_page = template_pdf.pages[0]  # Since the template has only 1 page\n",
        "\n",
        "    for page_num in range(len(overlay_pdf.pages)):\n",
        "        overlay_page = overlay_pdf.pages[page_num]\n",
        "\n",
        "        # Copy the template so it doesn't get modified\n",
        "        template_copy = template_page.create_blank_page(\n",
        "            width=template_page.mediabox[2], height=template_page.mediabox[3]\n",
        "        )\n",
        "        template_copy.merge_page(template_page)  # Copy original template\n",
        "        template_copy.merge_page(overlay_page)  # Overlay the new content\n",
        "\n",
        "        output_pdf.add_page(template_copy)\n",
        "\n",
        "    # Write final merged PDF\n",
        "    with open(output_pdf_path, \"wb\") as final_pdf:\n",
        "        output_pdf.write(final_pdf)\n",
        "\n",
        "def create_pdf_with_table_and_charts(output_file, table_df, table_title, charts, col_width_manual=None):\n",
        "    elements = []\n",
        "    temp_images = []  # Track temporary image files for cleanup\n",
        "\n",
        "    # Create PDF document\n",
        "    doc = SimpleDocTemplate(\n",
        "        output_file,\n",
        "        pagesize=landscape(A4),\n",
        "        leftMargin=0.4 * inch,  # Adjust left margin\n",
        "        rightMargin=0.3 * inch,  # Adjust right margin\n",
        "        topMargin=0.6 * inch,  # Adjust top margin\n",
        "        bottomMargin=0.2 * inch  # Adjust bottom margin\n",
        "    )\n",
        "\n",
        "    # Calculate available width for table\n",
        "    page_width = landscape(A4)[0]\n",
        "    available_width = page_width - (doc.leftMargin + doc.rightMargin)\n",
        "\n",
        "    # Create table elements\n",
        "    table_elements = create_table(table_df, table_title)\n",
        "\n",
        "    if table_elements:\n",
        "        table = table_elements[-1]  # Last element is the table\n",
        "\n",
        "        if isinstance(table, Table):\n",
        "            # Calculate column widths dynamically based on text length\n",
        "            text_lengths = table_df.applymap(lambda x: len(str(x))).sum(axis=0)\n",
        "            total_text_length = sum(text_lengths)\n",
        "\n",
        "            # Normalize column widths based on relative text length\n",
        "            if col_width_manual is None:\n",
        "                col_widths = [(available_width * (col_size / total_text_length)) for col_size in text_lengths]\n",
        "                table._argW = col_widths  # Manually set column widths\n",
        "            else:\n",
        "                table._argW = col_width_manual\n",
        "        # print(table._argW)\n",
        "        elements.extend(table_elements)  # Add table elements\n",
        "\n",
        "        # Add explanatory text if the table is for \"Income & Preservation Portfolios\"\n",
        "        if table_title == \"Income & Preservation Portfolios\":\n",
        "            explanation_text = (\n",
        "                \"<i>*Est. Yield (%): References latest annualised distribution yield for Income+ portfolios, estimated dividend yield for REIT+ portfolios, projected returns for Cash+ Flexi portfolios, and guaranteed rates for Cash+ Guaranteed portfolios.</i><br/>\"\n",
        "                \"<i>**Annualised Projected Dividend: Estimated dividend yield multiplied by current portfolio value.</i>\"\n",
        "            )\n",
        "            text_style = ParagraphStyle(\n",
        "                name=\"ExplanationStyle\",\n",
        "                fontName=\"Helvetica-Oblique\",  # Italic font\n",
        "                fontSize=6,\n",
        "                leading=8,  # Line spacing\n",
        "                alignment=0,  # Left-aligned\n",
        "            )\n",
        "            elements.append(Spacer(1, 0.1 * inch))  # Space before text\n",
        "            elements.append(Paragraph(explanation_text, text_style))\n",
        "\n",
        "        elements.append(Spacer(1, 0.2 * inch))  # Space before charts\n",
        "\n",
        "    # Chart settings\n",
        "    num_charts = len(charts)\n",
        "    cols_per_row = 2 if num_charts % 2 == 0 else 3  # Adjust layout\n",
        "\n",
        "    chart_width = 3.5 * inch\n",
        "    chart_height = 2.6 * inch\n",
        "\n",
        "    chart_grid = []\n",
        "    row = []\n",
        "\n",
        "    for idx, chart in enumerate(charts):\n",
        "        # Save chart to temporary image\n",
        "        image_file = f\"temp_chart_{idx}.png\"\n",
        "        chart.write_image(image_file, format=\"png\", width=4000, height=3000)\n",
        "        temp_images.append(image_file)\n",
        "\n",
        "        # Add chart image to row\n",
        "        img = Image(image_file, width=chart_width, height=chart_height)\n",
        "        row.append(img)\n",
        "\n",
        "        # Add row when cols_per_row charts are added or if it's the last chart\n",
        "        if len(row) == cols_per_row or idx == len(charts) - 1:\n",
        "            chart_grid.append(row)\n",
        "            row = []\n",
        "\n",
        "    # Create a table for charts with borders and adjusted colWidths\n",
        "    for chart_row in chart_grid:\n",
        "        col_widths = [available_width / len(chart_row)] * len(chart_row)  # Auto-fit chart columns\n",
        "        chart_table = Table([chart_row], colWidths=col_widths)\n",
        "\n",
        "        # Add border to chart table\n",
        "        chart_table.setStyle(TableStyle([\n",
        "            ('BOX', (0, 0), (-1, -1), 0.1, colors.white),\n",
        "        ]))\n",
        "        elements.append(chart_table)\n",
        "        elements.append(Spacer(1, 0.1 * inch))\n",
        "\n",
        "    doc.build(elements)\n",
        "\n",
        "    # Clean up temporary image files\n",
        "    for image_file in temp_images:\n",
        "        if os.path.exists(image_file):\n",
        "            os.remove(image_file)\n",
        "\n",
        "def create_pdf_with_table(output_file, table_df, table_title, col_width_manual=None):\n",
        "    elements = []\n",
        "    temp_images = []  # Track temporary image files for cleanup\n",
        "\n",
        "    # Create PDF document\n",
        "    doc = SimpleDocTemplate(\n",
        "        output_file,\n",
        "        pagesize=landscape(A4),\n",
        "        leftMargin=0.4 * inch,  # Adjust left margin\n",
        "        rightMargin=0.3 * inch,  # Adjust right margin\n",
        "        topMargin=0.6 * inch,  # Adjust top margin\n",
        "        bottomMargin=0.2 * inch  # Adjust bottom margin\n",
        "    )\n",
        "\n",
        "    # Calculate available width for table\n",
        "    page_width = landscape(A4)[0]\n",
        "    available_width = page_width - (doc.leftMargin + doc.rightMargin)\n",
        "\n",
        "    # Create table elements\n",
        "    table_elements = create_table(table_df, table_title)\n",
        "\n",
        "    if table_elements:\n",
        "        table = table_elements[-1]  # Last element is the table\n",
        "\n",
        "        if isinstance(table, Table):\n",
        "            # Calculate column widths dynamically based on text length\n",
        "            text_lengths = table_df.applymap(lambda x: len(str(x))).sum(axis=0)\n",
        "            total_text_length = sum(text_lengths)\n",
        "\n",
        "            # Normalize column widths based on relative text length\n",
        "            if col_width_manual is None:\n",
        "                col_widths = [(available_width * (col_size / total_text_length)) for col_size in text_lengths]\n",
        "                table._argW = col_widths  # Manually set column widths\n",
        "            else:\n",
        "                table._argW = col_width_manual\n",
        "        # print(table._argW)\n",
        "        elements.extend(table_elements)  # Add table elements\n",
        "\n",
        "        # Add explanatory text if the table is for \"Income & Preservation Portfolios\"\n",
        "        if table_title == \"Income & Preservation Portfolios\":\n",
        "            explanation_text = (\n",
        "                \"<i>*Est. Yield (%): References latest annualised distribution yield for Income+ portfolios, estimated dividend yield for REIT+ portfolios, projected returns for Cash+ Flexi portfolios, and guaranteed rates for Cash+ Guaranteed portfolios.</i><br/>\"\n",
        "                \"<i>**Annualised Projected Dividend: Estimated dividend yield multiplied by current portfolio value.</i>\"\n",
        "            )\n",
        "            text_style = ParagraphStyle(\n",
        "                name=\"ExplanationStyle\",\n",
        "                fontName=\"Helvetica-Oblique\",  # Italic font\n",
        "                fontSize=6,\n",
        "                leading=8,  # Line spacing\n",
        "                alignment=0,  # Left-aligned\n",
        "            )\n",
        "            elements.append(Spacer(1, 0.1 * inch))  # Space before text\n",
        "            elements.append(Paragraph(explanation_text, text_style))\n",
        "\n",
        "        elements.append(Spacer(1, 0.2 * inch))  # Space before charts\n",
        "\n",
        "    doc.build(elements)\n",
        "\n",
        "def create_pdf_with_charts(output_file, charts):\n",
        "    elements = []\n",
        "    temp_images = []  # Track temporary image files for cleanup\n",
        "\n",
        "    # Create PDF document\n",
        "    doc = SimpleDocTemplate(\n",
        "        output_file,\n",
        "        pagesize=landscape(A4),\n",
        "        leftMargin=0.3 * inch,  # Adjust left margin\n",
        "        rightMargin=0.3 * inch,  # Adjust right margin\n",
        "        topMargin=0.5 * inch,  # Increased top margin to shift charts down\n",
        "        bottomMargin=0.2 * inch  # Adjust bottom margin\n",
        "    )\n",
        "    elements.append(Spacer(1, 0.5 * inch))  # Add more space before charts\n",
        "\n",
        "    # Calculate available width for centering\n",
        "    page_width = landscape(A4)[0]\n",
        "    available_width = page_width - (doc.leftMargin + doc.rightMargin)\n",
        "\n",
        "    # Chart settings for 2x2 layout\n",
        "    cols_per_row = 2  # Ensuring 2 charts per row\n",
        "    chart_width = 4.5 * inch  # Adjusted for better centering\n",
        "    chart_height = 3.2 * inch  # Adjusted for better aspect ratio\n",
        "\n",
        "    chart_grid = []\n",
        "    row = []\n",
        "\n",
        "    for idx, chart in enumerate(charts):\n",
        "        # Save chart to temporary image\n",
        "        image_file = f\"temp_chart_{idx}.png\"\n",
        "        chart.write_image(image_file, format=\"png\", width=4000, height=3000)\n",
        "        temp_images.append(image_file)\n",
        "\n",
        "        # Add chart image to row\n",
        "        img = Image(image_file, width=chart_width, height=chart_height)\n",
        "        row.append(img)\n",
        "\n",
        "        # Add row when 2 charts are added or if it's the last chart\n",
        "        if len(row) == cols_per_row or idx == len(charts) - 1:\n",
        "            # Center align by adding empty space if row has only 1 chart\n",
        "            while len(row) < cols_per_row:\n",
        "                row.insert(0, Spacer(1, chart_height))  # Add blank space for alignment\n",
        "\n",
        "            chart_grid.append(row)\n",
        "            row = []\n",
        "\n",
        "    # Create a table for charts with borders and adjusted column widths\n",
        "    for chart_row in chart_grid:\n",
        "        col_widths = [available_width / cols_per_row] * cols_per_row  # Equal column widths\n",
        "        chart_table = Table([chart_row], colWidths=col_widths, hAlign=\"CENTER\")  # Center-align table\n",
        "\n",
        "        # Add border to chart table\n",
        "        chart_table.setStyle(TableStyle([\n",
        "            ('BOX', (0, 0), (-1, -1), 0.1, colors.white),\n",
        "        ]))\n",
        "        elements.append(chart_table)\n",
        "        elements.append(Spacer(1, 0.2 * inch))  # More spacing between chart rows\n",
        "\n",
        "    doc.build(elements)\n",
        "\n",
        "    # Clean up temporary image files\n",
        "    for image_file in temp_images:\n",
        "        if os.path.exists(image_file):\n",
        "            os.remove(image_file)\n",
        "\n",
        "    # Clean up temporary image files\n",
        "    for image_file in temp_images:\n",
        "        if os.path.exists(image_file):\n",
        "            os.remove(image_file)\n",
        "\n",
        "\n",
        "def calculate_subtotal_income_preservation(df, classification):\n",
        "    # Filter data for the given classification\n",
        "    subset = df[df['L2_classification'] == classification]\n",
        "\n",
        "    # Sum relevant numeric columns\n",
        "    subtotal = subset[['Value (SGD)', 'Value (USD)', 'Proj. Dividend (SGD)', 'Allocation']].sum()\n",
        "\n",
        "    # Assign Portfolio ID\n",
        "    subtotal['Portfolio ID'] = classification\n",
        "\n",
        "    # Calculate weighted average for Est. Yield (%)\n",
        "    allocation_sum = subset['Allocation'].sum()\n",
        "\n",
        "    if allocation_sum != 0:\n",
        "        weighted_yield = (subset['Est. Yield (%)'] * subset['Allocation']).sum() / allocation_sum\n",
        "        weighted_risk_rating = (subset['Risk rating'] * subset['Allocation']).sum() / allocation_sum # Calculate weighted avg Risk rating\n",
        "    else:\n",
        "        weighted_yield = 0  # Avoid division by zero\n",
        "        weighted_risk_rating = 0  # Avoid division by zero\n",
        "\n",
        "    # Add weighted Est. Yield (%) and Risk rating to the subtotal\n",
        "    subtotal['Est. Yield (%)'] = weighted_yield\n",
        "    subtotal['Risk rating'] = weighted_risk_rating # Add weighted Risk rating to subtotal\n",
        "\n",
        "    return subtotal\n",
        "\n",
        "def dividend_option_adj(row):\n",
        "    if row['Dividend Option'] == 'REINVEST':\n",
        "      if row['internal_port_name'] in alt_groups:\n",
        "        return 'Payout (semi-annually)'\n",
        "      if row['internal_port_name'] in cm_groups:\n",
        "        return 'Accumulating'\n",
        "      if row['internal_port_name'] in income_plus_groups:\n",
        "        return 'Reinvest'\n",
        "      if row['internal_port_name'] in reit_groups:\n",
        "        return 'Reinvest'\n",
        "    elif row['internal_port_name'] in income_plus_groups:\n",
        "        return 'Payout (monthly)'\n",
        "    elif row['internal_port_name'] in reit_groups:\n",
        "        return 'Payout (quarterly)'\n",
        "    else:\n",
        "        return '-'\n",
        "\n",
        "def format_maturity_period(value):\n",
        "    if isinstance(value, str):  # Check if value is a string\n",
        "        if value == '\"ONE_MONTH\"':\n",
        "            return \"1 month\"\n",
        "        if value == '\"THREE_MONTHS\"':\n",
        "            return \"3 months\"\n",
        "        if value == '\"SIX_MONTHS\"':\n",
        "            return \"6 months\"\n",
        "        if value == '\"TWELVE_MONTHS\"':\n",
        "            return \"12 months\"\n",
        "        else:\n",
        "            return \"-\"\n",
        "    return value  # Return original value if not a string or no match\n",
        "\n",
        "def add_client_name_to_cover(cover_pdf_path, client_name, client_id):\n",
        "\n",
        "    # Read the existing PDF\n",
        "    with open(cover_pdf_path, \"rb\") as f:\n",
        "        existing_pdf = PdfReader(f)\n",
        "        page = existing_pdf.pages[0]  # Get the first page\n",
        "\n",
        "        # Create a canvas for the overlay\n",
        "        packet = io.BytesIO()\n",
        "        can = canvas.Canvas(packet, pagesize=landscape(A4))  # Use landscape(A4)\n",
        "\n",
        "        # Calculate text position (center, 2/3 way down)\n",
        "        page_width = landscape(A4)[0]  # Get width from landscape(A4)\n",
        "        page_height = landscape(A4)[1]  # Get height from landscape(A4)\n",
        "        text_x = page_width / 2  # Center horizontally\n",
        "        text_y = page_height * (1/3)  # Adjust vertical position for client name\n",
        "        date_y = text_y - 30 # Adjust vertical position for date below client name\n",
        "\n",
        "        # Add the client name text in white\n",
        "        can.setFillColor(colors.white)  # Set text color to white\n",
        "        can.setFont(\"ProximaNovaBold\", 30)  # Set font and size\n",
        "        can.drawCentredString(text_x, text_y, client_name)\n",
        "\n",
        "        # Add today's date below client name\n",
        "        can.setFont(\"ProximaNovaBold\", 20)  # Set font and size for date\n",
        "        can.drawCentredString(text_x, date_y, datetime.now().strftime(\"%B %d, %Y\"))\n",
        "\n",
        "        # Save the overlay\n",
        "        can.save()\n",
        "\n",
        "        # Merge the overlay with the original page\n",
        "        packet.seek(0)\n",
        "        overlay_pdf = PdfReader(packet)\n",
        "        page.merge_page(overlay_pdf.pages[0])\n",
        "\n",
        "        # Create a new PDF with the modified page\n",
        "        output_pdf = PdfWriter()\n",
        "        output_pdf.add_page(page)\n",
        "        # Get original file name without extension\n",
        "        original_file_name = os.path.splitext(os.path.basename(cover_pdf_path))[0]\n",
        "        # Construct new file name with client ID\n",
        "        new_file_name = f\"{original_file_name}_{client_id}.pdf\"\n",
        "        # Construct new file path\n",
        "        new_file_path = os.path.join(os.path.dirname(cover_pdf_path), new_file_name)\n",
        "\n",
        "        # Overwrite the original PDF with the new file name\n",
        "        with open(new_file_path, \"wb\") as output_file:\n",
        "            output_pdf.write(output_file)"
      ],
      "metadata": {
        "id": "vYECEhoWIFEs"
      },
      "id": "vYECEhoWIFEs",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "\n",
        "syfe_port_mapping = pd.DataFrame({\n",
        "'MB_port_name': ['CASH_PLUS', 'CASH_PLUS_USD', 'CHINA_GROWTH', 'CORE_BALANCED', 'CORE_DEFENSIVE', 'CORE_GROWTH', 'DISRUPTIVE_TECHNOLOGY', 'ESG_AND_CLEAN_ENERGY',\n",
        "                  'GLOBAL_EQUITY_100', 'HEALTHCARE_INNOVATION', 'INCOME_ENHANCE', 'INCOME_PRESERVE', 'REIT', 'REIT_RISK_MANAGED',\n",
        "                  'SRS_CASH_PLUS', 'SRS_GLOBAL_EQUITY_100', 'SRS_INCOME_ENHANCED', 'SRS_INCOME_PRESERVE', 'DOWNSIDE_PROTECTED', 'CASH_PLUS_GUARANTEED_SGD',\n",
        "                 'CUSTOM_USD', 'SIFN27D'],\n",
        "\n",
        "'internal_port_name': ['Cash SGD flexi', 'Cash USD flexi', 'China Growth', 'Core Balanced', 'Core Defensive', 'Core Growth', 'Disruptive Technology',\n",
        "                        'ESG & Clean Energy', 'Core Equity100', 'Healthcare Innovation', 'Income Enhance', 'Income Preserve', 'REIT 100', 'REIT Risk Managed',\n",
        "                        'SRS Cash SGD flexi', 'SRS Equity100', 'SRS Income Enhance', 'SRS Income Preserve', 'Downside protected', 'Cash SGD guaranteed',\n",
        "                       'Custom USD', 'Silverdale Fund (Nov 2027)']\n",
        "})\n",
        "\n",
        "core_groups = ['Core Equity100', 'Core Growth', 'Core Balanced', 'Core Defensive', 'SRS Equity100']\n",
        "specialised_groups = ['China Growth', 'Disruptive Technology', 'ESG & Clean Energy', 'Healthcare Innovation', 'Downside protected', 'Custom USD']\n",
        "reit_groups = ['REIT 100', 'REIT Risk Managed']\n",
        "income_plus_groups = ['Income Enhance', 'Income Preserve', 'SRS Income Enhance', 'SRS Income Preserve']\n",
        "alt_groups = ['Silverdale Fund (Nov 2027)']\n",
        "custom_groups = ['Custom USD']\n",
        "cm_groups = ['Cash SGD flexi', 'SRS Cash SGD flexi', 'Cash USD flexi', 'Cash SGD guaranteed']\n",
        "\n",
        "growth_groups = core_groups + specialised_groups\n",
        "income_preservation_groups = income_plus_groups + reit_groups + alt_groups + cm_groups\n",
        "all_syfe__portfolios = growth_groups + income_preservation_groups\n",
        "\n",
        "syfe_port_mapping['L1_classification'] = np.where(syfe_port_mapping['internal_port_name'].isin(growth_groups), 'Growth', 'Income & Preservation')\n",
        "\n",
        "L2_conditions = [\n",
        "    syfe_port_mapping['internal_port_name'].isin(core_groups),\n",
        "    syfe_port_mapping['internal_port_name'].isin(specialised_groups),\n",
        "    syfe_port_mapping['internal_port_name'].isin(reit_groups),\n",
        "    syfe_port_mapping['internal_port_name'].isin(income_plus_groups),\n",
        "    syfe_port_mapping['internal_port_name'].isin(alt_groups),\n",
        "    syfe_port_mapping['internal_port_name'].isin(cm_groups),\n",
        "]\n",
        "\n",
        "labels = ['Core', 'Specialised', 'REITs', 'Income+', 'Alternatives','Cash / MMF']\n",
        "\n",
        "# Assign L2 classification\n",
        "syfe_port_mapping['L2_classification'] = np.select(L2_conditions, labels, default='Other')\n",
        "\n",
        "syfe_port_mapping = syfe_port_mapping.merge(df_sec_list[['Ticker', 'Risk rating']], how='left', left_on='internal_port_name', right_on='Ticker')\n",
        "syfe_port_mapping.drop(columns=['Ticker'], inplace=True)\n",
        "\n",
        "\n",
        "################################################################################################################################\n",
        "mb_port_names_core = syfe_port_mapping[syfe_port_mapping['internal_port_name'].isin(core_groups)]['MB_port_name'].tolist()\n",
        "mb_port_names_specialised = syfe_port_mapping[syfe_port_mapping['internal_port_name'].isin(specialised_groups)]['MB_port_name'].tolist()\n",
        "mb_port_names_cm = syfe_port_mapping[syfe_port_mapping['internal_port_name'].isin(cm_groups)]['MB_port_name'].tolist()\n",
        "mb_port_names_growth = syfe_port_mapping[syfe_port_mapping['internal_port_name'].isin(growth_groups)]['MB_port_name'].tolist()\n",
        "mb_port_names_income_preservation = syfe_port_mapping[syfe_port_mapping['internal_port_name'].isin(income_preservation_groups)]['MB_port_name'].tolist()\n",
        "mb_port_names_income_plus = ['INCOME_ENHANCE', 'INCOME_PRESERVE', 'SRS_INCOME_ENHANCE', 'SRS_INCOME_PRESERVE']\n",
        "mb_port_names_reits = ['REIT', 'REIT_RISK_MANAGED']\n",
        "mb_port_names_alt = ['SIFN27D']\n",
        "\n",
        "order_of_ports = ['GLOBAL_EQUITY_100', 'CORE_GROWTH', 'CORE_BALANCED', 'CORE_DEFENSIVE', 'SRS_GLOBAL_EQUITY_100',\n",
        "                  'DISRUPTIVE_TECHNOLOGY', 'ESG_AND_CLEAN_ENERGY', 'HEALTHCARE_INNOVATION', 'CHINA_GROWTH', 'DOWNSIDE_PROTECTED', 'CUSTOM_USD',\n",
        "                  'INCOME_PRESERVE', 'INCOME_ENHANCE', 'SRS_INCOME_PRESERVE', 'SRS_INCOME_ENHANCED', 'REIT' ,'REIT_RISK_MANAGED', 'SIFN27D',\n",
        "                  'CASH_PLUS', 'CASH_PLUS_USD', 'CASH_PLUS_GUARANTEED_SGD', 'SRS_CASH_PLUS']\n",
        "\n",
        "# all_asset_mapping = df_sec_list.merge(syfe_port_mapping, how='left', left_on='Ticker', right_on='internal_port_name')\n",
        "# all_asset_mapping.loc[all_asset_mapping['MB_port_name'].isnull(), ['MB_port_name', 'internal_port_name']] = all_asset_mapping['Ticker']"
      ],
      "metadata": {
        "id": "5KKVzOkl3cge"
      },
      "id": "5KKVzOkl3cge",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Upload MB report\n",
        "\n",
        "#####################################################################################################################\n",
        "\n",
        "bbg_last_update_date = pd.read_csv(data_path + 'PV_daily_ret.csv', index_col=0, usecols=[0], parse_dates=['Date'],dayfirst=True).index[-1]\n",
        "bbg_last_update_date = bbg_last_update_date.strftime('%Y-%m-%d')\n",
        "\n",
        "#####################################################################################################################\n",
        "print('\\n')\n",
        "print_arial_bold('Upload client holdings from <a href=\"https://metabase.internal.syfe.com/question/1470-find-clients-portfolios-by-email?email=&portfolio_id=&client_id=&phone=&source_of_funds=\" target=\"_blank\">Metabase</a>')\n",
        "\n",
        "uploader = widgets.FileUpload(\n",
        "    accept='*',  # Accepts all file types\n",
        "    multiple=False  # Only allows one file to be uploaded at a time\n",
        ")\n",
        "\n",
        "# function to upload file\n",
        "def handle_upload(change, syfe_port_mapping=syfe_port_mapping):\n",
        "    global df_client_portfolios, aggregated_holdings, custom_usd_rows, aggregated_holdings_all_clients, custom_usd_all_clients\n",
        "\n",
        "    syfe_port_mapping = pd.DataFrame({\n",
        "    'MB_port_name': ['CASH_PLUS', 'CASH_PLUS_USD', 'CHINA_GROWTH', 'CORE_BALANCED', 'CORE_DEFENSIVE', 'CORE_GROWTH', 'DISRUPTIVE_TECHNOLOGY', 'ESG_AND_CLEAN_ENERGY',\n",
        "                      'GLOBAL_EQUITY_100', 'HEALTHCARE_INNOVATION', 'INCOME_ENHANCE', 'INCOME_PRESERVE', 'REIT', 'REIT_RISK_MANAGED',\n",
        "                      'SRS_CASH_PLUS', 'SRS_GLOBAL_EQUITY_100', 'SRS_INCOME_ENHANCED', 'SRS_INCOME_PRESERVE', 'DOWNSIDE_PROTECTED', 'CASH_PLUS_GUARANTEED_SGD',\n",
        "                    'CUSTOM_USD', 'SIFN27D'],\n",
        "\n",
        "    'internal_port_name': ['Cash SGD flexi', 'Cash USD flexi', 'China Growth', 'Core Balanced', 'Core Defensive', 'Core Growth', 'Disruptive Technology',\n",
        "                            'ESG & Clean Energy', 'Core Equity100', 'Healthcare Innovation', 'Income Enhance', 'Income Preserve', 'REIT 100', 'REIT Risk Managed',\n",
        "                            'SRS Cash SGD flexi', 'SRS Equity100', 'SRS Income Enhance', 'SRS Income Preserve', 'Downside protected', 'Cash SGD guaranteed',\n",
        "                          'Custom USD', 'Silverdale Fund (Nov 2027)']\n",
        "    })\n",
        "\n",
        "    uploaded_filename = next(iter(uploader.value))\n",
        "    content = uploader.value[uploaded_filename]['content']\n",
        "    with open(uploaded_filename, 'wb') as f:\n",
        "        f.write(content)\n",
        "    print(f'Uploaded `{uploaded_filename}` successfully!')\n",
        "\n",
        "    # Read the CSV file into a pandas DataFrame\n",
        "    try:\n",
        "        df_client_portfolios = pd.read_csv(io.BytesIO(content))\n",
        "        client_id_list = list((df_client_portfolios['client_id']).unique())\n",
        "        aggregated_holdings_all_clients = pd.DataFrame()\n",
        "        custom_usd_all_clients = pd.DataFrame()\n",
        "\n",
        "        for client_id in client_id_list:\n",
        "          df_client_portfolios_active = df_client_portfolios[df_client_portfolios['client_id']==client_id]\n",
        "          df_client_portfolios_active = df_client_portfolios_active[df_client_portfolios_active['status']=='ACTIVE'] # filter for active portfolios only\n",
        "          if df_client_portfolios_active['actual_holding_weightage'].astype(str).str.startswith('SIFN27D', na=False).any():\n",
        "              df_client_portfolios_active = process_silverdale_port(df_client_portfolios_active)\n",
        "          df_client_portfolios_active = process_custom_usd(df_client_portfolios_active) # explode custom usd underlying into individual rows\n",
        "          # display(df_client_portfolios_active)\n",
        "          df_client_portfolios_active = df_client_portfolios_active.merge(syfe_port_mapping, how='left', left_on='type', right_on='MB_port_name')\n",
        "\n",
        "          # Handle custom usd mapping: filter for rows with NaN MB_port_name and update MB_port_name with 'type'\n",
        "          nan_mb_port_name_rows = df_client_portfolios_active['MB_port_name'].isna()\n",
        "          df_client_portfolios_active.loc[nan_mb_port_name_rows, 'MB_port_name'] = df_client_portfolios_active.loc[nan_mb_port_name_rows, 'type']\n",
        "          df_client_portfolios_active.loc[nan_mb_port_name_rows, 'internal_port_name'] = df_client_portfolios_active.loc[nan_mb_port_name_rows, 'type']\n",
        "          custom_usd_rows = df_client_portfolios_active[nan_mb_port_name_rows].copy()\n",
        "          custom_usd_rows = custom_usd_rows.merge(df_sec_list[['Ticker']], how='left', left_on='MB_port_name', right_on='Ticker')\n",
        "\n",
        "          non_custom_usd_rows = df_client_portfolios_active[~nan_mb_port_name_rows]  # Rows that were not originally NaN\n",
        "          df_client_portfolios_active = pd.concat([non_custom_usd_rows, custom_usd_rows], ignore_index=True)\n",
        "          # display(df_client_portfolios_active)\n",
        "\n",
        "          aggregated_holdings = aggregate_client_holdings(df_client_portfolios_active)\n",
        "          aggregated_holdings['client_id'] = client_id\n",
        "\n",
        "          aggregated_holdings_all_clients = pd.concat([aggregated_holdings_all_clients, aggregated_holdings],axis=0)\n",
        "          custom_usd_all_clients = pd.concat([custom_usd_all_clients, custom_usd_rows],axis=0)\n",
        "\n",
        "        return aggregated_holdings_all_clients\n",
        "\n",
        "    except pd.errors.ParserError:\n",
        "        print(\"Error: Could not parse the file as a CSV. Please ensure it's a valid CSV file.\")\n",
        "\n",
        "uploader.observe(handle_upload, names='value') # Observe the uploader for changes\n",
        "display(uploader) # Display the uploader\n",
        "\n",
        "def aggregate_client_holdings(df_client_portfolios):\n",
        "    # Aggregate holdings based on 'internal_port_name'\n",
        "    aggregated_holdings = df_client_portfolios.groupby('internal_port_name').agg({\n",
        "        'internal_port_name': lambda x: ', '.join(x.astype(str)),  # Join tickers with commas\n",
        "        'nav_in_sgd': 'sum'  # Sum market values\n",
        "    })\n",
        "    # aggregated_holdings[['nav_in_sgd']] = aggregated_holdings[['nav_in_sgd']].apply(pd.to_numeric)\n",
        "    # Calculate allocations\n",
        "    total_market_value = aggregated_holdings['nav_in_sgd'].sum()\n",
        "    aggregated_holdings['Allocation'] = aggregated_holdings['nav_in_sgd'] / total_market_value\n",
        "    aggregated_holdings['Allocation'] = round(aggregated_holdings['Allocation'], 8)\n",
        "    return aggregated_holdings\n",
        "\n",
        "def process_custom_usd(df):\n",
        "    df[\"nav_in_sgd\"] = df[\"nav_in_sgd\"].replace(\",\", \"\", regex=True)\n",
        "    df[\"nav_in_sgd\"] = pd.to_numeric(df[\"nav_in_sgd\"], errors=\"coerce\")\n",
        "    df[\"nav_in_usd\"] = df[\"nav_in_usd\"].replace(\",\", \"\", regex=True)\n",
        "    df[\"nav_in_usd\"] = pd.to_numeric(df[\"nav_in_usd\"], errors=\"coerce\")\n",
        "\n",
        "    # Separate CUSTOM_USD portfolios\n",
        "    custom_usd_df = df[df[\"type\"] == \"CUSTOM_USD\"].copy()\n",
        "    other_portfolios_df = df[df[\"type\"] != \"CUSTOM_USD\"]\n",
        "\n",
        "    split_custom_usd_df = []\n",
        "\n",
        "    for _, row in custom_usd_df.iterrows():\n",
        "        holdings_str = row[\"actual_holding_weightage\"]\n",
        "\n",
        "        if isinstance(holdings_str, str):  # Ensure it's a string\n",
        "            try:\n",
        "                # Split by comma and then by spaces\n",
        "                holdings = [\n",
        "                    h.strip().rsplit(\" \", 1)  # Split ticker and weight\n",
        "                    for h in holdings_str.split(\",\")\n",
        "                    if h.strip()]\n",
        "                # print(row)\n",
        "                for ticker, weight_str in holdings:\n",
        "                    try:\n",
        "                        weight = float(weight_str.strip(\"%\")) / 100\n",
        "                        new_row = row.copy()\n",
        "                        new_row[\"type\"] = ticker\n",
        "                        nav_in_sgd = row[\"nav_in_sgd\"]\n",
        "                        if isinstance(nav_in_sgd, str):\n",
        "                          nav_in_sgd = float(nav_in_sgd.replace(\",\", \"\"))\n",
        "                        new_row[\"nav_in_sgd\"] = nav_in_sgd * weight if nav_in_sgd else None\n",
        "                        nav_in_usd = row[\"nav_in_usd\"]\n",
        "                        if isinstance(nav_in_usd, str):\n",
        "                            nav_in_usd = float(nav_in_usd.replace(\",\", \"\"))\n",
        "                        new_row[\"nav_in_usd\"] = nav_in_usd * weight if nav_in_usd else None\n",
        "\n",
        "                        split_custom_usd_df.append(new_row)\n",
        "                    except ValueError:\n",
        "                        print(f\"Warning: Invalid weight format for ticker {ticker}: {weight_str}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing holdings string '{holdings_str}': {e}\")\n",
        "        else:\n",
        "            print(f\"Warning: actual_holding_weightage is not a string: {holdings_str}\")\n",
        "\n",
        "    # Concatenate the split CUSTOM_USD rows with the non-CUSTOM_USD rows\n",
        "    processed_df = pd.concat([other_portfolios_df, pd.DataFrame(split_custom_usd_df)],ignore_index=True,)\n",
        "    processed_df[['nav_in_sgd']] = processed_df[['nav_in_sgd']].apply(pd.to_numeric)\n",
        "    processed_df[['nav_in_usd']] = processed_df[['nav_in_usd']].apply(pd.to_numeric)\n",
        "\n",
        "\n",
        "    return processed_df\n",
        "\n",
        "def process_silverdale_port(df):\n",
        "    # Check if 'SIFN27D' is present in actual_holding_weightage\n",
        "    if df['actual_holding_weightage'].str.startswith('SIFN27D', na=False).any():\n",
        "        # If present, update the 'type' column to 'SIFN27D'\n",
        "        df.loc[df['actual_holding_weightage'].str.startswith('SIFN27D', na=False), 'type'] = 'SIFN27D'\n",
        "    return df\n",
        "\n",
        "#####################################################################################################################"
      ],
      "metadata": {
        "id": "zpcwvrMlT9UV",
        "outputId": "9912e934-8e5d-4595-9c6a-cb35406c9bbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133,
          "referenced_widgets": [
            "bc23505c5f3e4407b22508c6857c1f78",
            "b9e4498d8b844f92b1deb913755fe592",
            "1a0dfa0e8b234a71b42063f0f5d3b67f",
            "67b4e516417f46a9aab6ae1d9ca7ef8e",
            "d4323663013940878accdf6549d4e9b3",
            "34193d718da84c0f90f7b4b6ef97e6a7"
          ]
        },
        "cellView": "form"
      },
      "id": "zpcwvrMlT9UV",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HTML(value='<div style=\\'font-family: Arial, sans-serif; font-weight: bold;\\'>Upload client holdings from <a h…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc23505c5f3e4407b22508c6857c1f78"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileUpload(value={}, accept='*', description='Upload')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67b4e516417f46a9aab6ae1d9ca7ef8e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded `Client_1_PV copy.csv` successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aggregated_holdings"
      ],
      "metadata": {
        "id": "j6wQ0L5nfH1e",
        "outputId": "2308ec25-68f5-4ab9-b896-3964f52b6cb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        }
      },
      "id": "j6wQ0L5nfH1e",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    internal_port_name    nav_in_sgd  \\\n",
              "internal_port_name                                                     \n",
              "Cash SGD flexi                          Cash SGD flexi  26312.880000   \n",
              "Cash SGD guaranteed                Cash SGD guaranteed  10116.000000   \n",
              "Cash USD flexi                          Cash USD flexi   9322.750767   \n",
              "Core Equity100                          Core Equity100  40578.030000   \n",
              "Disruptive Technology            Disruptive Technology   5290.890000   \n",
              "Downside protected                  Downside protected   8423.350909   \n",
              "Income Enhance                          Income Enhance  10909.207190   \n",
              "REIT 100                                      REIT 100  13494.160000   \n",
              "SRS Cash SGD flexi                  SRS Cash SGD flexi   7458.931860   \n",
              "SRS Equity100                            SRS Equity100    827.286060   \n",
              "SRS Income Enhance                  SRS Income Enhance   5982.980000   \n",
              "Silverdale Fund (Nov 2027)  Silverdale Fund (Nov 2027)  25766.740000   \n",
              "\n",
              "                            Allocation  client_id  \n",
              "internal_port_name                                 \n",
              "Cash SGD flexi                0.159973   12345678  \n",
              "Cash SGD guaranteed           0.061502   12345678  \n",
              "Cash USD flexi                0.056679   12345678  \n",
              "Core Equity100                0.246700   12345678  \n",
              "Disruptive Technology         0.032167   12345678  \n",
              "Downside protected            0.051211   12345678  \n",
              "Income Enhance                0.066324   12345678  \n",
              "REIT 100                      0.082040   12345678  \n",
              "SRS Cash SGD flexi            0.045348   12345678  \n",
              "SRS Equity100                 0.005030   12345678  \n",
              "SRS Income Enhance            0.036374   12345678  \n",
              "Silverdale Fund (Nov 2027)    0.156653   12345678  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-26301732-09bd-4b91-8f72-c2609d4cbd51\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>internal_port_name</th>\n",
              "      <th>nav_in_sgd</th>\n",
              "      <th>Allocation</th>\n",
              "      <th>client_id</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>internal_port_name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Cash SGD flexi</th>\n",
              "      <td>Cash SGD flexi</td>\n",
              "      <td>26312.880000</td>\n",
              "      <td>0.159973</td>\n",
              "      <td>12345678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cash SGD guaranteed</th>\n",
              "      <td>Cash SGD guaranteed</td>\n",
              "      <td>10116.000000</td>\n",
              "      <td>0.061502</td>\n",
              "      <td>12345678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cash USD flexi</th>\n",
              "      <td>Cash USD flexi</td>\n",
              "      <td>9322.750767</td>\n",
              "      <td>0.056679</td>\n",
              "      <td>12345678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Core Equity100</th>\n",
              "      <td>Core Equity100</td>\n",
              "      <td>40578.030000</td>\n",
              "      <td>0.246700</td>\n",
              "      <td>12345678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Disruptive Technology</th>\n",
              "      <td>Disruptive Technology</td>\n",
              "      <td>5290.890000</td>\n",
              "      <td>0.032167</td>\n",
              "      <td>12345678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Downside protected</th>\n",
              "      <td>Downside protected</td>\n",
              "      <td>8423.350909</td>\n",
              "      <td>0.051211</td>\n",
              "      <td>12345678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Income Enhance</th>\n",
              "      <td>Income Enhance</td>\n",
              "      <td>10909.207190</td>\n",
              "      <td>0.066324</td>\n",
              "      <td>12345678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>REIT 100</th>\n",
              "      <td>REIT 100</td>\n",
              "      <td>13494.160000</td>\n",
              "      <td>0.082040</td>\n",
              "      <td>12345678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SRS Cash SGD flexi</th>\n",
              "      <td>SRS Cash SGD flexi</td>\n",
              "      <td>7458.931860</td>\n",
              "      <td>0.045348</td>\n",
              "      <td>12345678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SRS Equity100</th>\n",
              "      <td>SRS Equity100</td>\n",
              "      <td>827.286060</td>\n",
              "      <td>0.005030</td>\n",
              "      <td>12345678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SRS Income Enhance</th>\n",
              "      <td>SRS Income Enhance</td>\n",
              "      <td>5982.980000</td>\n",
              "      <td>0.036374</td>\n",
              "      <td>12345678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Silverdale Fund (Nov 2027)</th>\n",
              "      <td>Silverdale Fund (Nov 2027)</td>\n",
              "      <td>25766.740000</td>\n",
              "      <td>0.156653</td>\n",
              "      <td>12345678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26301732-09bd-4b91-8f72-c2609d4cbd51')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-26301732-09bd-4b91-8f72-c2609d4cbd51 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-26301732-09bd-4b91-8f72-c2609d4cbd51');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5fc97c20-4df0-45d7-9978-2d858f4ef75d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5fc97c20-4df0-45d7-9978-2d858f4ef75d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5fc97c20-4df0-45d7-9978-2d858f4ef75d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_fcc4c451-2917-4320-91f2-8cd419b238b2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('aggregated_holdings')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fcc4c451-2917-4320-91f2-8cd419b238b2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('aggregated_holdings');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "aggregated_holdings",
              "repr_error": "cannot insert internal_port_name, already exists"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Calc & Generate PDF\n",
        "\n",
        "client_id_list = list((df_client_portfolios['client_id']).unique())\n",
        "\n",
        "for client_id in client_id_list:\n",
        "  client_first_name = df_client_portfolios[df_client_portfolios['client_id']==client_id]['first_name'].iloc[0]\n",
        "  client_last_name = df_client_portfolios[df_client_portfolios['client_id']==client_id]['last_name'].iloc[0]\n",
        "  client_name = client_first_name + ' ' + client_last_name\n",
        "  print('Generating report for ', client_name)\n",
        "\n",
        "  # GENERATE KEY HOLDINGS & ALLOCATIONS\n",
        "\n",
        "  ###################################################################################################################################################################################################\n",
        "  # client_latest_alloc = df_client_portfolios[df_client_portfolios['status']=='ACTIVE'][['type', 'nav_in_sgd']]\n",
        "  client_latest_alloc = aggregated_holdings_all_clients[aggregated_holdings_all_clients['client_id']==client_id]\n",
        "  client_latest_alloc['nav_in_sgd'] = client_latest_alloc['nav_in_sgd'].astype(str).str.replace(',', '').astype(float)\n",
        "  # client_latest_alloc = pd.DataFrame(client_latest_alloc.groupby('type')['nav_in_sgd'].sum())\n",
        "  client_latest_alloc['Client Portfolio'] = client_latest_alloc['nav_in_sgd'] / client_latest_alloc['nav_in_sgd'].sum()\n",
        "  client_latest_alloc = client_latest_alloc[['Client Portfolio']]\n",
        "  client_latest_alloc = client_latest_alloc.rename(index=syfe_port_mapping.set_index('MB_port_name')['internal_port_name'])\n",
        "\n",
        "  client_latest_alloc_adj = client_latest_alloc.T\n",
        "  client_latest_alloc_adj['reb_flag'] = True\n",
        "\n",
        "  # split into growth and income portfolios\n",
        "  all_port_wgt_income_preservation = client_latest_alloc_adj.loc[client_latest_alloc_adj[('reb_flag')] == True].head().iloc[-1:]\n",
        "  cols_to_keep_income_pres = ['reb_flag'] + [col for col in income_preservation_groups if col in all_port_wgt_income_preservation.columns]\n",
        "  all_port_wgt_income_preservation = all_port_wgt_income_preservation[cols_to_keep_income_pres]\n",
        "\n",
        "  all_port_wgt_growth = client_latest_alloc_adj.loc[client_latest_alloc_adj[('reb_flag')] == True].head().iloc[-1:]\n",
        "  cols_to_keep_growth = ['reb_flag'] + [col for col in all_port_wgt_growth.columns if col != 'reb_flag' and col not in income_preservation_groups]\n",
        "  # cols_to_keep_growth = ['reb_flag'] + [col for col in growth_groups if col in all_port_wgt_growth.columns]\n",
        "  all_port_wgt_growth = all_port_wgt_growth[cols_to_keep_growth]\n",
        "  ###################################################################################################################################################################################################\n",
        "\n",
        "  assetclass_breakdown_all = pc.exposure_analysis(client_latest_alloc_adj, df_asset_class, latest_data=True)\n",
        "  assetclass_breakdown_all = (assetclass_breakdown_all.loc[(assetclass_breakdown_all != 0).any(axis=1)].sort_values(by=assetclass_breakdown_all.columns[0], ascending=False))\n",
        "\n",
        "  country_breakdown_all = pc.exposure_analysis(client_latest_alloc_adj, df_country, latest_data=True)\n",
        "  country_breakdown_all = (country_breakdown_all.loc[(country_breakdown_all != 0).any(axis=1)].sort_values(by=country_breakdown_all.columns[0], ascending=False))\n",
        "  country_breakdown_all.pipe(pc.apply_style_heatmap).pipe(pc.apply_2dp_percentage)\n",
        "\n",
        "  # growth exposure\n",
        "  if all_port_wgt_growth.empty == False:\n",
        "    assetclass_breakdown_growth = pc.exposure_analysis(all_port_wgt_growth, df_asset_class, latest_data=True)\n",
        "    assetclass_breakdown_growth = (assetclass_breakdown_growth.loc[(assetclass_breakdown_growth != 0).any(axis=1)].sort_values(by=assetclass_breakdown_growth.columns[0], ascending=False))\n",
        "    assetclass_breakdown_growth = assetclass_breakdown_growth / assetclass_breakdown_growth.sum()\n",
        "\n",
        "    country_breakdown_growth = pc.exposure_analysis(all_port_wgt_growth, df_country, latest_data=True)\n",
        "    country_breakdown_growth = (country_breakdown_growth.loc[(country_breakdown_growth != 0).any(axis=1)].sort_values(by=country_breakdown_growth.columns[0], ascending=False))\n",
        "    country_breakdown_growth.pipe(pc.apply_style_heatmap).pipe(pc.apply_2dp_percentage)\n",
        "    country_breakdown_growth = country_breakdown_growth / country_breakdown_growth.sum()\n",
        "\n",
        "    sector_breakdown_growth = pc.exposure_analysis(all_port_wgt_growth, df_sector, latest_data=True)\n",
        "    sector_breakdown_growth = (sector_breakdown_growth.loc[(sector_breakdown_growth != 0).any(axis=1)].sort_values(by=sector_breakdown_growth.columns[0], ascending=False))\n",
        "    sector_breakdown_growth.pipe(pc.apply_style_heatmap).pipe(pc.apply_2dp_percentage)\n",
        "    sector_breakdown_growth = sector_breakdown_growth / sector_breakdown_growth.sum()\n",
        "\n",
        "  # income & preservation exposure\n",
        "  if all_port_wgt_income_preservation.empty == False:\n",
        "    assetclass_breakdown_income_preservation = pc.exposure_analysis(all_port_wgt_income_preservation, df_asset_class, latest_data=True)\n",
        "    assetclass_breakdown_income_preservation = (assetclass_breakdown_income_preservation.loc[(assetclass_breakdown_income_preservation != 0).any(axis=1)].sort_values(by=assetclass_breakdown_income_preservation.columns[0], ascending=False))\n",
        "    assetclass_breakdown_income_preservation = assetclass_breakdown_income_preservation / assetclass_breakdown_income_preservation.sum()\n",
        "\n",
        "    country_breakdown_income_preservation = pc.exposure_analysis(all_port_wgt_income_preservation, df_country, latest_data=True)\n",
        "    country_breakdown_income_preservation = (country_breakdown_income_preservation.loc[(country_breakdown_income_preservation != 0).any(axis=1)].sort_values(by=country_breakdown_income_preservation.columns[0], ascending=False))\n",
        "    country_breakdown_income_preservation.pipe(pc.apply_style_heatmap).pipe(pc.apply_2dp_percentage)\n",
        "    country_breakdown_income_preservation = country_breakdown_income_preservation / country_breakdown_income_preservation.sum()\n",
        "\n",
        "    sector_breakdown_income_preservation = pc.exposure_analysis(all_port_wgt_income_preservation, df_sector, latest_data=True)\n",
        "    sector_breakdown_income_preservation = (sector_breakdown_income_preservation.loc[(sector_breakdown_income_preservation != 0).any(axis=1)].sort_values(by=sector_breakdown_income_preservation.columns[0], ascending=False))\n",
        "    sector_breakdown_income_preservation.pipe(pc.apply_style_heatmap).pipe(pc.apply_2dp_percentage)\n",
        "    sector_breakdown_income_preservation = sector_breakdown_income_preservation / sector_breakdown_income_preservation.sum()\n",
        "\n",
        "  ###################################################################################################################################################################################################\n",
        "\n",
        "  # PORTFOLIO SUMMARY TABLE\n",
        "  for col in ['nav_in_sgd', 'nav_in_usd', 'pnl_inception', 'invested_amount', 'dividend_balance']:\n",
        "      df_client_portfolios[col] = pd.to_numeric(df_client_portfolios[col].astype(str).str.replace(',', '', regex=True), errors='coerce')\n",
        "\n",
        "  # df_client_portfolios = df_client_portfolios.sort_values(by='nav_in_sgd', ascending=False)\n",
        "  df_client_portfolios_to_show = df_client_portfolios[df_client_portfolios['client_id']==client_id]\n",
        "  df_client_portfolios_to_show = df_client_portfolios_to_show[df_client_portfolios_to_show['status'] == 'ACTIVE']\n",
        "  if df_client_portfolios_to_show['actual_holding_weightage'].astype(str).str.startswith('SIFN27D', na=False).any():\n",
        "      df_client_portfolios_to_show = process_silverdale_port(df_client_portfolios_to_show)\n",
        "  # Select and format columns\n",
        "  cols_to_show_all = ['portfolio_id', 'type', 'activated_date_sgt', 'nav_in_sgd', 'nav_in_usd', 'dividend_balance', 'dividend_option', 'maturity_period', 'fd_created_at_rate']\n",
        "  client_port_rename_cols_all = ['Portfolio ID', 'Portfolio Type', 'Activated date', 'Value (SGD)', 'Value (USD)', 'Dividend (SGD)', 'Dividend Option','Maturity period', 'Guaranteed rate']\n",
        "  df_client_portfolios_to_show_all = df_client_portfolios_to_show[cols_to_show_all]\n",
        "  df_client_portfolios_to_show_all.columns = client_port_rename_cols_all\n",
        "  df_client_portfolios_to_show_all = df_client_portfolios_to_show_all.merge(syfe_port_mapping, left_on='Portfolio Type', right_on='MB_port_name', how='left')\n",
        "\n",
        "  # Check if 'CUSTOM_USD' exists in 'Portfolio Type'\n",
        "  if 'CUSTOM_USD' in df_client_portfolios_to_show_all['Portfolio Type'].values:\n",
        "      custom_usd_risk_rating = calc_custom_weighted_risk_rating(custom_usd_all_clients[custom_usd_all_clients['client_id']==client_id], df_sec_list)\n",
        "\n",
        "      # Iterate through rows with 'CUSTOM_USD'\n",
        "      for index, row in df_client_portfolios_to_show_all[df_client_portfolios_to_show_all['Portfolio Type'] == 'CUSTOM_USD'].iterrows():\n",
        "          # Get the Portfolio ID\n",
        "          portfolio_id = row['Portfolio ID']\n",
        "\n",
        "          # Find the corresponding Risk rating in custom_usd_risk_rating\n",
        "          try:\n",
        "              risk_rating = custom_usd_risk_rating[custom_usd_risk_rating['portfolio_id'] == portfolio_id]['Risk rating'].values[0]\n",
        "              # Update the Risk rating in df_client_portfolios_to_show_all\n",
        "              df_client_portfolios_to_show_all.loc[index, 'Risk rating'] = risk_rating\n",
        "          except IndexError:\n",
        "              # Handle cases where portfolio_id is not found in custom_usd_risk_rating\n",
        "              print(f\"Warning: Risk rating not found for Portfolio ID: {portfolio_id}\")\n",
        "\n",
        "  ###################################################################################################################################################################################################\n",
        "\n",
        "  # PORTFOLIO SUMMARY TABLE\n",
        "  all_portfolios_summary = df_client_portfolios_to_show_all.copy()\n",
        "\n",
        "  all_portfolios_summary['Allocation'] = all_portfolios_summary['Value (SGD)'] / all_portfolios_summary['Value (SGD)'].sum()\n",
        "\n",
        "  total_row_all = pd.DataFrame(columns=all_portfolios_summary.columns)\n",
        "\n",
        "  for col in all_portfolios_summary.columns:\n",
        "      if col in ['Value (SGD)', 'Value (USD)', 'Allocation']:\n",
        "          total_row_all.at['Total', col] = all_portfolios_summary[col].sum()\n",
        "      elif col == 'Risk rating':\n",
        "          total_row_all.at['Total', col] = np.dot(\n",
        "              all_portfolios_summary[col].astype(float), all_portfolios_summary['Allocation']\n",
        "          ) / all_portfolios_summary['Allocation'].sum()\n",
        "      else:\n",
        "          total_row_all.at['Total', col] = ''\n",
        "\n",
        "  total_row_all.iloc[0, 0] = 'Total'\n",
        "\n",
        "  all_portfolios_summary['Portfolio Type'] = pd.Categorical(\n",
        "      all_portfolios_summary['Portfolio Type'],\n",
        "      categories=order_of_ports,\n",
        "      ordered=True\n",
        "  )\n",
        "\n",
        "  # Sort the DataFrame\n",
        "  all_portfolios_summary = all_portfolios_summary.sort_values(by='Portfolio Type').reset_index(drop=True)\n",
        "\n",
        "  all_portfolios_summary[['Value (SGD)', 'Value (USD)']] = round(all_portfolios_summary[['Value (SGD)', 'Value (USD)']], 2)\n",
        "  growth_rows = all_portfolios_summary[all_portfolios_summary['Portfolio Type'].isin(mb_port_names_growth)]\n",
        "  income_pres_rows = all_portfolios_summary[all_portfolios_summary['Portfolio Type'].isin(mb_port_names_income_preservation)]\n",
        "\n",
        "  if not growth_rows.empty:\n",
        "    growth_subtotal = growth_rows.agg({\n",
        "        'Value (SGD)': 'sum',\n",
        "        'Value (USD)': 'sum',\n",
        "        'Allocation': 'sum',\n",
        "        'Risk rating': lambda x: np.average(x.astype(float), weights=growth_rows.loc[x.index, 'Allocation'])\n",
        "    })\n",
        "    growth_subtotal['Portfolio ID'] = 'Growth Portfolios'\n",
        "  else:\n",
        "      # Create an empty Series with 0 values for all columns\n",
        "      growth_subtotal = pd.Series({\n",
        "          'Value (SGD)': 0,\n",
        "          'Value (USD)': 0,\n",
        "          'Allocation': 0,\n",
        "          'Risk rating': 0\n",
        "      }, dtype=object)  # Using object dtype to handle mixed types\n",
        "      growth_subtotal['Portfolio ID'] = 'Growth Portfolios'\n",
        "      growth_subtotal = growth_subtotal.to_frame().T  # Convert to DataFrame\n",
        "\n",
        "  # Calculate subtotals for income_preservation_groups\n",
        "  if not income_pres_rows.empty:  # Only calculate if there are relevant rows\n",
        "      income_pres_subtotal = income_pres_rows.agg({\n",
        "          'Value (SGD)': 'sum',\n",
        "          'Value (USD)': 'sum',\n",
        "          'Allocation': 'sum',\n",
        "          'Risk rating': lambda x: np.average(\n",
        "              x.astype(float),\n",
        "              weights=income_pres_rows.loc[x.index, 'Allocation']\n",
        "          ) if not x.empty else np.nan  # Handle empty cases safely\n",
        "      })\n",
        "\n",
        "      income_pres_subtotal['Portfolio ID'] = 'Income & Preservation Portfolios'\n",
        "  else:\n",
        "    # Create an empty Series with 0 values for all columns\n",
        "    income_pres_subtotal = pd.Series({\n",
        "        'Value (SGD)': 0,\n",
        "        'Value (USD)': 0,\n",
        "        'Allocation': 0,\n",
        "        'Risk rating': 0\n",
        "    }, dtype=object)  # Using object dtype to handle mixed types\n",
        "    income_pres_subtotal['Portfolio ID'] = 'Income & Preservation Portfolios'\n",
        "    income_pres_subtotal = income_pres_subtotal.to_frame().T  # Convert to DataFrame\n",
        "\n",
        "  # Concatenate subtotals and original DataFrame\n",
        "  if total_row_all['Value (SGD)'].values[0] > 0:  # Check if NAV (SGD) is greater than 0\n",
        "      all_portfolios_summary_final = pd.concat([all_portfolios_summary, total_row_all])\n",
        "\n",
        "  other_rows = all_portfolios_summary_final[~all_portfolios_summary_final['L1_classification'].isin(['Growth', 'Income & Preservation'])]\n",
        "\n",
        "  concat_list = [growth_rows]\n",
        "\n",
        "  if not growth_rows.empty:\n",
        "      concat_list.append(growth_subtotal.to_frame().T)\n",
        "\n",
        "  concat_list.append(income_pres_rows)\n",
        "\n",
        "  if not income_pres_rows.empty:  # Check if subtotal exists\n",
        "      concat_list.append(income_pres_subtotal.to_frame().T)\n",
        "\n",
        "  concat_list.append(other_rows)\n",
        "\n",
        "  all_portfolios_summary_final = pd.concat(concat_list, ignore_index=True)\n",
        "\n",
        "  all_portfolios_summary_final[['Value (SGD)', 'Value (USD)']] = all_portfolios_summary_final[['Value (SGD)', 'Value (USD)']].applymap(lambda x: \"{:,.2f}\".format(x) if isinstance(x, (int, float)) else x)\n",
        "  all_portfolios_summary_final[['Risk rating']] = all_portfolios_summary_final[['Risk rating']].applymap(lambda x: \"{:,.1f}\".format(x) if isinstance(x, (int, float)) else x)\n",
        "  all_portfolios_summary_final['Allocation'] = (all_portfolios_summary_final['Allocation'] * 100).map('{:.2f}%'.format)\n",
        "\n",
        "  for col in all_portfolios_summary_final.columns:\n",
        "      if pd.api.types.is_categorical_dtype(all_portfolios_summary_final[col]):\n",
        "          # Add an empty string to the categories\n",
        "          all_portfolios_summary_final[col] = all_portfolios_summary_final[col].cat.add_categories([''])\n",
        "          # Fill NaN with the empty string\n",
        "          all_portfolios_summary_final[col] = all_portfolios_summary_final[col].fillna('')\n",
        "\n",
        "      elif all_portfolios_summary_final[col].dtype == 'object':  # For string columns\n",
        "          all_portfolios_summary_final[col] = all_portfolios_summary_final[col].fillna('')\n",
        "\n",
        "      else:  # For numeric columns\n",
        "          all_portfolios_summary_final[col] = all_portfolios_summary_final[col].fillna(0)\n",
        "\n",
        "\n",
        "  all_portfolios_summary_final = all_portfolios_summary_final[['Portfolio ID', 'internal_port_name', 'L2_classification', 'Risk rating', 'Activated date', 'Value (SGD)', 'Allocation']]\n",
        "  all_portfolios_summary_final.rename(columns={'internal_port_name': 'Portfolio Type', 'L2_classification':'Classification', 'Risk rating':'Risk rating (0-5)'}, inplace=True)\n",
        "\n",
        "  ###################################################################################################################################################################################################\n",
        "  # GROWTH PORTFOLIO TABLE\n",
        "  growth_portfolios = None\n",
        "\n",
        "  # Separate the dataframe based on the 'type' column\n",
        "  growth_portfolios = all_portfolios_summary[all_portfolios_summary['L1_classification']=='Growth']\n",
        "  growth_portfolios['Allocation'] = growth_portfolios['Value (SGD)'] / growth_portfolios['Value (SGD)'].sum()\n",
        "\n",
        "  growth_portfolios = growth_portfolios.sort_values(by='Portfolio Type').reset_index(drop=True)\n",
        "  core_rows = growth_portfolios[growth_portfolios['L2_classification'] == 'Core']\n",
        "  specialised_rows = growth_portfolios[growth_portfolios['L2_classification'] == 'Specialised']\n",
        "  other_rows = growth_portfolios[~growth_portfolios['L2_classification'].isin(['Core', 'Specialised'])]\n",
        "\n",
        "\n",
        "  if not core_rows.empty:  # Check if there are Core rows to avoid errors\n",
        "    core_subtotal = core_rows.agg({\n",
        "        'Value (SGD)': 'sum',\n",
        "        'Value (USD)': 'sum',\n",
        "        'Allocation': 'sum',\n",
        "        # risk rating needs to be a weighted avg\n",
        "        'Risk rating': lambda x: np.average(x.astype(float), weights=core_rows.loc[x.index, 'Allocation'])\n",
        "    })\n",
        "\n",
        "    core_subtotal['Portfolio ID'] = 'Core'\n",
        "  else:\n",
        "      core_subtotal = pd.Series({\n",
        "          'Value (SGD)': 0,\n",
        "          'Value (USD)': 0,\n",
        "          'Allocation': 0,\n",
        "          'Risk rating': 0\n",
        "      }, dtype=object)  # Using object dtype to handle mixed types\n",
        "      core_subtotal['Portfolio ID'] = 'Core'\n",
        "      core_subtotal = core_subtotal.to_frame().T\n",
        "\n",
        "  if not specialised_rows.empty:  # Check if there are Specialised rows\n",
        "    specialised_subtotal = specialised_rows.agg({\n",
        "        'Value (SGD)': 'sum',\n",
        "        'Value (USD)': 'sum',\n",
        "        'Allocation': 'sum',\n",
        "        'Risk rating': lambda x: np.average(x.astype(float), weights=specialised_rows.loc[x.index, 'Allocation'])\n",
        "    })\n",
        "    specialised_subtotal['Portfolio ID'] = 'Specialised'\n",
        "  else:\n",
        "      specialised_subtotal = pd.Series({\n",
        "          'Value (SGD)': 0,\n",
        "          'Value (USD)': 0,\n",
        "          'Allocation': 0,\n",
        "          'Risk rating': 0\n",
        "      }, dtype=object)  # Using object dtype to handle mixed types\n",
        "      specialised_subtotal['Portfolio ID'] = 'Specialised'\n",
        "      specialised_subtotal = specialised_subtotal.to_frame().T  # Convert to DataFrame\n",
        "\n",
        "  # core_subtotal = growth_portfolios[growth_portfolios['L2_classification']=='Core'].sum(numeric_only=True)\n",
        "  # core_subtotal['Portfolio ID'] = 'Core'\n",
        "\n",
        "  # specialised_subtotal = growth_portfolios[growth_portfolios['L2_classification']=='Specialised'].sum(numeric_only=True)\n",
        "  # specialised_subtotal['Portfolio ID'] = 'Specialised'\n",
        "\n",
        "  total_row_growth = pd.DataFrame({\n",
        "    col: [\n",
        "        # Sum numeric columns\n",
        "        growth_portfolios[col].sum() if col in ['Value (SGD)', 'Value (USD)', 'Invested Amount', 'P&L since inception', 'Dividend (SGD)', 'Allocation'] else\n",
        "        # Calculate weighted average for Risk rating column safely\n",
        "        ((growth_portfolios[col] * growth_portfolios['Allocation']).sum() / growth_portfolios['Allocation'].sum())\n",
        "        if col == 'Risk rating' and growth_portfolios['Allocation'].sum() != 0 else\n",
        "        ''  # Keep other columns empty\n",
        "    ] for col in growth_portfolios.columns\n",
        "}, index=['Total'])\n",
        "\n",
        "  total_row_growth.iloc[0, 0] = 'Total'\n",
        "\n",
        "  # if total_row_growth['Value (SGD)'].values[0] > 0:  # Check if NAV (SGD) is greater than 0\n",
        "  #     growth_portfolios = pd.concat([growth_portfolios, total_row_growth])\n",
        "\n",
        "  # growth_portfolios['Portfolio Type'] = pd.Categorical(\n",
        "  #     growth_portfolios['Portfolio Type'],\n",
        "  #     categories=order_of_ports,\n",
        "  #     ordered=True\n",
        "  # )\n",
        "\n",
        "  # Sort the DataFrame\n",
        "\n",
        "  # growth_portfolios = pd.concat([core_rows, core_subtotal.to_frame().T, specialised_rows, specialised_subtotal.to_frame().T, other_rows])\n",
        "\n",
        "  growth_portfolios_list = []  # Start with an empty list\n",
        "  growth_portfolios_list.append(core_rows)\n",
        "\n",
        "  if core_rows['Value (SGD)'].sum() != 0:\n",
        "      growth_portfolios_list.append(core_subtotal.to_frame().T)\n",
        "\n",
        "  growth_portfolios_list.append(specialised_rows)\n",
        "\n",
        "  if specialised_rows['Value (SGD)'].sum() != 0:\n",
        "      growth_portfolios_list.append(specialised_subtotal.to_frame().T)\n",
        "\n",
        "  growth_portfolios_list.append(total_row_growth)\n",
        "\n",
        "  # Concatenate the list of DataFrames\n",
        "  growth_portfolios = pd.concat(growth_portfolios_list)\n",
        "\n",
        "  growth_portfolios[['Value (SGD)', 'Value (USD)']] = growth_portfolios[['Value (SGD)', 'Value (USD)']].applymap(lambda x: \"{:,.2f}\".format(x) if isinstance(x, (int, float)) else x)\n",
        "  growth_portfolios[['Risk rating']] = growth_portfolios[['Risk rating']].applymap(lambda x: \"{:,.1f}\".format(x) if isinstance(x, (int, float)) else x)\n",
        "  growth_portfolios['Allocation'] = (growth_portfolios['Allocation'] * 100).map('{:.2f}%'.format)\n",
        "\n",
        "  for col in growth_portfolios.columns:\n",
        "      if pd.api.types.is_categorical_dtype(growth_portfolios[col]):\n",
        "          # Add an empty string to the categories\n",
        "          growth_portfolios[col] = growth_portfolios[col].cat.add_categories([''])\n",
        "          # Fill NaN with the empty string\n",
        "          growth_portfolios[col] = growth_portfolios[col].fillna('')\n",
        "\n",
        "      elif growth_portfolios[col].dtype == 'object':  # For string columns\n",
        "          growth_portfolios[col] = growth_portfolios[col].fillna('')\n",
        "\n",
        "      else:  # For numeric columns\n",
        "          growth_portfolios[col] = growth_portfolios[col].fillna(0)\n",
        "\n",
        "  growth_portfolios = growth_portfolios[['Portfolio ID', 'internal_port_name', 'Risk rating', 'Value (SGD)', 'Allocation']]\n",
        "  growth_portfolios.rename(columns={'internal_port_name': 'Portfolio Type', 'Risk rating':'Risk rating (0-5)'}, inplace=True)\n",
        "\n",
        "  ###################################################################################################################################################################################################\n",
        "  # INCOME & PRESERVATION PORTFOLIOS TABLE\n",
        "  income_pres_portfolios = None\n",
        "  income_preservation_fi_metrics = df_fi_metrics[[ticker for ticker in df_fi_metrics.columns if ticker in income_preservation_groups]]\n",
        "  # Create a dictionary for ticker to MB_port_name mapping\n",
        "  ticker_to_mb_mapping = dict(zip(syfe_port_mapping['internal_port_name'], syfe_port_mapping['MB_port_name']))\n",
        "  income_preservation_fi_metrics = income_preservation_fi_metrics.rename(columns=ticker_to_mb_mapping)\n",
        "  income_preservation_fi_metrics.T[['T12M dividend yield']]\n",
        "\n",
        "  income_pres_portfolios = all_portfolios_summary[all_portfolios_summary['L1_classification']=='Income & Preservation']\n",
        "  income_pres_portfolios = pd.merge(income_pres_portfolios, income_preservation_fi_metrics.T[['T12M dividend yield']], left_on='Portfolio Type', right_index=True, how='left')\n",
        "  income_pres_portfolios['Est. Yield (%)'] = income_pres_portfolios.apply(lambda row: row['T12M dividend yield'] if row['Portfolio Type'] != 'CASH_PLUS_GUARANTEED_SGD' else row['Guaranteed rate'], axis=1)\n",
        "  income_pres_portfolios = income_pres_portfolios.drop(columns=['T12M dividend yield', 'Guaranteed rate'])\n",
        "\n",
        "  # Ensure correct data types\n",
        "  income_pres_portfolios['Allocation'] = pd.to_numeric(income_pres_portfolios['Value (SGD)'], errors='coerce') / income_pres_portfolios['Value (SGD)'].sum()\n",
        "  income_pres_portfolios['Est. Yield (%)'] = pd.to_numeric(income_pres_portfolios['Est. Yield (%)'], errors='coerce')\n",
        "  income_pres_portfolios['Allocation'] = pd.to_numeric(income_pres_portfolios['Allocation'], errors='coerce')\n",
        "  income_pres_portfolios['Proj. Dividend (SGD)'] = income_pres_portfolios['Est. Yield (%)'] / 100 * income_pres_portfolios['Value (SGD)']\n",
        "\n",
        "  # Calculate subtotals\n",
        "  income_plus_subtotal = calculate_subtotal_income_preservation(income_pres_portfolios, 'Income+')\n",
        "  reits_subtotal = calculate_subtotal_income_preservation(income_pres_portfolios, 'REITs')\n",
        "  alt_subtotal = calculate_subtotal_income_preservation(income_pres_portfolios, 'Alternatives')\n",
        "  cash_mmf_subtotal = calculate_subtotal_income_preservation(income_pres_portfolios, 'Cash / MMF')\n",
        "\n",
        "  income_pres_portfolios['Est. Yield (%)'] = pd.to_numeric(income_pres_portfolios['Est. Yield (%)'], errors='coerce')\n",
        "  income_pres_portfolios['Proj. Dividend (SGD)'] = pd.to_numeric(income_pres_portfolios['Proj. Dividend (SGD)'], errors='coerce')\n",
        "\n",
        "  total_row_income_pres = pd.DataFrame({\n",
        "    col: [\n",
        "        # Sum numeric columns\n",
        "        income_pres_portfolios[col].sum() if col in ['Value (SGD)', 'Value (USD)', 'Invested Amount', 'P&L since inception', 'Dividend (SGD)', 'Allocation', 'Proj. Dividend (SGD)'] else\n",
        "        # Calculate weighted average for Yield (%) and Risk rating columns safely\n",
        "        ((income_pres_portfolios[col] * income_pres_portfolios['Allocation']).sum() / income_pres_portfolios['Allocation'].sum())\n",
        "        if col in ['Est. Yield (%)', 'Risk rating'] and income_pres_portfolios['Allocation'].sum() != 0 else\n",
        "        ''  # Keep other columns empty\n",
        "    ] for col in income_pres_portfolios.columns\n",
        "}, index=['Total'])\n",
        "\n",
        "  total_row_income_pres.iloc[0, 0] = 'Total'\n",
        "\n",
        "  if total_row_income_pres['Value (SGD)'].values[0] > 0:  # Check if NAV (SGD) is greater than 0\n",
        "      income_pres_portfolios = pd.concat([income_pres_portfolios, total_row_income_pres])\n",
        "\n",
        "  income_pres_portfolios['Portfolio Type'] = pd.Categorical(\n",
        "      income_pres_portfolios['Portfolio Type'],\n",
        "      categories=order_of_ports,\n",
        "      ordered=True\n",
        "  )\n",
        "\n",
        "  # Sort the DataFrame\n",
        "  income_pres_portfolios = income_pres_portfolios.sort_values(by='Portfolio Type').reset_index(drop=True)\n",
        "  income_plus_rows = income_pres_portfolios[income_pres_portfolios['L2_classification'] == 'Income+']\n",
        "  reits_rows = income_pres_portfolios[income_pres_portfolios['L2_classification'] == 'REITs']\n",
        "  alt_rows = income_pres_portfolios[income_pres_portfolios['L2_classification'] == 'Alternatives']\n",
        "  cm_rows = income_pres_portfolios[income_pres_portfolios['L2_classification'] == 'Cash / MMF']\n",
        "  others_rows = income_pres_portfolios[~income_pres_portfolios['L2_classification'].isin(['Income+', 'REITs', 'Alternatives', 'Cash / MMF'])]\n",
        "\n",
        "\n",
        "  # income_pres_portfolios = pd.concat([income_plus_rows, income_plus_subtotal.to_frame().T, reits_rows, reits_subtotal.to_frame().T, cm_rows, cash_mmf_subtotal.to_frame().T, total_row_income_pres])\n",
        "\n",
        "  income_pres_portfolios_list = []  # Start with an empty list\n",
        "  income_pres_portfolios_list.append(income_plus_rows)\n",
        "\n",
        "  if income_plus_rows['Value (SGD)'].sum() != 0:\n",
        "      income_pres_portfolios_list.append(income_plus_subtotal.to_frame().T)\n",
        "\n",
        "  income_pres_portfolios_list.append(reits_rows)\n",
        "\n",
        "  if reits_rows['Value (SGD)'].sum() != 0:\n",
        "      income_pres_portfolios_list.append(reits_subtotal.to_frame().T)\n",
        "\n",
        "  income_pres_portfolios_list.append(alt_rows)\n",
        "\n",
        "  if alt_rows['Value (SGD)'].sum() != 0:\n",
        "      income_pres_portfolios_list.append(alt_subtotal.to_frame().T)\n",
        "\n",
        "  income_pres_portfolios_list.append(cm_rows)\n",
        "\n",
        "  if cm_rows['Value (SGD)'].sum() != 0:\n",
        "      income_pres_portfolios_list.append(cash_mmf_subtotal.to_frame().T)\n",
        "\n",
        "  income_pres_portfolios_list.append(total_row_income_pres)\n",
        "\n",
        "  # Concatenate the list of DataFrames\n",
        "  income_pres_portfolios = pd.concat(income_pres_portfolios_list)\n",
        "\n",
        "  income_pres_portfolios[['Value (SGD)', 'Value (USD)', 'Est. Yield (%)', 'Dividend (SGD)', 'Proj. Dividend (SGD)']] = income_pres_portfolios[['Value (SGD)', 'Value (USD)', 'Est. Yield (%)', 'Dividend (SGD)', 'Proj. Dividend (SGD)']].applymap(lambda x: \"{:,.2f}\".format(x) if isinstance(x, (int, float)) else x)\n",
        "  income_pres_portfolios[['Risk rating']] = income_pres_portfolios[['Risk rating']].applymap(lambda x: \"{:,.1f}\".format(x) if isinstance(x, (int, float)) else x)\n",
        "  income_pres_portfolios['Allocation'] = (income_pres_portfolios['Allocation'] * 100).map('{:.2f}%'.format)\n",
        "\n",
        "  for col in income_pres_portfolios.columns:\n",
        "      if pd.api.types.is_categorical_dtype(income_pres_portfolios[col]):\n",
        "          # Add an empty string to the categories\n",
        "          income_pres_portfolios[col] = income_pres_portfolios[col].cat.add_categories([''])\n",
        "          # Fill NaN with the empty string\n",
        "          income_pres_portfolios[col] = income_pres_portfolios[col].fillna('')\n",
        "\n",
        "      elif income_pres_portfolios[col].dtype == 'object':  # For string columns\n",
        "          income_pres_portfolios[col] = income_pres_portfolios[col].fillna('')\n",
        "\n",
        "      else:  # For numeric columns\n",
        "          income_pres_portfolios[col] = income_pres_portfolios[col].fillna(0)\n",
        "\n",
        "  income_pres_portfolios['Dividend Option adj'] = income_pres_portfolios.apply(dividend_option_adj, axis=1)\n",
        "  income_pres_portfolios.drop(columns=['Dividend Option'], inplace=True)\n",
        "\n",
        "  # Apply the function to the 'Maturity Period' column\n",
        "  income_pres_portfolios['Maturity period'] = income_pres_portfolios['Maturity period'].apply(format_maturity_period)\n",
        "\n",
        "  income_pres_portfolios = income_pres_portfolios[['Portfolio ID', 'internal_port_name', 'Risk rating', 'Value (SGD)', 'Est. Yield (%)', 'Proj. Dividend (SGD)', 'Dividend Option adj','Maturity period', 'Allocation']]\n",
        "  income_pres_portfolios.rename(columns={'internal_port_name': 'Portfolio Type', 'Est. Yield (%)':'Est. Yield (%)*',\n",
        "                                         'Proj. Dividend (SGD)':'Ann. Proj. Dividend (SGD)**', 'Dividend Option adj':'Dividend Option',\n",
        "                                         'Risk rating': 'Risk rating (0-5)'}, inplace=True)\n",
        "\n",
        "  ###################################################################################################################################################################################################\n",
        "\n",
        "  # GENERATE PDF\n",
        "\n",
        "  template_pdf = PyPDF2.PdfReader(data_path + 'Portfolio_Visualiser_Template_Landscape.pdf')\n",
        "\n",
        "  # if client_latest_alloc[i][client_latest_alloc[i].index.isin(growth_groups)].empty == False:\n",
        "  #   growth_breakdown_chart = plot_sunburst_chart_growth(client_latest_alloc[i][client_latest_alloc[i].index.isin(growth_groups)], title='Growth Allocation')\n",
        "\n",
        "  # if client_latest_alloc[i][client_latest_alloc[i].index.isin(income_preservation_groups)].empty == False:\n",
        "  #   income_pres_breakdown_chart = plot_sunburst_chart_income_preservation(client_latest_alloc[i][client_latest_alloc[i].index.isin(income_preservation_groups)],\n",
        "  #                                                               title='Income & Preservation Allocation')\n",
        "  # if client_latest_alloc[i][client_latest_alloc[i].index.isin(income_preservation_groups)].empty == False and client_latest_alloc[i][client_latest_alloc[i].index.isin(growth_groups)].empty == False:\n",
        "  #   growth_income_breakdown_chart = plot_sunburst_chart_growth_income(client_latest_alloc[i], title='Growth & Income Allocation')\n",
        "\n",
        "  top_asset_class_chart_all = plot_pie_chart_topX(assetclass_breakdown_all.iloc[:, 0], title='Asset Class Exposure', colors=syfe_colors)\n",
        "  top_asset_class_chart_growth = plot_pie_chart_topX(assetclass_breakdown_growth.iloc[:, 0], title='Asset Class Exposure', colors=syfe_colors)\n",
        "  top_asset_class_chart_income_preservation = plot_pie_chart_topX(assetclass_breakdown_income_preservation.iloc[:, 0], title='Asset Class Exposure', colors=syfe_colors)\n",
        "\n",
        "  top_country_chart_all = plot_bar_chart_topX([country_breakdown_all.iloc[:, 0]], title=\"Country Exposure\",  colors=syfe_colors)\n",
        "  top_country_chart_growth = plot_bar_chart_topX([country_breakdown_growth.iloc[:, 0], df_country['Core Growth']], title=\"Country Exposure\",  colors=syfe_colors)\n",
        "  top_country_chart_income_preservation = plot_bar_chart_topX([country_breakdown_income_preservation.iloc[:, 0]], title=\"Country Exposure\",  colors=syfe_colors)\n",
        "\n",
        "  top_sector_chart_growth = plot_bar_chart_topX([sector_breakdown_growth.iloc[:, 0], df_sector['Core Growth']], title=\"Sector Exposure\",  colors=syfe_colors,legend_names=['Growth Portfolio', 'Benchmark'])\n",
        "  top_sector_chart_income_preservation = plot_bar_chart_topX([sector_breakdown_income_preservation.iloc[:, 0]], title=\"Sector Exposure\", colors=syfe_colors)\n",
        "\n",
        "  # CREATE INDIVIDUAL PDF & MERGE PDFS\n",
        "  # Assuming you have your table DataFrame, title, and chart variables\n",
        "  # display(growth_portfolios, income_pres_portfolios)\n",
        "  # create_pdf_with_table(\"portfolio_summary.pdf\", all_portfolios_summary_final, \"Portfolio Summary\",\n",
        "  #                                  col_width_manual=[130, 130, 110, 120, 90, 90, 110])\n",
        "\n",
        "  create_pdf_with_table_and_charts(\"portfolio_summary.pdf\", all_portfolios_summary_final, \"Portfolio Summary\",[top_asset_class_chart_all, top_country_chart_all],\n",
        "                                   col_width_manual=[130, 130, 110, 120, 90, 90, 110])\n",
        "\n",
        "  if (growth_portfolios.loc['Total']['Value (SGD)'] == '0.00') == False:\n",
        "      create_pdf_with_table(\"growth_portfolios.pdf\", growth_portfolios, \"Growth Portfolios\",\n",
        "                                       col_width_manual=[156, 156, 156, 156, 156])\n",
        "      create_pdf_with_charts(\"growth_portfolios_charts.pdf\",\n",
        "                                       [top_asset_class_chart_growth, top_country_chart_growth, top_sector_chart_growth, top_sector_chart_growth])\n",
        "\n",
        "\n",
        "  # if (growth_portfolios.loc['Total']['Value (SGD)'] == '0.00') == False:\n",
        "  #     create_pdf_with_table_and_charts(\"growth_portfolios.pdf\", growth_portfolios, \"Growth Portfolios\", [top_asset_class_chart_growth, top_country_chart_growth, top_sector_chart_growth],\n",
        "  #                                      col_width_manual=[156, 156, 156, 156, 156])\n",
        "\n",
        "  if (income_pres_portfolios.loc['Total']['Value (SGD)'] == '0.00') == False:\n",
        "      create_pdf_with_table(\"income_preservation_portfolios.pdf\", income_pres_portfolios, \"Income & Preservation Portfolios\",\n",
        "                                      col_width_manual=[75, 130, 65, 90, 95, 105, 100, 70, 50])\n",
        "\n",
        "      create_pdf_with_charts(\"income_preservation_portfolios_charts.pdf\",\n",
        "       [top_asset_class_chart_income_preservation , top_country_chart_income_preservation, top_sector_chart_income_preservation, top_sector_chart_income_preservation])\n",
        "\n",
        "\n",
        "  # if (income_pres_portfolios.loc['Total']['Value (SGD)'] == '0.00') == False:\n",
        "  #     create_pdf_with_table_and_charts(\"income_preservation_portfolios.pdf\", income_pres_portfolios, \"Income & Preservation Portfolios\",\n",
        "  #                                     [top_asset_class_chart_income_preservation , top_country_chart_income_preservation, top_sector_chart_income_preservation],\n",
        "  #                                     col_width_manual=[75, 130, 65, 90, 95, 105, 100, 70, 50])\n",
        "\n",
        "  # Merge PDFs\n",
        "  appendix_pdf = PyPDF2.PdfReader(data_path + 'Portfolio_Visualiser_Appendix.pdf')\n",
        "\n",
        "  merger = PdfMerger()\n",
        "  merger.append(\"portfolio_summary.pdf\")\n",
        "  if (growth_portfolios.loc['Total']['Value (SGD)'] == '0.00') == False:\n",
        "      merger.append(\"growth_portfolios.pdf\")\n",
        "      merger.append(\"growth_portfolios_charts.pdf\")\n",
        "  if (income_pres_portfolios.loc['Total']['Value (SGD)'] == '0.00') == False:\n",
        "      merger.append(\"income_preservation_portfolios.pdf\")\n",
        "      merger.append(\"income_preservation_portfolios_charts.pdf\")\n",
        "  merger.write(str(client_id) + \"_report_merged.pdf\")\n",
        "\n",
        "\n",
        "  template_pdf_path = os.path.join(data_path, \"Portfolio_Visualiser_Template_Landscape.pdf\")\n",
        "  cover_pdf_path = os.path.join(data_path, \"Portfolio_Visualiser_Cover.pdf\")\n",
        "  overlay_pdf_path = os.path.join('/content/Projects/' + str(client_id) + '_report_merged.pdf')\n",
        "  output_pdf_path = os.path.join('/content/Projects/' + client_name + ' ' + str(client_id) + ' Portfolio Summary V1 [Date].pdf')\n",
        "\n",
        "  add_client_name_to_cover(cover_pdf_path, client_name=client_name, client_id=client_id) # add client name to pdf cover\n",
        "  cover_pdf_name_path = os.path.join(data_path, \"Portfolio_Visualiser_Cover_\" + str(client_id) + \".pdf\")\n",
        "\n",
        "  # Merge overlay onto the template PDF\n",
        "  merge_with_template(template_pdf_path, overlay_pdf_path, output_pdf_path)\n",
        "\n",
        "  merger = PdfMerger()\n",
        "  merger.append(output_pdf_path)\n",
        "  merger.append(appendix_pdf)\n",
        "  merger.write(output_pdf_path)\n",
        "\n",
        "  add_page_numbers_header(output_pdf_path, output_pdf_path, client_name=client_name, client_id=client_id)\n",
        "  merger = PdfMerger()\n",
        "  merger.append(cover_pdf_name_path)\n",
        "  merger.append(output_pdf_path)\n",
        "  merger.write(output_pdf_path)\n",
        "\n",
        "  files.download(output_pdf_path)\n",
        "\n",
        "  print(f\"Final report generated: {output_pdf_path}\")\n"
      ],
      "metadata": {
        "id": "zLO0ezPQDgZV",
        "outputId": "2195ebab-3b59-4505-d44c-70a9b9ca4a10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "id": "zLO0ezPQDgZV",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating report for  Firstname Lastname\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_635523ee-972f-4e21-8a26-68d7019ab2f0\", \"Firstname Lastname 12345678 Portfolio Summary V1 [Date].pdf\", 3077969)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final report generated: /content/Projects/Firstname Lastname 12345678 Portfolio Summary V1 [Date].pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forecast_portfolio(df_ret):\n",
        "    port_name = df_ret.columns\n",
        "\n",
        "    # Initialize NAV DataFrame\n",
        "    df_nav = pd.DataFrame(0, columns=df_ret.columns, index=df_ret.index)\n",
        "    df_nav.iloc[0] = 100\n",
        "\n",
        "    # Calculate NAV series\n",
        "    for i in range(1, len(df_ret)):\n",
        "        df_nav.iloc[i] = df_nav.iloc[i - 1] * (1 + df_ret.iloc[i])\n",
        "\n",
        "    geo_ret = np.log(df_nav / df_nav.shift(1))  # Calculate geometric returns\n",
        "\n",
        "    # Calculate average returns and standard deviations\n",
        "    avg_ret_list = geo_ret.mean() * 261  # Annualized mean return\n",
        "    stdev_list = geo_ret.std() * np.sqrt(261)  # Annualized standard deviation\n",
        "\n",
        "    conf_interval = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
        "    all_simulations = pd.DataFrame()\n",
        "\n",
        "    for n, portfolio in enumerate(port_name):\n",
        "        simulations = pd.DataFrame()\n",
        "        simulations['Month'] = range(0, 360)\n",
        "        simulations['ExpRtn'] = avg_ret_list[portfolio]\n",
        "        simulations['Stdev'] = stdev_list[portfolio]\n",
        "\n",
        "        for percentile in conf_interval:\n",
        "            percentile_label = f\"{int(percentile * 100)}th Percentile\"\n",
        "            simulations[percentile_label] = 100\n",
        "            for i in range(1, len(simulations)):\n",
        "                simulations.loc[i, percentile_label] = math.exp(\n",
        "                    (simulations.loc[i, 'Month'] / 12 * simulations.loc[i, 'ExpRtn']) +\n",
        "                    (np.sqrt(simulations.loc[i, 'Month'] / 12) * simulations.loc[i, 'Stdev'] * norm.ppf(percentile))\n",
        "                ) * 100\n",
        "\n",
        "        simulations = simulations.drop(columns=['ExpRtn', 'Stdev'])\n",
        "        simulations.set_index('Month', inplace=True)\n",
        "        simulations.columns = [f\"{portfolio}_{col}\" for col in simulations.columns]\n",
        "\n",
        "        all_simulations = pd.concat([all_simulations, simulations], axis=1)\n",
        "\n",
        "    return all_simulations"
      ],
      "metadata": {
        "id": "MvtdICtI-gIy"
      },
      "id": "MvtdICtI-gIy",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Archive\n",
        "\n",
        "# Func sunburst charts\n",
        "# Function to save charts to a single PDF\n",
        "\n",
        "from reportlab.lib.units import inch\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.units import inch\n",
        "from reportlab.lib.pagesizes import letter, A4, landscape\n",
        "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, BaseDocTemplate, Frame, PageTemplate, PageBreak\n",
        "from reportlab.lib import colors\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "from reportlab.lib.units import cm  # Import cm for specifying width in centimeters\n",
        "\n",
        "\n",
        "########################################################################################################################\n",
        "\n",
        "syfe_colors = ['#263159', '#2f51c9', '#879be3', '#bcbed7', '#dedfee','#fff2cc', '#ffe599', '#e3bf61', '#666666', '#7d839b', '#414e7d']\n",
        "\n",
        "def convert_maturity_period(value):\n",
        "    \"\"\"Converts maturity period values to the desired format, handling non-string values.\"\"\"\n",
        "    if isinstance(value, str):  # Check if value is a string\n",
        "        match = re.search(r'(\\w+)_MONTHS', value)\n",
        "        if match:\n",
        "            period_num = {\n",
        "                'THREE': '3',\n",
        "                'SIX': '6',\n",
        "                'TWELVE': '12'  # Add more mappings as needed\n",
        "            }.get(match.group(1))\n",
        "            if period_num:\n",
        "                return f\"{period_num} months\"\n",
        "    return value  # Return original value if not a string or no match\n",
        "\n",
        "def plot_sunburst_chart_MP(df_allocation, title=None, width=1000, height=600):\n",
        "    # Define groups\n",
        "    core_groups = ['Core E100', 'Core Growth', 'Core Balanced', 'Core Defensive', 'SRS E100']\n",
        "    specialised_groups = ['China Growth', 'Disruptive Tech', 'ESG & Clean Energy', 'Healthcare Innovation', 'Downside protected']\n",
        "    passive_income_groups = ['Income Enhance', 'Income Preserve', 'REIT 100', 'REIT RM', 'SRS Income Enhance', 'SRS Income Preserve']\n",
        "    custom_groups = ['CUSTOM_USD']\n",
        "\n",
        "    # Filter out rows with allocation <= 0.0001 or NaN\n",
        "    df_allocation = df_allocation[df_allocation != 0].dropna()\n",
        "\n",
        "    # Categorize portfolios\n",
        "    categories = []\n",
        "    for portfolio in df_allocation.index:\n",
        "        if portfolio in core_groups:\n",
        "            categories.append('Core')\n",
        "        elif portfolio in specialised_groups:\n",
        "            categories.append('Specialised')\n",
        "        elif portfolio in passive_income_groups:\n",
        "            categories.append('Passive Income')\n",
        "        elif portfolio in custom_groups:\n",
        "            categories.append('Custom')\n",
        "        else:\n",
        "            categories.append('Other')\n",
        "\n",
        "    # Dynamically create the list of unique categories based on the data\n",
        "    unique_categories = sorted(set(categories))  # Only include categories present in the data\n",
        "    labels = ['Portfolio Allocation'] + unique_categories + list(df_allocation.index)\n",
        "    parents = [''] + ['Portfolio Allocation'] * len(unique_categories) + categories\n",
        "\n",
        "    # Calculate values dynamically for existing categories\n",
        "    category_sums = []\n",
        "    for unique_cat in unique_categories:\n",
        "        category_sum = df_allocation.loc[\n",
        "            [portfolio for portfolio in df_allocation.index if\n",
        "             (portfolio in core_groups and unique_cat == 'Core') or\n",
        "             (portfolio in specialised_groups and unique_cat == 'Specialised') or\n",
        "             (portfolio in custom_groups and unique_cat == 'Custom') or\n",
        "             (portfolio in passive_income_groups and unique_cat == 'Passive Income')]\n",
        "        ].sum()\n",
        "        category_sums.append(category_sum)\n",
        "\n",
        "    values = [df_allocation.sum()] + category_sums + list(df_allocation.values)\n",
        "\n",
        "    # Filter out nodes where values <= 0\n",
        "    filtered_data = [\n",
        "        (label, parent, value) for label, parent, value in zip(labels, parents, values) if value > 0\n",
        "    ]\n",
        "    filtered_labels = [x[0] for x in filtered_data]\n",
        "    filtered_parents = [x[1] for x in filtered_data]\n",
        "    filtered_values = [x[2] for x in filtered_data]\n",
        "\n",
        "    # Create the sunburst chart\n",
        "    fig = go.Figure(go.Sunburst(\n",
        "        labels=filtered_labels,\n",
        "        parents=filtered_parents,\n",
        "        values=filtered_values,\n",
        "        branchvalues=\"total\",\n",
        "        textinfo=\"label+percent parent\",  # Include labels and percent for all nodes\n",
        "        insidetextorientation=\"horizontal\",\n",
        "    ))\n",
        "\n",
        "    # Customize traces\n",
        "    fig.update_traces(\n",
        "        texttemplate=[\n",
        "            \"%{label}<br>%{percentRoot:.2%}\" if parent != \"\" else \"\"\n",
        "            for parent in filtered_parents\n",
        "        ],\n",
        "        outsidetextfont={\"size\": 12, \"family\": \"Arial\"},\n",
        "        marker=dict(line=dict(width=0.5, color=\"white\"))\n",
        "    )\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        title_text=title,\n",
        "        margin=dict(t=50, l=0, r=0, b=0),\n",
        "        width=width,\n",
        "        height=height,\n",
        "        uniformtext=dict(minsize=10, mode='show')  # Uniform text size setting\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "\n",
        "def plot_sunburst_chart_MP_and_CM(df_allocation, title=None, width=1000, height=600):\n",
        "    # Define groups\n",
        "    core_groups = ['Core E100', 'Core Growth', 'Core Balanced', 'Core Defensive', 'SRS E100']\n",
        "    specialised_groups = ['China Growth', 'Disruptive Tech', 'ESG & Clean Energy', 'Healthcare Innovation', 'Downside protected']\n",
        "    passive_income_groups = ['Income Enhance', 'Income Preserve', 'REIT 100', 'REIT RM', 'SRS Income Enhance', 'SRS Income Preserve']\n",
        "    custom_groups = ['CUSTOM_USD']\n",
        "\n",
        "    mp_groups = core_groups + specialised_groups + passive_income_groups + custom_groups\n",
        "    cm_groups = ['Cash SGD flexi', 'Cash USD flexi', 'Cash SGD guaranteed']\n",
        "\n",
        "    # Filter out rows with allocation of 0 or NaN\n",
        "    df_allocation = df_allocation[df_allocation != 0].dropna()\n",
        "\n",
        "    # Categorize portfolios\n",
        "    categories = []\n",
        "    for portfolio in df_allocation.index:\n",
        "        if portfolio in mp_groups:\n",
        "            categories.append('Managed Portfolios')\n",
        "        elif portfolio in cm_groups:\n",
        "            categories.append('Cash Management')\n",
        "        else:\n",
        "            categories.append('Other')\n",
        "\n",
        "    # Create labels, parents, and values\n",
        "    unique_categories = ['Managed Portfolios', 'Cash Management']\n",
        "    labels = ['Portfolio Allocation'] + unique_categories + list(df_allocation.index)\n",
        "    parents = [''] + ['Portfolio Allocation'] * len(unique_categories) + categories\n",
        "\n",
        "    # Corrected calculation of values\n",
        "    category_sums = []\n",
        "    for unique_cat in unique_categories:\n",
        "        category_sum = df_allocation.loc[[portfolio for portfolio in df_allocation.index if portfolio in mp_groups and unique_cat == 'Managed Portfolios' or \\\n",
        "                                          portfolio in cm_groups and unique_cat == 'Cash Management']].sum()\n",
        "        category_sums.append(category_sum)\n",
        "\n",
        "    values = [df_allocation.sum()] + category_sums + list(df_allocation.values)\n",
        "\n",
        "    # Create the sunburst chart\n",
        "    fig = go.Figure(go.Sunburst(\n",
        "    labels=labels,\n",
        "    parents=parents,\n",
        "    values=values,\n",
        "    branchvalues=\"total\",\n",
        "    textinfo=\"label+percent parent\",  # Include labels and percent for all nodes\n",
        "    insidetextorientation=\"horizontal\",))\n",
        "\n",
        "    # Customize traces to hide the root node label\n",
        "    fig.update_traces(\n",
        "    texttemplate=[\n",
        "        \"%{label}<br>%{percentRoot:.2%}\" if parent != \"\" else \"\"\n",
        "        for parent in parents\n",
        "    ],\n",
        "    outsidetextfont={\"size\": 12},\n",
        "    marker=dict(line=dict(width=0.5, color=\"white\"))\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        title_text=title,\n",
        "        margin=dict(t=50, l=0, r=0, b=0),\n",
        "        width=width,\n",
        "        height=height,\n",
        "        uniformtext=dict(minsize=10, mode='show')  # Uniform text size setting\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "def plot_sunburst_chart_growth(df_allocation, title=None, width=1000, height=600):\n",
        "    # Define groups\n",
        "    core_groups = ['Core E100', 'Core Growth', 'Core Balanced', 'Core Defensive', 'SRS E100']\n",
        "    specialised_groups = ['China Growth', 'Disruptive Tech', 'ESG & Clean Energy', 'Healthcare Innovation', 'Downside protected', 'Custom USD']\n",
        "\n",
        "    # Filter out rows with allocation of 0 or NaN\n",
        "    df_allocation = df_allocation[df_allocation != 0].dropna()\n",
        "\n",
        "    # Categorize portfolios\n",
        "    categories = []\n",
        "    for portfolio in df_allocation.index:\n",
        "        if portfolio in core_groups:\n",
        "            categories.append('Core')\n",
        "        elif portfolio in specialised_groups:\n",
        "            categories.append('Specialised')\n",
        "        else:\n",
        "            categories.append('Other')\n",
        "\n",
        "    # Create labels, parents, and values\n",
        "    unique_categories = ['Core', 'Specialised']\n",
        "    labels = ['Portfolio Allocation'] + unique_categories + list(df_allocation.index)\n",
        "    parents = [''] + ['Portfolio Allocation'] * len(unique_categories) + categories\n",
        "\n",
        "    # Calculate category sums\n",
        "    category_sums = []\n",
        "    for unique_cat in unique_categories:\n",
        "        category_sum = df_allocation.loc[[portfolio for portfolio in df_allocation.index if portfolio in core_groups and unique_cat == 'Core' or \\\n",
        "                                          portfolio in specialised_groups and unique_cat == 'Specialised']].sum()\n",
        "        category_sums.append(category_sum)\n",
        "\n",
        "    values = [df_allocation.sum()] + category_sums + list(df_allocation.values)\n",
        "\n",
        "    # Filter nodes with values > 0\n",
        "    filtered_data = [\n",
        "        (label, parent, value) for label, parent, value in zip(labels, parents, values) if value > 0\n",
        "    ]\n",
        "    filtered_labels = [x[0] for x in filtered_data]\n",
        "    filtered_parents = [x[1] for x in filtered_data]\n",
        "    filtered_values = [x[2] for x in filtered_data]\n",
        "\n",
        "    # Create the sunburst chart\n",
        "    fig = go.Figure(go.Sunburst(\n",
        "        labels=filtered_labels,\n",
        "        parents=filtered_parents,\n",
        "        values=filtered_values,\n",
        "        branchvalues=\"total\",\n",
        "        textinfo=\"label+percent parent\",  # Include labels and percent for all nodes\n",
        "        insidetextorientation=\"horizontal\",\n",
        "    ))\n",
        "\n",
        "    # Customize traces to hide the root node label\n",
        "    fig.update_traces(\n",
        "        texttemplate=[\n",
        "            \"%{label}<br>%{percentRoot:.2%}\" if parent != \"\" else \"\"\n",
        "            for parent in filtered_parents\n",
        "        ],\n",
        "        outsidetextfont={\"size\": 12},\n",
        "        marker=dict(line=dict(width=0.5, color=\"white\"))\n",
        "    )\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(\n",
        "        title_text=title,\n",
        "        margin=dict(t=50, l=0, r=0, b=0),\n",
        "        width=width,\n",
        "        height=height,\n",
        "        uniformtext=dict(minsize=10, mode='show')  # Uniform text size setting\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "def plot_sunburst_chart_income_preservation(df_allocation, title=None, width=1000, height=600):\n",
        "    # Define groups\n",
        "    income_groups = ['Income Enhance', 'Income Preserve', 'SRS Income Enhance', 'SRS Income Preserve']\n",
        "    reits_groups = ['REIT 100', 'REIT RM']\n",
        "    cm_groups = ['Cash SGD flexi', 'Cash USD flexi', 'Cash SGD guaranteed']\n",
        "\n",
        "    # Filter out rows with allocation of 0 or NaN\n",
        "    df_allocation = df_allocation[df_allocation != 0].dropna()\n",
        "\n",
        "    # Categorize portfolios\n",
        "    categories = []\n",
        "    for portfolio in df_allocation.index:\n",
        "        if portfolio in income_groups:\n",
        "            categories.append('Bonds')\n",
        "        elif portfolio in reits_groups:\n",
        "            categories.append('REITs')\n",
        "        elif portfolio in cm_groups:\n",
        "            categories.append('Cash / MMF')\n",
        "        else:\n",
        "            categories.append('Other')\n",
        "\n",
        "    # Create labels, parents, and values\n",
        "    unique_categories = ['Bonds', 'REITs', 'Cash / MMF']\n",
        "    labels = ['Portfolio Allocation'] + unique_categories + list(df_allocation.index)\n",
        "    parents = [''] + ['Portfolio Allocation'] * len(unique_categories) + categories\n",
        "\n",
        "    # Corrected calculation of values\n",
        "    category_sums = []\n",
        "    for unique_cat in unique_categories:\n",
        "        category_sum = df_allocation.loc[[portfolio for portfolio in df_allocation.index if portfolio in income_groups and unique_cat == 'Bonds' or\n",
        "                                          portfolio in reits_groups and unique_cat == 'REITs' or\n",
        "                                          portfolio in cm_groups and unique_cat == 'Cash / MMF']].sum()\n",
        "        category_sums.append(category_sum)\n",
        "\n",
        "    values = [df_allocation.sum()] + category_sums + list(df_allocation.values)\n",
        "\n",
        "    # Create the sunburst chart\n",
        "    fig = go.Figure(go.Sunburst(\n",
        "    labels=labels,\n",
        "    parents=parents,\n",
        "    values=values,\n",
        "    branchvalues=\"total\",\n",
        "    textinfo=\"label+percent parent\",  # Include labels and percent for all nodes\n",
        "    insidetextorientation=\"horizontal\",))\n",
        "\n",
        "    # Customize traces to hide the root node label\n",
        "    fig.update_traces(\n",
        "    texttemplate=[\n",
        "        \"%{label}<br>%{percentRoot:.2%}\" if parent != \"\" else \"\"\n",
        "        for parent in parents\n",
        "    ],\n",
        "    outsidetextfont={\"size\": 12},\n",
        "    marker=dict(line=dict(width=0.5, color=\"white\"))\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        title_text=title,\n",
        "        margin=dict(t=50, l=0, r=0, b=0),\n",
        "        width=width,\n",
        "        height=height,\n",
        "        uniformtext=dict(minsize=10, mode='show')  # Uniform text size setting\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "def plot_sunburst_chart_growth_income(df_allocation, title=None, width=1000, height=600):\n",
        "    # Define groups\n",
        "    growth_groups = ['Core E100', 'Core Growth', 'Core Balanced', 'Core Defensive','SRS E100', 'China Growth','Disruptive Tech', 'ESG & Clean Energy', 'Healthcare Innovation', 'Downside protected', 'Custom USD']\n",
        "    income_preservation_groups = ['Income Enhance', 'Income Preserve','REIT 100', 'REIT RM', 'SRS Income Enhance','SRS Income Preserve', 'Cash SGD flexi', 'Cash USD flexi', 'Cash SGD guaranteed']\n",
        "\n",
        "    # Filter out rows with allocation of 0 or NaN\n",
        "    df_allocation = df_allocation[df_allocation != 0].dropna()\n",
        "\n",
        "    # Categorize portfolios\n",
        "    categories = []\n",
        "    for portfolio in df_allocation.index:\n",
        "        if portfolio in growth_groups:\n",
        "            categories.append('Growth')\n",
        "        elif portfolio in income_preservation_groups:\n",
        "            categories.append('Income & Preservation')\n",
        "        else:\n",
        "            categories.append('Other')\n",
        "\n",
        "    # Create labels, parents, and values\n",
        "    unique_categories = ['Growth', 'Income & Preservation']\n",
        "    labels = ['Portfolio Allocation'] + unique_categories + list(df_allocation.index)\n",
        "    parents = [''] + ['Portfolio Allocation'] * len(unique_categories) + categories\n",
        "\n",
        "    # Corrected calculation of values\n",
        "    category_sums = []\n",
        "    for unique_cat in unique_categories:\n",
        "        category_sum = df_allocation.loc[[portfolio for portfolio in df_allocation.index if portfolio in growth_groups and unique_cat == 'Growth' or\n",
        "                                          portfolio in income_preservation_groups and unique_cat == 'Income & Preservation']].sum()\n",
        "        category_sums.append(category_sum)\n",
        "\n",
        "    values = [df_allocation.sum()] + category_sums + list(df_allocation.values)\n",
        "\n",
        "    # Create the sunburst chart\n",
        "    fig = go.Figure(go.Sunburst(\n",
        "    labels=labels,\n",
        "    parents=parents,\n",
        "    values=values,\n",
        "    branchvalues=\"total\",\n",
        "    textinfo=\"label+percent parent\",  # Include labels and percent for all nodes\n",
        "    insidetextorientation=\"horizontal\",))\n",
        "\n",
        "    # Customize traces to hide the root node label\n",
        "    fig.update_traces(\n",
        "    texttemplate=[\n",
        "        \"%{label}<br>%{percentRoot:.2%}\" if parent != \"\" else \"\"\n",
        "        for parent in parents\n",
        "    ],\n",
        "    outsidetextfont={\"size\": 12},\n",
        "    marker=dict(line=dict(width=0.5, color=\"white\"))\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        title_text=title,\n",
        "        margin=dict(t=50, l=0, r=0, b=0),\n",
        "        width=width,\n",
        "        height=height,\n",
        "        uniformtext=dict(minsize=10, mode='show')  # Uniform text size setting\n",
        "    )\n",
        "    return fig\n",
        "\n",
        "\n",
        "# Fixed income metrics - duration, YTM, dividend yield, credit quality\n",
        "\n",
        "# # calc dividend of all constituents\n",
        "# dvd_breakdown_all = pc.exposure_analysis(client_latest_alloc_adj, df_fi_metrics.loc[['T12M dividend yield']].astype(float), latest_data=True)\n",
        "# dvd_breakdown_all = round(dvd_breakdown_all, 2)\n",
        "\n",
        "\n",
        "# # Duration, YTM and credit quality of FI components only\n",
        "# fixed_income_list = df_fi_metrics.columns[df_fi_metrics.iloc[df_fi_metrics.index.get_loc('YTM / est. yield')] != 0].tolist()\n",
        "# port_fi_metrics = pd.DataFrame()\n",
        "\n",
        "# ytm_duration_df = pc.exposure_analysis_mixed(client_latest_alloc_adj, df_fi_metrics.loc[['Duration', 'YTM / est. yield']].astype(float), fixed_income_list, latest_data=True)\n",
        "# port_fi_metrics = pd.concat([port_fi_metrics, ytm_duration_df], axis=1)\n",
        "# port_fi_metrics.loc['Credit rating'] = pc.calc_avg_credit_rating(client_latest_alloc_adj, df_fi_metrics.loc[['Credit rating']], latest_data=True)\n",
        "\n",
        "# # port_fi_metrics = pd.concat([port_fi_metrics, df_fi_metrics.loc[['Duration', 'YTM / est. yield', 'Credit rating']][bm_tickers]], axis=1)\n",
        "# port_fi_metrics = pd.concat([port_fi_metrics, dvd_breakdown_all], axis=0)\n",
        "# port_fi_metrics"
      ],
      "metadata": {
        "cellView": "form",
        "id": "E6zglWkVSj3o"
      },
      "id": "E6zglWkVSj3o",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bc23505c5f3e4407b22508c6857c1f78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9e4498d8b844f92b1deb913755fe592",
            "placeholder": "​",
            "style": "IPY_MODEL_1a0dfa0e8b234a71b42063f0f5d3b67f",
            "value": "<div style='font-family: Arial, sans-serif; font-weight: bold;'>Upload client holdings from <a href=\"https://metabase.internal.syfe.com/question/1470-find-clients-portfolios-by-email?email=&portfolio_id=&client_id=&phone=&source_of_funds=\" target=\"_blank\">Metabase</a></div>"
          }
        },
        "b9e4498d8b844f92b1deb913755fe592": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a0dfa0e8b234a71b42063f0f5d3b67f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67b4e516417f46a9aab6ae1d9ca7ef8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 1,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": "*",
            "button_style": "",
            "data": [
              null
            ],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_d4323663013940878accdf6549d4e9b3",
            "metadata": [
              {
                "name": "Client_1_PV copy.csv",
                "type": "text/csv",
                "size": 5225,
                "lastModified": 1740376033882
              }
            ],
            "multiple": false,
            "style": "IPY_MODEL_34193d718da84c0f90f7b4b6ef97e6a7"
          }
        },
        "d4323663013940878accdf6549d4e9b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34193d718da84c0f90f7b4b6ef97e6a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}